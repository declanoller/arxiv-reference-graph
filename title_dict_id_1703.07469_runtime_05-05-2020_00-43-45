{
    "robustfill: neural program learning under noisy i/o": {
        "id": "1703.07469",
        "depth": 0,
        "children_titles": [
            "syntax guided synthesis",
            "neural machine translation by jointly learning to align and translate",
            "deepcoder learning to write programs",
            "terpret a probabilistic programming language for program induction",
            "neural turing machines",
            "hybrid computing using a neural network with dynamic external memory",
            "automating string processing in spreadsheets using input output examples",
            "spreadsheet data manipulation using examples",
            "attention based multimodal neural machine translation",
            "inferring algorithmic patterns with stack augmented recurrent nets",
            "neural gpus learn algorithms",
            "neural random access machines",
            "effective approaches to attention based neural machine translation",
            "knowledge and reasoning in program synthesis",
            "a deductive approach to program synthesis",
            "computation of normalized edit distance and applications",
            "a machine learning framework for programming by example",
            "neural programmer inducing latent programs with gradient descent",
            "neuro symbolic program synthesis",
            "flashmeta a framework for inductive program synthesis",
            "neural programmer interpreters",
            "programming with a differentiable forth interpreter",
            "sequence to sequence learning with neural networks",
            "improved semantic representations from tree structured long short term memory networks",
            "grammar as a foreign language",
            "prow a step toward automatic program writing",
            "show attend and tell neural image caption generation with visual attention",
            "learning to execute"
        ],
        "status": "root",
        "title_full": "RobustFill: Neural Program Learning under Noisy I/O",
        "link": "https://arxiv.org/abs/1703.07469",
        "n_parents": 0,
        "year": "2017",
        "children_full_dicts": [
            {
                "ref_title_clean": "syntax guided synthesis",
                "ref_title_full": "Syntax guided synthesis",
                "year": "2013",
                "full_block": "Syntax-guided synthesis.\n"
            },
            {
                "ref_title_clean": "neural machine translation by jointly learning to align and translate",
                "ref_title_full": "Neural machine translation by jointly learning to align and translate",
                "year": "2014",
                "full_block": "Neural machine translation by jointly learning to align and\n  translate.\n"
            },
            {
                "ref_title_clean": "deepcoder learning to write programs",
                "ref_title_full": "Deepcoder: Learning to write programs",
                "year": "2016",
                "full_block": "Deepcoder: Learning to write programs.\n"
            },
            {
                "ref_title_clean": "terpret a probabilistic programming language for program induction",
                "ref_title_full": "Terpret: A probabilistic programming language for program induction",
                "year": "2016",
                "full_block": "Terpret: {A} probabilistic programming language for program\n  induction.\n"
            },
            {
                "ref_title_clean": "neural turing machines",
                "ref_title_full": "Neural turing machines",
                "year": "2014",
                "full_block": "Neural turing machines.\n"
            },
            {
                "ref_title_clean": "hybrid computing using a neural network with dynamic external memory",
                "ref_title_full": "Hybrid computing using a neural network with dynamic external memory",
                "year": "2016",
                "full_block": "Hybrid computing using a neural network with dynamic external memory.\n"
            },
            {
                "ref_title_clean": "automating string processing in spreadsheets using input output examples",
                "ref_title_full": "Automating string processing in spreadsheets using input output examples",
                "year": "2011",
                "full_block": "Automating string processing in spreadsheets using input-output\n  examples.\n"
            },
            {
                "ref_title_clean": "spreadsheet data manipulation using examples",
                "ref_title_full": "Spreadsheet data manipulation using examples",
                "year": "2012",
                "full_block": "Spreadsheet data manipulation using examples.\n"
            },
            {
                "ref_title_clean": "attention based multimodal neural machine translation",
                "ref_title_full": "Attention based multimodal neural machine translation",
                "year": "2016",
                "full_block": "Attention-based multimodal neural machine translation.\n"
            },
            {
                "ref_title_clean": "inferring algorithmic patterns with stack augmented recurrent nets",
                "ref_title_full": "Inferring algorithmic patterns with stack augmented recurrent nets",
                "year": "2015",
                "full_block": "Inferring algorithmic patterns with stack-augmented recurrent nets.\n"
            },
            {
                "ref_title_clean": "neural gpus learn algorithms",
                "ref_title_full": "Neural gpus learn algorithms",
                "year": "2015",
                "full_block": "Neural gpus learn algorithms.\n"
            },
            {
                "ref_title_clean": "neural random access machines",
                "ref_title_full": "Neural random access machines",
                "year": "2016",
                "full_block": "Neural random-access machines.\n"
            },
            {
                "ref_title_clean": "effective approaches to attention based neural machine translation",
                "ref_title_full": "Effective approaches to attention based neural machine translation",
                "year": "2015",
                "full_block": "Effective approaches to attention-based neural machine translation.\n"
            },
            {
                "ref_title_clean": "knowledge and reasoning in program synthesis",
                "ref_title_full": "Knowledge and reasoning in program synthesis",
                "year": "1975",
                "full_block": "Knowledge and reasoning in program synthesis.\n"
            },
            {
                "ref_title_clean": "a deductive approach to program synthesis",
                "ref_title_full": "A deductive approach to program synthesis",
                "year": "1980",
                "full_block": "A deductive approach to program synthesis.\n"
            },
            {
                "ref_title_clean": "computation of normalized edit distance and applications",
                "ref_title_full": "Computation of normalized edit distance and applications",
                "year": "1993",
                "full_block": "Computation of normalized edit distance and applications.\n"
            },
            {
                "ref_title_clean": "a machine learning framework for programming by example",
                "ref_title_full": "A machine learning framework for programming by example",
                "year": "2013",
                "full_block": "A machine learning framework for programming by example.\n"
            },
            {
                "ref_title_clean": "neural programmer inducing latent programs with gradient descent",
                "ref_title_full": "Neural programmer: Inducing latent programs with gradient descent",
                "year": "2016",
                "full_block": "Neural programmer: Inducing latent programs with gradient descent.\n"
            },
            {
                "ref_title_clean": "neuro symbolic program synthesis",
                "ref_title_full": "Neuro symbolic program synthesis",
                "year": "2017",
                "full_block": "Neuro-symbolic program synthesis.\n"
            },
            {
                "ref_title_clean": "flashmeta a framework for inductive program synthesis",
                "ref_title_full": "Flashmeta: a framework for inductive program synthesis",
                "year": "2015",
                "full_block": "Flashmeta: a framework for inductive program synthesis.\n"
            },
            {
                "ref_title_clean": "neural programmer interpreters",
                "ref_title_full": "Neural programmer interpreters",
                "year": "2016",
                "full_block": "Neural programmer-interpreters.\n"
            },
            {
                "ref_title_clean": "programming with a differentiable forth interpreter",
                "ref_title_full": "Programming with a differentiable forth interpreter",
                "year": "2016",
                "full_block": "Programming with a differentiable forth interpreter.\n"
            },
            {
                "ref_title_clean": "sequence to sequence learning with neural networks",
                "ref_title_full": "Sequence to sequence learning with neural networks",
                "year": "2014",
                "full_block": "Sequence to sequence learning with neural networks.\n"
            },
            {
                "ref_title_clean": "improved semantic representations from tree structured long short term memory networks",
                "ref_title_full": "Improved semantic representations from tree structured long short term memory networks",
                "year": "2015",
                "full_block": "Improved semantic representations from tree-structured long\n  short-term memory networks.\n"
            },
            {
                "ref_title_clean": "grammar as a foreign language",
                "ref_title_full": "Grammar as a foreign language",
                "year": "2015",
                "full_block": "Grammar as a foreign language.\n"
            },
            {
                "ref_title_clean": "prow a step toward automatic program writing",
                "ref_title_full": "Prow: A step toward automatic program writing",
                "year": "1969",
                "full_block": "Prow: A step toward automatic program writing.\n"
            },
            {
                "ref_title_clean": "show attend and tell neural image caption generation with visual attention",
                "ref_title_full": "Show, attend and tell: Neural image caption generation with visual attention",
                "year": "2015",
                "full_block": "Show, attend and tell: Neural image caption generation with visual\n  attention.\n"
            },
            {
                "ref_title_clean": "learning to execute",
                "ref_title_full": "Learning to execute",
                "year": "2014",
                "full_block": "Learning to execute.\n"
            }
        ],
        "refs_source": "unpacked_sources/1703.07469/ms.bbl"
    },
    "syntax guided synthesis": {
        "id": "1405.5590",
        "depth": 1,
        "children_titles": [
            "syntax guided synthesis"
        ],
        "status": "expanded",
        "title_full": "Syntax guided synthesis",
        "link": "https://arxiv.org/abs/1405.5590",
        "n_parents": 4,
        "year": "2013",
        "children_full_dicts": [
            {
                "ref_title_clean": "syntax guided synthesis",
                "ref_title_full": "Syntax guided synthesis",
                "year": "2013",
                "full_block": "Syntax-guided synthesis.\n"
            }
        ],
        "refs_source": "unpacked_sources/1405.5590/sygus.bbl"
    },
    "neural machine translation by jointly learning to align and translate": {
        "id": "1409.0473",
        "depth": 1,
        "children_titles": [
            "domain adaptation via pseudo in domain data selection",
            "theano new features and speed improvements",
            "learning long term dependencies with gradient descent is difficult",
            "a neural probabilistic language model",
            "theano a cpu and gpu math expression compiler",
            "audio chord recognition with recurrent neural networks",
            "learning phrase representations using rnn encoder decoder for statistical machine translation",
            "on the properties of neural machine translation encoder decoder approaches",
            "fast and robust neural network joint models for statistical machine translation",
            "recursive hetero associative memories for translation",
            "maxout networks",
            "sequence transduction with recurrent neural networks",
            "generating sequences with recurrent neural networks",
            "hybrid speech recognition with deep bidirectional lstm",
            "multilingual distributed representations without word alignment",
            "long short term memory",
            "recurrent continuous translation models",
            "statistical machine translation",
            "statistical phrase based translation",
            "on the difficulty of training recurrent neural networks",
            "on the difficulty of training recurrent neural networks",
            "how to construct deep recurrent neural networks",
            "overcoming the curse of sentence length for neural machine translation using automatic segmentation",
            "bidirectional recurrent neural networks",
            "continuous space translation models for phrase based statistical machine translation",
            "continuous space language models for statistical machine translation",
            "sequence to sequence learning with neural networks",
            "adadelta an adaptive learning rate method"
        ],
        "status": "expanded",
        "title_full": "Neural machine translation by jointly learning to align and translate",
        "link": "https://arxiv.org/abs/1409.0473",
        "n_parents": 9,
        "year": "2014",
        "children_full_dicts": [
            {
                "ref_title_clean": "domain adaptation via pseudo in domain data selection",
                "ref_title_full": "Domain adaptation via pseudo in domain data selection",
                "year": "none",
                "full_block": "Domain adaptation via pseudo in-domain data selection.\n"
            },
            {
                "ref_title_clean": "theano new features and speed improvements",
                "ref_title_full": "Theano: new features and speed improvements",
                "year": "none",
                "full_block": "Theano: new features and speed improvements.\n"
            },
            {
                "ref_title_clean": "learning long term dependencies with gradient descent is difficult",
                "ref_title_full": "Learning long term dependencies with gradient descent is difficult",
                "year": "none",
                "full_block": "Learning long-term dependencies with gradient descent is difficult.\n"
            },
            {
                "ref_title_clean": "a neural probabilistic language model",
                "ref_title_full": "A neural probabilistic language model",
                "year": "none",
                "full_block": "A neural probabilistic language model.\n"
            },
            {
                "ref_title_clean": "theano a cpu and gpu math expression compiler",
                "ref_title_full": "Theano: a CPU and GPU math expression compiler",
                "year": "none",
                "full_block": "Theano: a {CPU} and {GPU} math expression compiler.\n"
            },
            {
                "ref_title_clean": "audio chord recognition with recurrent neural networks",
                "ref_title_full": "Audio chord recognition with recurrent neural networks",
                "year": "none",
                "full_block": "Audio chord recognition with recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "learning phrase representations using rnn encoder decoder for statistical machine translation",
                "ref_title_full": "Learning phrase representations using RNN encoder decoder for statistical machine translation",
                "year": "none",
                "full_block": "Learning phrase representations using {RNN} encoder-decoder for\n  statistical machine translation.\n"
            },
            {
                "ref_title_clean": "on the properties of neural machine translation encoder decoder approaches",
                "ref_title_full": "On the properties of neural machine translation: Encoder Decoder approaches",
                "year": "none",
                "full_block": "On the properties of neural machine translation: {E}ncoder--{D}ecoder\n  approaches.\n"
            },
            {
                "ref_title_clean": "fast and robust neural network joint models for statistical machine translation",
                "ref_title_full": "Fast and robust neural network joint models for statistical machine translation",
                "year": "none",
                "full_block": "Fast and robust neural network joint models for statistical machine\n  translation.\n"
            },
            {
                "ref_title_clean": "recursive hetero associative memories for translation",
                "ref_title_full": "Recursive hetero associative memories for translation",
                "year": "none",
                "full_block": "Recursive hetero-associative memories for translation.\n"
            },
            {
                "ref_title_clean": "maxout networks",
                "ref_title_full": "Maxout networks",
                "year": "none",
                "full_block": "Maxout networks.\n"
            },
            {
                "ref_title_clean": "sequence transduction with recurrent neural networks",
                "ref_title_full": "Sequence transduction with recurrent neural networks",
                "year": "none",
                "full_block": "Sequence transduction with recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "generating sequences with recurrent neural networks",
                "ref_title_full": "Generating sequences with recurrent neural networks",
                "year": "1308",
                "full_block": "Generating sequences with recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "hybrid speech recognition with deep bidirectional lstm",
                "ref_title_full": "Hybrid speech recognition with deep bidirectional LSTM",
                "year": "none",
                "full_block": "Hybrid speech recognition with deep bidirectional {LSTM}.\n"
            },
            {
                "ref_title_clean": "multilingual distributed representations without word alignment",
                "ref_title_full": "Multilingual distributed representations without word alignment",
                "year": "none",
                "full_block": "Multilingual distributed representations without word alignment.\n"
            },
            {
                "ref_title_clean": "long short term memory",
                "ref_title_full": "Long short term memory",
                "year": "none",
                "full_block": "Long short-term memory.\n"
            },
            {
                "ref_title_clean": "recurrent continuous translation models",
                "ref_title_full": "Recurrent continuous translation models",
                "year": "none",
                "full_block": "Recurrent continuous translation models.\n"
            },
            {
                "ref_title_clean": "statistical machine translation",
                "ref_title_full": "Statistical Machine Translation\\/",
                "year": "none",
                "full_block": "{\\em Statistical Machine Translation\\/}.\n"
            },
            {
                "ref_title_clean": "statistical phrase based translation",
                "ref_title_full": "Statistical phrase based translation",
                "year": "none",
                "full_block": "Statistical phrase-based translation.\n"
            },
            {
                "ref_title_clean": "on the difficulty of training recurrent neural networks",
                "ref_title_full": "On the difficulty of training recurrent neural networks",
                "year": "none",
                "full_block": "On the difficulty of training recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "on the difficulty of training recurrent neural networks",
                "ref_title_full": "On the difficulty of training recurrent neural networks",
                "year": "none",
                "full_block": "On the difficulty of training recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "how to construct deep recurrent neural networks",
                "ref_title_full": "How to construct deep recurrent neural networks",
                "year": "none",
                "full_block": "How to construct deep recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "overcoming the curse of sentence length for neural machine translation using automatic segmentation",
                "ref_title_full": "Overcoming the curse of sentence length for neural machine translation using automatic segmentation",
                "year": "none",
                "full_block": "Overcoming the curse of sentence length for neural machine\n  translation using automatic segmentation.\n"
            },
            {
                "ref_title_clean": "bidirectional recurrent neural networks",
                "ref_title_full": "Bidirectional recurrent neural networks",
                "year": "none",
                "full_block": "Bidirectional recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "continuous space translation models for phrase based statistical machine translation",
                "ref_title_full": "Continuous space translation models for phrase based statistical machine translation",
                "year": "none",
                "full_block": "Continuous space translation models for phrase-based statistical\n  machine translation.\n"
            },
            {
                "ref_title_clean": "continuous space language models for statistical machine translation",
                "ref_title_full": "Continuous space language models for statistical machine translation",
                "year": "none",
                "full_block": "Continuous space language models for statistical machine translation.\n"
            },
            {
                "ref_title_clean": "sequence to sequence learning with neural networks",
                "ref_title_full": "Sequence to sequence learning with neural networks",
                "year": "none",
                "full_block": "Sequence to sequence learning with neural networks.\n"
            },
            {
                "ref_title_clean": "adadelta an adaptive learning rate method",
                "ref_title_full": "ADADELTA: An adaptive learning rate method",
                "year": "1212",
                "full_block": "{ADADELTA}: An adaptive learning rate method.\n"
            }
        ],
        "refs_source": "unpacked_sources/1409.0473/search.bbl"
    },
    "deepcoder learning to write programs": {
        "id": "1611.01989",
        "depth": 1,
        "children_titles": [
            "deepmath deep sequence models for premise selection",
            "adaptive neural compilation",
            "the helmholtz machine",
            "on label dependence and loss minimization in multi label classification",
            "bayes optimal multilabel classification via probabilistic classifier chains",
            "synthesizing data structure transformations from input output examples",
            "terpret a probabilistic programming language for program induction",
            "neural turing machines",
            "hybrid computing using a neural network with dynamic external memory",
            "learning to transduce with unbounded memory",
            "programming by examples applications algorithms and ambiguity resolution",
            "synthesis of loop free programs",
            "learning to pass expectation propagation messages",
            "the informed sampler a discriminative approach to bayesian inference in generative computer vision models",
            "inferring algorithmic patterns with stack augmented recurrent nets",
            "neural gpus learn algorithms",
            "stochastic gradient vb and the variational auto encoder",
            "neural random access machines",
            "gated graph sequence neural networks",
            "latent predictor networks for code generation",
            "deep network guided proof search",
            "a machine learning framework for programming by example",
            "neural programmer inducing latent programs with gradient descent",
            "learning program embeddings to propagate feedback on student code",
            "flashmeta a framework for inductive program synthesis",
            "neural programmer interpreters",
            "programming with a differentiable forth interpreter",
            "stochastic program optimization",
            "real time human pose recognition in parts from single depth images",
            "predicting a correct program in programming by example",
            "program synthesis by sketching",
            "learning stochastic inverses",
            "end to end memory networks",
            "memory networks",
            "learning simple algorithms from examples"
        ],
        "status": "expanded",
        "title_full": "Deepcoder: Learning to write programs",
        "link": "https://arxiv.org/abs/1611.01989",
        "n_parents": 1,
        "year": "2016",
        "children_full_dicts": [
            {
                "ref_title_clean": "deepmath deep sequence models for premise selection",
                "ref_title_full": "DeepMath deep sequence models for premise selection",
                "year": "2016",
                "full_block": "{DeepMath} - deep sequence models for premise selection.\n"
            },
            {
                "ref_title_clean": "adaptive neural compilation",
                "ref_title_full": "Adaptive neural compilation",
                "year": "2016",
                "full_block": "Adaptive neural compilation.\n"
            },
            {
                "ref_title_clean": "the helmholtz machine",
                "ref_title_full": "The Helmholtz machine",
                "year": "1995",
                "full_block": "The {H}elmholtz machine.\n"
            },
            {
                "ref_title_clean": "on label dependence and loss minimization in multi label classification",
                "ref_title_full": "On label dependence and loss minimization in multi label classification",
                "year": "2012",
                "full_block": "On label dependence and loss minimization in multi-label\n  classification.\n"
            },
            {
                "ref_title_clean": "bayes optimal multilabel classification via probabilistic classifier chains",
                "ref_title_full": "Bayes optimal multilabel classification via probabilistic classifier chains",
                "year": "2010",
                "full_block": "Bayes optimal multilabel classification via probabilistic classifier\n  chains.\n"
            },
            {
                "ref_title_clean": "synthesizing data structure transformations from input output examples",
                "ref_title_full": "Synthesizing data structure transformations from input output examples",
                "year": "2015",
                "full_block": "Synthesizing data structure transformations from input-output\n  examples.\n"
            },
            {
                "ref_title_clean": "terpret a probabilistic programming language for program induction",
                "ref_title_full": "Terpret: A probabilistic programming language for program induction",
                "year": "2016",
                "full_block": "Terpret: A probabilistic programming language for program induction.\n"
            },
            {
                "ref_title_clean": "neural turing machines",
                "ref_title_full": "Neural Turing machines",
                "year": "2014",
                "full_block": "Neural {T}uring machines.\n"
            },
            {
                "ref_title_clean": "hybrid computing using a neural network with dynamic external memory",
                "ref_title_full": "Hybrid computing using a neural network with dynamic external memory",
                "year": "2016",
                "full_block": "Hybrid computing using a neural network with dynamic external memory.\n"
            },
            {
                "ref_title_clean": "learning to transduce with unbounded memory",
                "ref_title_full": "Learning to transduce with unbounded memory",
                "year": "2015",
                "full_block": "Learning to transduce with unbounded memory.\n"
            },
            {
                "ref_title_clean": "programming by examples applications algorithms and ambiguity resolution",
                "ref_title_full": "Programming by examples: Applications, algorithms, and ambiguity resolution",
                "year": "2016",
                "full_block": "Programming by examples: Applications, algorithms, and ambiguity\n  resolution.\n"
            },
            {
                "ref_title_clean": "synthesis of loop free programs",
                "ref_title_full": "Synthesis of loop free programs",
                "year": "2011",
                "full_block": "Synthesis of loop-free programs.\n"
            },
            {
                "ref_title_clean": "learning to pass expectation propagation messages",
                "ref_title_full": "Learning to pass expectation propagation messages",
                "year": "2013",
                "full_block": "Learning to pass expectation propagation messages.\n"
            },
            {
                "ref_title_clean": "the informed sampler a discriminative approach to bayesian inference in generative computer vision models",
                "ref_title_full": "The informed sampler: A discriminative approach to Bayesian inference in generative computer vision models",
                "year": "2015",
                "full_block": "The informed sampler: A discriminative approach to {B}ayesian\n  inference in generative computer vision models.\n"
            },
            {
                "ref_title_clean": "inferring algorithmic patterns with stack augmented recurrent nets",
                "ref_title_full": "Inferring algorithmic patterns with stack augmented recurrent nets",
                "year": "2015",
                "full_block": "Inferring algorithmic patterns with stack-augmented recurrent nets.\n"
            },
            {
                "ref_title_clean": "neural gpus learn algorithms",
                "ref_title_full": "Neural GPUs learn algorithms",
                "year": "2016",
                "full_block": "Neural {GPU}s learn algorithms.\n"
            },
            {
                "ref_title_clean": "stochastic gradient vb and the variational auto encoder",
                "ref_title_full": "Stochastic gradient VB and the variational auto encoder",
                "year": "2014",
                "full_block": "Stochastic gradient {VB} and the variational auto-encoder.\n"
            },
            {
                "ref_title_clean": "neural random access machines",
                "ref_title_full": "Neural random access machines",
                "year": "2015",
                "full_block": "Neural random-access machines.\n"
            },
            {
                "ref_title_clean": "gated graph sequence neural networks",
                "ref_title_full": "Gated graph sequence neural networks",
                "year": "2016",
                "full_block": "Gated graph sequence neural networks.\n"
            },
            {
                "ref_title_clean": "latent predictor networks for code generation",
                "ref_title_full": "Latent predictor networks for code generation",
                "year": "2016",
                "full_block": "Latent predictor networks for code generation.\n"
            },
            {
                "ref_title_clean": "deep network guided proof search",
                "ref_title_full": "Deep network guided proof search",
                "year": "2017",
                "full_block": "Deep network guided proof search.\n"
            },
            {
                "ref_title_clean": "a machine learning framework for programming by example",
                "ref_title_full": "A machine learning framework for programming by example",
                "year": "2013",
                "full_block": "A machine learning framework for programming by example.\n"
            },
            {
                "ref_title_clean": "neural programmer inducing latent programs with gradient descent",
                "ref_title_full": "Neural programmer: Inducing latent programs with gradient descent",
                "year": "2016",
                "full_block": "Neural programmer: Inducing latent programs with gradient descent.\n"
            },
            {
                "ref_title_clean": "learning program embeddings to propagate feedback on student code",
                "ref_title_full": "Learning program embeddings to propagate feedback on student code",
                "year": "2015",
                "full_block": "Learning program embeddings to propagate feedback on student code.\n"
            },
            {
                "ref_title_clean": "flashmeta a framework for inductive program synthesis",
                "ref_title_full": "FlashMeta: a framework for inductive program synthesis",
                "year": "2015",
                "full_block": "{FlashMeta}: a framework for inductive program synthesis.\n"
            },
            {
                "ref_title_clean": "neural programmer interpreters",
                "ref_title_full": "Neural programmer interpreters",
                "year": "2016",
                "full_block": "Neural programmer-interpreters.\n"
            },
            {
                "ref_title_clean": "programming with a differentiable forth interpreter",
                "ref_title_full": "Programming with a differentiable forth interpreter",
                "year": "2016",
                "full_block": "Programming with a differentiable forth interpreter.\n"
            },
            {
                "ref_title_clean": "stochastic program optimization",
                "ref_title_full": "Stochastic program optimization",
                "year": "2016",
                "full_block": "Stochastic program optimization.\n"
            },
            {
                "ref_title_clean": "real time human pose recognition in parts from single depth images",
                "ref_title_full": "Real time human pose recognition in parts from single depth images",
                "year": "2013",
                "full_block": "Real-time human pose recognition in parts from single depth images.\n"
            },
            {
                "ref_title_clean": "predicting a correct program in programming by example",
                "ref_title_full": "Predicting a correct program in programming by example",
                "year": "2015",
                "full_block": "Predicting a correct program in programming by example.\n"
            },
            {
                "ref_title_clean": "program synthesis by sketching",
                "ref_title_full": "\\Program Synthesis By Sketching",
                "year": "2008",
                "full_block": "\\emph{Program Synthesis By Sketching}.\n"
            },
            {
                "ref_title_clean": "learning stochastic inverses",
                "ref_title_full": "Learning stochastic inverses",
                "year": "2013",
                "full_block": "Learning stochastic inverses.\n"
            },
            {
                "ref_title_clean": "end to end memory networks",
                "ref_title_full": "End to end memory networks",
                "year": "2015",
                "full_block": "End-to-end memory networks.\n"
            },
            {
                "ref_title_clean": "memory networks",
                "ref_title_full": "Memory networks",
                "year": "2015",
                "full_block": "Memory networks.\n"
            },
            {
                "ref_title_clean": "learning simple algorithms from examples",
                "ref_title_full": "Learning simple algorithms from examples",
                "year": "2016",
                "full_block": "Learning simple algorithms from examples.\n"
            }
        ],
        "refs_source": "unpacked_sources/1611.01989/main.bbl"
    },
    "terpret a probabilistic programming language for program induction": {
        "id": "1608.04428",
        "depth": 1,
        "children_titles": [
            "control flow analysis",
            "syntax guided synthesis",
            "the toolsmt lib standard version 25",
            "learning long term dependencies with gradient descent is difficult",
            "the inference of regular lisp programs from examples",
            "adaptive neural compilation",
            "stan a probabilistic programming language",
            "on the properties of neural machine translation encoder decoder approaches",
            "bounded model checking using satisfiability solving",
            "using prior knowledge in a nnpda to learn context free languages",
            "identifying and attacking the saddle point problem in high dimensional non convex optimization",
            "z3 an efficient smt solver",
            "unsupervised learning by program synthesis",
            "higher order recurrent networks and grammatical inference",
            "church a language for generative models",
            "generating sequences with recurrent neural networks",
            "neural turing machines",
            "learning to transduce with unbounded memory",
            "automating string processing in spreadsheets using input output examples",
            "program verification as probabilistic inference",
            "spreadsheet data manipulation using examples",
            "long short term memory",
            "inferring algorithmic patterns with stack augmented recurrent nets",
            "neural gpus learn algorithms",
            "a clockwork rnn",
            "complete functional synthesis",
            "neural random access machines",
            "human level concept learning through probabilistic program induction",
            "llvm a compilation framework for lifelong program analysis  transformation",
            "learning longer memory in recurrent neural networks",
            "microsoft research cambridge httpresearchmicrosoftcominfernet",
            "gates",
            "a connectionist symbol manipulator that discovers the structure of context free languages",
            "neural programmer inducing latent programs with gradient descent",
            "adding gradient noise improves learning for very deep networks",
            "automatic sampler discovery via probabilistic programming and approximate bayesian computation",
            "chlorophyll synthesis aided compiler for low power spatial architectures",
            "flashmeta a framework for inductive program synthesis",
            "learning programs from noisy data",
            "neural programmer interpreters",
            "counterexample guided quantifier instantiation for synthesis in smt",
            "programming with a differentiable forth interpreter",
            "stochastic superoptimization",
            "syntactic analysis of two dimensional visual signals in the presence of noise",
            "blinkfill semi supervised programming by example for syntactic string transformations",
            "automated feedback generation for introductory programming assignments",
            "program synthesis by sketching",
            "programming by sketching for bit streaming programs",
            "combinatorial sketching for finite programs",
            "tightening lp relaxations for map using message passing",
            "url urlhttpmc stanorg",
            "end to end memory networks",
            "a methodology for lisp program construction from examples",
            "lecture 65 rmsprop divide the gradient by a running average of its recent magnitude",
            "transit specifying protocols with concolic snippets",
            "graphical models exponential families and variational inference",
            "a linear programming approach to max sum problem a review",
            "memory networks",
            "learning simple algorithms from examples"
        ],
        "status": "expanded",
        "title_full": "Terpret: A probabilistic programming language for program induction",
        "link": "https://arxiv.org/abs/1608.04428",
        "n_parents": 4,
        "year": "2016",
        "children_full_dicts": [
            {
                "ref_title_clean": "control flow analysis",
                "ref_title_full": "Control flow analysis",
                "year": "1970",
                "full_block": "Control flow analysis.\n"
            },
            {
                "ref_title_clean": "syntax guided synthesis",
                "ref_title_full": "Syntax guided synthesis",
                "year": "2015",
                "full_block": "Syntax-guided synthesis.\n"
            },
            {
                "ref_title_clean": "the toolsmt lib standard version 25",
                "ref_title_full": "The \\toolSMT LIB standard: Version 2.5",
                "year": "2015",
                "full_block": "The \\tool{SMT-LIB} standard: Version 2.5.\n"
            },
            {
                "ref_title_clean": "learning long term dependencies with gradient descent is difficult",
                "ref_title_full": "Learning long term dependencies with gradient descent is difficult",
                "year": "1994",
                "full_block": "Learning long-term dependencies with gradient descent is difficult.\n"
            },
            {
                "ref_title_clean": "the inference of regular lisp programs from examples",
                "ref_title_full": "The inference of regular lisp programs from examples",
                "year": "1978",
                "full_block": "The inference of regular lisp programs from examples.\n"
            },
            {
                "ref_title_clean": "adaptive neural compilation",
                "ref_title_full": "Adaptive neural compilation",
                "year": "2016",
                "full_block": "Adaptive neural compilation.\n"
            },
            {
                "ref_title_clean": "stan a probabilistic programming language",
                "ref_title_full": "Stan: A probabilistic programming language",
                "year": "2015",
                "full_block": "Stan: A probabilistic programming language.\n"
            },
            {
                "ref_title_clean": "on the properties of neural machine translation encoder decoder approaches",
                "ref_title_full": "On the properties of neural machine translation: Encoder decoder approaches",
                "year": "2014",
                "full_block": "On the properties of neural machine translation: Encoder-decoder\n  approaches.\n"
            },
            {
                "ref_title_clean": "bounded model checking using satisfiability solving",
                "ref_title_full": "Bounded model checking using satisfiability solving",
                "year": "2001",
                "full_block": "Bounded model checking using satisfiability solving.\n"
            },
            {
                "ref_title_clean": "using prior knowledge in a nnpda to learn context free languages",
                "ref_title_full": "Using prior knowledge in a \\NNPDA\\ to learn context free languages",
                "year": "1992",
                "full_block": "Using prior knowledge in a \\{NNPDA\\} to learn context-free languages.\n"
            },
            {
                "ref_title_clean": "identifying and attacking the saddle point problem in high dimensional non convex optimization",
                "ref_title_full": "Identifying and attacking the saddle point problem in high dimensional non convex optimization",
                "year": "2014",
                "full_block": "Identifying and attacking the saddle point problem in\n  high-dimensional non-convex optimization.\n"
            },
            {
                "ref_title_clean": "z3 an efficient smt solver",
                "ref_title_full": "Z3: an efficient SMT solver",
                "year": "2008",
                "full_block": "{Z3:} an efficient {SMT} solver.\n"
            },
            {
                "ref_title_clean": "unsupervised learning by program synthesis",
                "ref_title_full": "Unsupervised learning by program synthesis",
                "year": "2015",
                "full_block": "Unsupervised learning by program synthesis.\n"
            },
            {
                "ref_title_clean": "higher order recurrent networks and grammatical inference",
                "ref_title_full": "Higher order recurrent networks and grammatical inference",
                "year": "1989",
                "full_block": "Higher order recurrent networks and grammatical inference.\n"
            },
            {
                "ref_title_clean": "church a language for generative models",
                "ref_title_full": "Church: a language for generative models",
                "year": "2008",
                "full_block": "Church: a language for generative models.\n"
            },
            {
                "ref_title_clean": "generating sequences with recurrent neural networks",
                "ref_title_full": "Generating sequences with recurrent neural networks",
                "year": "2013",
                "full_block": "Generating sequences with recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "neural turing machines",
                "ref_title_full": "Neural turing machines",
                "year": "2014",
                "full_block": "Neural turing machines.\n"
            },
            {
                "ref_title_clean": "learning to transduce with unbounded memory",
                "ref_title_full": "Learning to transduce with unbounded memory",
                "year": "2015",
                "full_block": "Learning to transduce with unbounded memory.\n"
            },
            {
                "ref_title_clean": "automating string processing in spreadsheets using input output examples",
                "ref_title_full": "Automating string processing in spreadsheets using input output examples",
                "year": "2011",
                "full_block": "Automating string processing in spreadsheets using input-output\n  examples.\n"
            },
            {
                "ref_title_clean": "program verification as probabilistic inference",
                "ref_title_full": "Program verification as probabilistic inference",
                "year": "2007",
                "full_block": "Program verification as probabilistic inference.\n"
            },
            {
                "ref_title_clean": "spreadsheet data manipulation using examples",
                "ref_title_full": "Spreadsheet data manipulation using examples",
                "year": "2012",
                "full_block": "Spreadsheet data manipulation using examples.\n"
            },
            {
                "ref_title_clean": "long short term memory",
                "ref_title_full": "Long short term memory",
                "year": "1997",
                "full_block": "Long short-term memory.\n"
            },
            {
                "ref_title_clean": "inferring algorithmic patterns with stack augmented recurrent nets",
                "ref_title_full": "Inferring algorithmic patterns with stack augmented recurrent nets",
                "year": "2015",
                "full_block": "Inferring algorithmic patterns with stack-augmented recurrent nets.\n"
            },
            {
                "ref_title_clean": "neural gpus learn algorithms",
                "ref_title_full": "Neural gpus learn algorithms",
                "year": "2016",
                "full_block": "Neural gpus learn algorithms.\n"
            },
            {
                "ref_title_clean": "a clockwork rnn",
                "ref_title_full": "A clockwork RNN",
                "year": "2014",
                "full_block": "A clockwork {RNN}.\n"
            },
            {
                "ref_title_clean": "complete functional synthesis",
                "ref_title_full": "Complete functional synthesis",
                "year": "2010",
                "full_block": "Complete functional synthesis.\n"
            },
            {
                "ref_title_clean": "neural random access machines",
                "ref_title_full": "Neural random access machines",
                "year": "2015",
                "full_block": "Neural random-access machines.\n"
            },
            {
                "ref_title_clean": "human level concept learning through probabilistic program induction",
                "ref_title_full": "Human level concept learning through probabilistic program induction",
                "year": "2015",
                "full_block": "Human-level concept learning through probabilistic program induction.\n"
            },
            {
                "ref_title_clean": "llvm a compilation framework for lifelong program analysis  transformation",
                "ref_title_full": "Llvm: A compilation framework for lifelong program analysis \\& transformation",
                "year": "none",
                "full_block": "Llvm: A compilation framework for lifelong program analysis \\&\n  transformation.\n"
            },
            {
                "ref_title_clean": "learning longer memory in recurrent neural networks",
                "ref_title_full": "Learning longer memory in recurrent neural networks",
                "year": "2015",
                "full_block": "Learning longer memory in recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "microsoft research cambridge httpresearchmicrosoftcominfernet",
                "ref_title_full": "Microsoft Research Cambridge. http://research.microsoft.com/infernet",
                "year": "2014",
                "full_block": "Microsoft Research Cambridge. http://research.microsoft.com/infernet.\n\n"
            },
            {
                "ref_title_clean": "gates",
                "ref_title_full": "Gates",
                "year": "2009",
                "full_block": "Gates.\n"
            },
            {
                "ref_title_clean": "a connectionist symbol manipulator that discovers the structure of context free languages",
                "ref_title_full": "A connectionist symbol manipulator that discovers the structure of context free languages",
                "year": "1992",
                "full_block": "A connectionist symbol manipulator that discovers the structure of\n  context-free languages.\n"
            },
            {
                "ref_title_clean": "neural programmer inducing latent programs with gradient descent",
                "ref_title_full": "Neural programmer: Inducing latent programs with gradient descent",
                "year": "none",
                "full_block": "Neural programmer: Inducing latent programs with gradient descent.\n"
            },
            {
                "ref_title_clean": "adding gradient noise improves learning for very deep networks",
                "ref_title_full": "Adding gradient noise improves learning for very deep networks",
                "year": "none",
                "full_block": "Adding gradient noise improves learning for very deep networks.\n"
            },
            {
                "ref_title_clean": "automatic sampler discovery via probabilistic programming and approximate bayesian computation",
                "ref_title_full": "Automatic sampler discovery via probabilistic programming and approximate bayesian computation",
                "year": "2016",
                "full_block": "Automatic sampler discovery via probabilistic programming and\n  approximate bayesian computation.\n"
            },
            {
                "ref_title_clean": "chlorophyll synthesis aided compiler for low power spatial architectures",
                "ref_title_full": "Chlorophyll: synthesis aided compiler for low power spatial architectures",
                "year": "2014",
                "full_block": "Chlorophyll: synthesis-aided compiler for low-power spatial\n  architectures.\n"
            },
            {
                "ref_title_clean": "flashmeta a framework for inductive program synthesis",
                "ref_title_full": "Flashmeta: a framework for inductive program synthesis",
                "year": "2015",
                "full_block": "Flashmeta: a framework for inductive program synthesis.\n"
            },
            {
                "ref_title_clean": "learning programs from noisy data",
                "ref_title_full": "Learning programs from noisy data",
                "year": "2016",
                "full_block": "Learning programs from noisy data.\n"
            },
            {
                "ref_title_clean": "neural programmer interpreters",
                "ref_title_full": "Neural programmer interpreters",
                "year": "none",
                "full_block": "Neural programmer-interpreters.\n"
            },
            {
                "ref_title_clean": "counterexample guided quantifier instantiation for synthesis in smt",
                "ref_title_full": "Counterexample guided quantifier instantiation for synthesis in SMT",
                "year": "2015",
                "full_block": "Counterexample-guided quantifier instantiation for synthesis in\n  {SMT}.\n"
            },
            {
                "ref_title_clean": "programming with a differentiable forth interpreter",
                "ref_title_full": "Programming with a differentiable forth interpreter",
                "year": "2016",
                "full_block": "Programming with a differentiable forth interpreter.\n"
            },
            {
                "ref_title_clean": "stochastic superoptimization",
                "ref_title_full": "Stochastic superoptimization",
                "year": "2013",
                "full_block": "Stochastic superoptimization.\n"
            },
            {
                "ref_title_clean": "syntactic analysis of two dimensional visual signals in the presence of noise",
                "ref_title_full": "Syntactic analysis of two dimensional visual signals in the presence of noise",
                "year": "1976",
                "full_block": "Syntactic analysis of two-dimensional visual signals in the presence\n  of noise.\n"
            },
            {
                "ref_title_clean": "blinkfill semi supervised programming by example for syntactic string transformations",
                "ref_title_full": "Blinkfill: Semi supervised programming by example for syntactic string transformations",
                "year": "2016",
                "full_block": "Blinkfill: Semi-supervised programming by example for syntactic\n  string transformations.\n"
            },
            {
                "ref_title_clean": "automated feedback generation for introductory programming assignments",
                "ref_title_full": "Automated feedback generation for introductory programming assignments",
                "year": "2013",
                "full_block": "Automated feedback generation for introductory programming\n  assignments.\n"
            },
            {
                "ref_title_clean": "program synthesis by sketching",
                "ref_title_full": "\\Program Synthesis By Sketching",
                "year": "2008",
                "full_block": "\\emph{Program Synthesis By Sketching}.\n"
            },
            {
                "ref_title_clean": "programming by sketching for bit streaming programs",
                "ref_title_full": "Programming by sketching for bit streaming programs",
                "year": "2005",
                "full_block": "Programming by sketching for bit-streaming programs.\n"
            },
            {
                "ref_title_clean": "combinatorial sketching for finite programs",
                "ref_title_full": "Combinatorial sketching for finite programs",
                "year": "2006",
                "full_block": "Combinatorial sketching for finite programs.\n"
            },
            {
                "ref_title_clean": "tightening lp relaxations for map using message passing",
                "ref_title_full": "Tightening lp relaxations for map using message passing",
                "year": "2008",
                "full_block": "Tightening lp relaxations for map using message passing.\n"
            },
            {
                "ref_title_clean": "url urlhttpmc stanorg",
                "ref_title_full": "URL \\urlhttp://mc stan.org/",
                "year": "2015",
                "full_block": "URL \\url{http://mc-stan.org/}.\n\n"
            },
            {
                "ref_title_clean": "end to end memory networks",
                "ref_title_full": "End to end memory networks",
                "year": "2015",
                "full_block": "End-to-end memory networks.\n"
            },
            {
                "ref_title_clean": "a methodology for lisp program construction from examples",
                "ref_title_full": "A methodology for lisp program construction from examples",
                "year": "1977",
                "full_block": "A methodology for lisp program construction from examples.\n"
            },
            {
                "ref_title_clean": "lecture 65 rmsprop divide the gradient by a running average of its recent magnitude",
                "ref_title_full": "Lecture 6.5 RmsProp: Divide the gradient by a running average of its recent magnitude",
                "year": "2012",
                "full_block": "{Lecture 6.5---RmsProp: Divide the gradient by a running average of\n  its recent magnitude}.\n"
            },
            {
                "ref_title_clean": "transit specifying protocols with concolic snippets",
                "ref_title_full": "TRANSIT: specifying protocols with concolic snippets",
                "year": "2013",
                "full_block": "{TRANSIT:} specifying protocols with concolic snippets.\n"
            },
            {
                "ref_title_clean": "graphical models exponential families and variational inference",
                "ref_title_full": "Graphical models, exponential families, and variational inference",
                "year": "2008",
                "full_block": "Graphical models, exponential families, and variational inference.\n"
            },
            {
                "ref_title_clean": "a linear programming approach to max sum problem a review",
                "ref_title_full": "A linear programming approach to max sum problem: A review",
                "year": "2007",
                "full_block": "A linear programming approach to max-sum problem: A review.\n"
            },
            {
                "ref_title_clean": "memory networks",
                "ref_title_full": "Memory networks",
                "year": "2014",
                "full_block": "Memory networks.\n"
            },
            {
                "ref_title_clean": "learning simple algorithms from examples",
                "ref_title_full": "Learning simple algorithms from examples",
                "year": "2016",
                "full_block": "Learning simple algorithms from examples.\n"
            }
        ],
        "refs_source": "unpacked_sources/1608.04428/main.bbl"
    },
    "neural turing machines": {
        "id": "1410.5401",
        "depth": 1,
        "children_titles": [
            "memory",
            "neural machine translation by jointly learning to align and translate",
            "time constraints and resource sharing in adults working memory spans",
            "three models for the description of language",
            "learning context free grammars capabilities and limitations of a recurrent neural network with an external stack memory",
            "simple substrates for complex cognition",
            "how to build a brain a neural architecture for biological cognition",
            "the evolution of the language faculty clarifications and implications",
            "connectionism and cognitive architecture a critical analysis",
            "a general framework for adaptive processing of data structures",
            "memory and the computational brain why cognitive science will transform neuroscience volume3",
            "cellular basis of working memory",
            "generating sequences with recurrent neural networks",
            "towards end to end speech recognition with recurrent neural networks",
            "speech recognition with deep recurrent neural networks",
            "the problem of rapid variable creation",
            "banishing the homunculus making working memory work",
            "learning distributed representations of concepts",
            "gradient flow in recurrent nets the difficulty of learning long term dependencies",
            "long short term memory",
            "learning to learn using gradient descent",
            "neural networks and physical systems with emergent collective computational abilities",
            "the nature of the language faculty and its implications for evolution of language reply to fitch hauser and chomsky",
            "hyperdimensional computing an introduction to computing in distributed representation with high dimensional random vectors",
            "the algebraic mind integrating connectionism and cognitive science",
            "the magical number seven plus or minus two some limits on our capacity for processing information",
            "the cognitive revolution a historical perspective",
            "computation finite and infinite machines",
            "machine learning a probabilistic perspective",
            "holographic reduced representation distributed representation for cognitive structures",
            "recursive distributed representations",
            "the importance of mixed selectivity in complex cognitive tasks",
            "parallel distributed processing volume1",
            "continuous attractors and oculomotor control",
            "on the computational power of neural nets",
            "tensor product variable binding and the representation of symbolic structures in connectionist systems",
            "semantic compositionality through recursive matrix vector spaces",
            "generating text with recurrent neural networks",
            "sequence to sequence learning with neural networks",
            "boltzcons dynamic symbol structures in a connectionist network",
            "first draft of a report on the edvac",
            "synaptic basis of cortical persistent activity the importance of nmda receptors to working memory"
        ],
        "status": "expanded",
        "title_full": "Neural turing machines",
        "link": "https://arxiv.org/abs/1410.5401",
        "n_parents": 9,
        "year": "2014",
        "children_full_dicts": [
            {
                "ref_title_clean": "memory",
                "ref_title_full": "Memory",
                "year": "none",
                "full_block": "{\\em Memory}.\n"
            },
            {
                "ref_title_clean": "neural machine translation by jointly learning to align and translate",
                "ref_title_full": "Neural machine translation by jointly learning to align and translate",
                "year": "none",
                "full_block": "Neural machine translation by jointly learning to align and\n  translate.\n"
            },
            {
                "ref_title_clean": "time constraints and resource sharing in adults working memory spans",
                "ref_title_full": "Time constraints and resource sharing in adults' working memory spans",
                "year": "none",
                "full_block": "Time constraints and resource sharing in adults' working memory\n  spans.\n"
            },
            {
                "ref_title_clean": "three models for the description of language",
                "ref_title_full": "Three models for the description of language",
                "year": "none",
                "full_block": "Three models for the description of language.\n"
            },
            {
                "ref_title_clean": "learning context free grammars capabilities and limitations of a recurrent neural network with an external stack memory",
                "ref_title_full": "Learning context free grammars: Capabilities and limitations of a recurrent neural network with an external stack memory",
                "year": "none",
                "full_block": "Learning context-free grammars: Capabilities and limitations of a\n  recurrent neural network with an external stack memory.\n"
            },
            {
                "ref_title_clean": "simple substrates for complex cognition",
                "ref_title_full": "Simple substrates for complex cognition",
                "year": "none",
                "full_block": "Simple substrates for complex cognition.\n"
            },
            {
                "ref_title_clean": "how to build a brain a neural architecture for biological cognition",
                "ref_title_full": "How to build a brain: A neural architecture for biological cognition",
                "year": "none",
                "full_block": "{\\em How to build a brain: A neural architecture for biological\n  cognition}.\n"
            },
            {
                "ref_title_clean": "the evolution of the language faculty clarifications and implications",
                "ref_title_full": "The evolution of the language faculty: clarifications and implications",
                "year": "none",
                "full_block": "The evolution of the language faculty: clarifications and\n  implications.\n"
            },
            {
                "ref_title_clean": "connectionism and cognitive architecture a critical analysis",
                "ref_title_full": "Connectionism and cognitive architecture: A critical analysis",
                "year": "none",
                "full_block": "Connectionism and cognitive architecture: A critical analysis.\n"
            },
            {
                "ref_title_clean": "a general framework for adaptive processing of data structures",
                "ref_title_full": "A general framework for adaptive processing of data structures",
                "year": "none",
                "full_block": "A general framework for adaptive processing of data structures.\n"
            },
            {
                "ref_title_clean": "memory and the computational brain why cognitive science will transform neuroscience volume3",
                "ref_title_full": "Memory and the computational brain: Why cognitive science will transform neuroscience, volume~3",
                "year": "none",
                "full_block": "{\\em Memory and the computational brain: Why cognitive science will\n  transform neuroscience}, volume~3.\n"
            },
            {
                "ref_title_clean": "cellular basis of working memory",
                "ref_title_full": "Cellular basis of working memory",
                "year": "none",
                "full_block": "Cellular basis of working memory.\n"
            },
            {
                "ref_title_clean": "generating sequences with recurrent neural networks",
                "ref_title_full": "Generating sequences with recurrent neural networks",
                "year": "none",
                "full_block": "Generating sequences with recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "towards end to end speech recognition with recurrent neural networks",
                "ref_title_full": "Towards end to end speech recognition with recurrent neural networks",
                "year": "none",
                "full_block": "Towards end-to-end speech recognition with recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "speech recognition with deep recurrent neural networks",
                "ref_title_full": "Speech recognition with deep recurrent neural networks",
                "year": "none",
                "full_block": "Speech recognition with deep recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "the problem of rapid variable creation",
                "ref_title_full": "The problem of rapid variable creation",
                "year": "none",
                "full_block": "The problem of rapid variable creation.\n"
            },
            {
                "ref_title_clean": "banishing the homunculus making working memory work",
                "ref_title_full": "Banishing the homunculus: making working memory work",
                "year": "none",
                "full_block": "Banishing the homunculus: making working memory work.\n"
            },
            {
                "ref_title_clean": "learning distributed representations of concepts",
                "ref_title_full": "Learning distributed representations of concepts",
                "year": "none",
                "full_block": "Learning distributed representations of concepts.\n"
            },
            {
                "ref_title_clean": "gradient flow in recurrent nets the difficulty of learning long term dependencies",
                "ref_title_full": "Gradient flow in recurrent nets: the difficulty of learning long term dependencies",
                "year": "none",
                "full_block": "Gradient flow in recurrent nets: the difficulty of learning long-term\n  dependencies.\n\n"
            },
            {
                "ref_title_clean": "long short term memory",
                "ref_title_full": "Long short term memory",
                "year": "none",
                "full_block": "Long short-term memory.\n"
            },
            {
                "ref_title_clean": "learning to learn using gradient descent",
                "ref_title_full": "Learning to learn using gradient descent",
                "year": "none",
                "full_block": "Learning to learn using gradient descent.\n"
            },
            {
                "ref_title_clean": "neural networks and physical systems with emergent collective computational abilities",
                "ref_title_full": "Neural networks and physical systems with emergent collective computational abilities",
                "year": "none",
                "full_block": "Neural networks and physical systems with emergent collective\n  computational abilities.\n"
            },
            {
                "ref_title_clean": "the nature of the language faculty and its implications for evolution of language reply to fitch hauser and chomsky",
                "ref_title_full": "The nature of the language faculty and its implications for evolution of language (reply to fitch, hauser, and chomsky)",
                "year": "none",
                "full_block": "The nature of the language faculty and its implications for evolution\n  of language (reply to fitch, hauser, and chomsky).\n"
            },
            {
                "ref_title_clean": "hyperdimensional computing an introduction to computing in distributed representation with high dimensional random vectors",
                "ref_title_full": "Hyperdimensional computing: An introduction to computing in distributed representation with high dimensional random vectors",
                "year": "none",
                "full_block": "Hyperdimensional computing: An introduction to computing in\n  distributed representation with high-dimensional random vectors.\n"
            },
            {
                "ref_title_clean": "the algebraic mind integrating connectionism and cognitive science",
                "ref_title_full": "The algebraic mind: Integrating connectionism and cognitive science",
                "year": "none",
                "full_block": "{\\em The algebraic mind: Integrating connectionism and cognitive\n  science}.\n"
            },
            {
                "ref_title_clean": "the magical number seven plus or minus two some limits on our capacity for processing information",
                "ref_title_full": "The magical number seven, plus or minus two: some limits on our capacity for processing information",
                "year": "none",
                "full_block": "The magical number seven, plus or minus two: some limits on our\n  capacity for processing information.\n"
            },
            {
                "ref_title_clean": "the cognitive revolution a historical perspective",
                "ref_title_full": "The cognitive revolution: a historical perspective",
                "year": "none",
                "full_block": "The cognitive revolution: a historical perspective.\n"
            },
            {
                "ref_title_clean": "computation finite and infinite machines",
                "ref_title_full": "Computation: finite and infinite machines",
                "year": "none",
                "full_block": "{\\em Computation: finite and infinite machines}.\n"
            },
            {
                "ref_title_clean": "machine learning a probabilistic perspective",
                "ref_title_full": "Machine learning: a probabilistic perspective",
                "year": "none",
                "full_block": "{\\em Machine learning: a probabilistic perspective}.\n"
            },
            {
                "ref_title_clean": "holographic reduced representation distributed representation for cognitive structures",
                "ref_title_full": "Holographic Reduced Representation: Distributed representation for cognitive structures",
                "year": "none",
                "full_block": "{\\em Holographic Reduced Representation: Distributed representation\n  for cognitive structures}.\n"
            },
            {
                "ref_title_clean": "recursive distributed representations",
                "ref_title_full": "Recursive distributed representations",
                "year": "none",
                "full_block": "Recursive distributed representations.\n"
            },
            {
                "ref_title_clean": "the importance of mixed selectivity in complex cognitive tasks",
                "ref_title_full": "The importance of mixed selectivity in complex cognitive tasks",
                "year": "none",
                "full_block": "The importance of mixed selectivity in complex cognitive tasks.\n"
            },
            {
                "ref_title_clean": "parallel distributed processing volume1",
                "ref_title_full": "Parallel distributed processing, volume~1",
                "year": "none",
                "full_block": "{\\em Parallel distributed processing}, volume~1.\n"
            },
            {
                "ref_title_clean": "continuous attractors and oculomotor control",
                "ref_title_full": "Continuous attractors and oculomotor control",
                "year": "none",
                "full_block": "Continuous attractors and oculomotor control.\n"
            },
            {
                "ref_title_clean": "on the computational power of neural nets",
                "ref_title_full": "On the computational power of neural nets",
                "year": "none",
                "full_block": "On the computational power of neural nets.\n"
            },
            {
                "ref_title_clean": "tensor product variable binding and the representation of symbolic structures in connectionist systems",
                "ref_title_full": "Tensor product variable binding and the representation of symbolic structures in connectionist systems",
                "year": "none",
                "full_block": "Tensor product variable binding and the representation of symbolic\n  structures in connectionist systems.\n"
            },
            {
                "ref_title_clean": "semantic compositionality through recursive matrix vector spaces",
                "ref_title_full": "Semantic compositionality through recursive matrix vector spaces",
                "year": "none",
                "full_block": "Semantic compositionality through recursive matrix-vector spaces.\n"
            },
            {
                "ref_title_clean": "generating text with recurrent neural networks",
                "ref_title_full": "Generating text with recurrent neural networks",
                "year": "none",
                "full_block": "Generating text with recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "sequence to sequence learning with neural networks",
                "ref_title_full": "Sequence to sequence learning with neural networks",
                "year": "none",
                "full_block": "Sequence to sequence learning with neural networks.\n"
            },
            {
                "ref_title_clean": "boltzcons dynamic symbol structures in a connectionist network",
                "ref_title_full": "Boltzcons: Dynamic symbol structures in a connectionist network",
                "year": "none",
                "full_block": "Boltzcons: Dynamic symbol structures in a connectionist network.\n"
            },
            {
                "ref_title_clean": "first draft of a report on the edvac",
                "ref_title_full": "First draft of a report on the edvac",
                "year": "none",
                "full_block": "First draft of a report on the edvac.\n\n"
            },
            {
                "ref_title_clean": "synaptic basis of cortical persistent activity the importance of nmda receptors to working memory",
                "ref_title_full": "Synaptic basis of cortical persistent activity: the importance of nmda receptors to working memory",
                "year": "none",
                "full_block": "Synaptic basis of cortical persistent activity: the importance of\n  nmda receptors to working memory.\n"
            }
        ],
        "refs_source": "unpacked_sources/1410.5401/ntm_arxiv.bbl"
    },
    "hybrid computing using a neural network with dynamic external memory": {
        "id": null,
        "depth": 1,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Hybrid computing using a neural network with dynamic external memory",
        "link": "none",
        "n_parents": 3,
        "year": "2016"
    },
    "automating string processing in spreadsheets using input output examples": {
        "id": null,
        "depth": 1,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Automating string processing in spreadsheets using input output examples",
        "link": "none",
        "n_parents": 3,
        "year": "2011"
    },
    "spreadsheet data manipulation using examples": {
        "id": null,
        "depth": 1,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Spreadsheet data manipulation using examples",
        "link": "none",
        "n_parents": 3,
        "year": "2012"
    },
    "attention based multimodal neural machine translation": {
        "id": null,
        "depth": 1,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Attention based multimodal neural machine translation",
        "link": "none",
        "n_parents": 1,
        "year": "2016"
    },
    "inferring algorithmic patterns with stack augmented recurrent nets": {
        "id": "1503.01007",
        "depth": 1,
        "children_titles": [
            "scaling learning algorithms towards ai",
            "pattern recognition and machine learning",
            "context free and context sensitive dynamics in recurrent neural networks",
            "large scale machine learning with stochastic gradient descent",
            "random forests",
            "probabilistic interpretation of feedforward classification network outputs with relationships to statistical pattern recognition",
            "learning phrase representations using rnn encoder decoder for statistical machine translation",
            "toward a connectionist model of recursion in human linguistic performance",
            "gated feedback recurrent neural networks",
            "high performance neural networks for visual object classification",
            "mechanisms for sentence processing",
            "context dependent pre trained deep neural networks for large vocabulary speech recognition",
            "learning context free grammars capabilities and limitations of a recurrent neural network with an external stack memory",
            "using prior knowledge in a nnpda to learn context free languages",
            "finding structure in time",
            "context free parsing in connectionist networks",
            "lstm recurrent networks learn simple context free and context sensitive languages",
            "neural turing machines",
            "a recurrent network that performs a context sensitive prediction task",
            "long short term memory",
            "designing a counter another case study of dynamics and activation landscapes in recurrent networks",
            "imagenet classification with deep convolutional neural networks",
            "gradient based learning applied to document recognition",
            "statistical language models based on neural networks",
            "learning longer memory in recurrent neural networks",
            "perceptrons",
            "a connectionist symbol manipulator that discovers the structure of context free languages",
            "the induction of dynamical recognizers",
            "hogwild a lock free approach to parallelizing stochastic gradient descent",
            "a recurrent neural network that learns to count",
            "learning internal representations by error propagation",
            "fractal encoding of context free grammars in connectionist networks",
            "generalization of backpropagation with application to a recurrent gas market model",
            "memory networks",
            "learning to count without a counter a case study of dynamics and activation landscapes in recurrent networks",
            "gradient based learning algorithms for recurrent networks and their computational complexity",
            "learning to execute",
            "discrete recurrent neural networks for grammatical inference"
        ],
        "status": "expanded",
        "title_full": "Inferring algorithmic patterns with stack augmented recurrent nets",
        "link": "https://arxiv.org/abs/1503.01007",
        "n_parents": 8,
        "year": "2015",
        "children_full_dicts": [
            {
                "ref_title_clean": "scaling learning algorithms towards ai",
                "ref_title_full": "Scaling learning algorithms towards ai",
                "year": "2007",
                "full_block": "Scaling learning algorithms towards ai.\n"
            },
            {
                "ref_title_clean": "pattern recognition and machine learning",
                "ref_title_full": "Pattern recognition and machine learning",
                "year": "2006",
                "full_block": "{\\em Pattern recognition and machine learning}.\n"
            },
            {
                "ref_title_clean": "context free and context sensitive dynamics in recurrent neural networks",
                "ref_title_full": "Context free and context sensitive dynamics in recurrent neural networks",
                "year": "2000",
                "full_block": "Context-free and context-sensitive dynamics in recurrent neural\n  networks.\n"
            },
            {
                "ref_title_clean": "large scale machine learning with stochastic gradient descent",
                "ref_title_full": "Large scale machine learning with stochastic gradient descent",
                "year": "2010",
                "full_block": "Large-scale machine learning with stochastic gradient descent.\n"
            },
            {
                "ref_title_clean": "random forests",
                "ref_title_full": "Random forests",
                "year": "2001",
                "full_block": "Random forests.\n"
            },
            {
                "ref_title_clean": "probabilistic interpretation of feedforward classification network outputs with relationships to statistical pattern recognition",
                "ref_title_full": "Probabilistic interpretation of feedforward classification network outputs, with relationships to statistical pattern recognition",
                "year": "1990",
                "full_block": "Probabilistic interpretation of feedforward classification network\n  outputs, with relationships to statistical pattern recognition.\n"
            },
            {
                "ref_title_clean": "learning phrase representations using rnn encoder decoder for statistical machine translation",
                "ref_title_full": "Learning phrase representations using rnn encoder decoder for statistical machine translation",
                "year": "2014",
                "full_block": "Learning phrase representations using rnn encoder-decoder for\n  statistical machine translation.\n"
            },
            {
                "ref_title_clean": "toward a connectionist model of recursion in human linguistic performance",
                "ref_title_full": "Toward a connectionist model of recursion in human linguistic performance",
                "year": "1999",
                "full_block": "Toward a connectionist model of recursion in human linguistic\n  performance.\n"
            },
            {
                "ref_title_clean": "gated feedback recurrent neural networks",
                "ref_title_full": "Gated feedback recurrent neural networks",
                "year": "2015",
                "full_block": "Gated feedback recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "high performance neural networks for visual object classification",
                "ref_title_full": "High performance neural networks for visual object classification",
                "year": "2011",
                "full_block": "High-performance neural networks for visual object classification.\n"
            },
            {
                "ref_title_clean": "mechanisms for sentence processing",
                "ref_title_full": "Mechanisms for sentence processing",
                "year": "1996",
                "full_block": "{\\em Mechanisms for sentence processing}.\n"
            },
            {
                "ref_title_clean": "context dependent pre trained deep neural networks for large vocabulary speech recognition",
                "ref_title_full": "Context dependent pre trained deep neural networks for large vocabulary speech recognition",
                "year": "2012",
                "full_block": "Context-dependent pre-trained deep neural networks for\n  large-vocabulary speech recognition.\n"
            },
            {
                "ref_title_clean": "learning context free grammars capabilities and limitations of a recurrent neural network with an external stack memory",
                "ref_title_full": "Learning context free grammars: Capabilities and limitations of a recurrent neural network with an external stack memory",
                "year": "1992",
                "full_block": "Learning context-free grammars: Capabilities and limitations of a\n  recurrent neural network with an external stack memory.\n"
            },
            {
                "ref_title_clean": "using prior knowledge in a nnpda to learn context free languages",
                "ref_title_full": "Using prior knowledge in a nnpda to learn context free languages",
                "year": "1993",
                "full_block": "Using prior knowledge in a nnpda to learn context-free languages.\n"
            },
            {
                "ref_title_clean": "finding structure in time",
                "ref_title_full": "Finding structure in time",
                "year": "1990",
                "full_block": "Finding structure in time.\n"
            },
            {
                "ref_title_clean": "context free parsing in connectionist networks",
                "ref_title_full": "Context free parsing in connectionist networks",
                "year": "1994",
                "full_block": "Context-free parsing in connectionist networks.\n"
            },
            {
                "ref_title_clean": "lstm recurrent networks learn simple context free and context sensitive languages",
                "ref_title_full": "Lstm recurrent networks learn simple context free and context sensitive languages",
                "year": "2001",
                "full_block": "Lstm recurrent networks learn simple context-free and\n  context-sensitive languages.\n"
            },
            {
                "ref_title_clean": "neural turing machines",
                "ref_title_full": "Neural turing machines",
                "year": "2014",
                "full_block": "Neural turing machines.\n"
            },
            {
                "ref_title_clean": "a recurrent network that performs a context sensitive prediction task",
                "ref_title_full": "A recurrent network that performs a context sensitive prediction task",
                "year": "1996",
                "full_block": "A recurrent network that performs a context-sensitive prediction\n  task.\n"
            },
            {
                "ref_title_clean": "long short term memory",
                "ref_title_full": "Long short term memory",
                "year": "1997",
                "full_block": "Long short-term memory.\n"
            },
            {
                "ref_title_clean": "designing a counter another case study of dynamics and activation landscapes in recurrent networks",
                "ref_title_full": "Designing a counter: Another case study of dynamics and activation landscapes in recurrent networks",
                "year": "1997",
                "full_block": "Designing a counter: Another case study of dynamics and activation\n  landscapes in recurrent networks.\n"
            },
            {
                "ref_title_clean": "imagenet classification with deep convolutional neural networks",
                "ref_title_full": "Imagenet classification with deep convolutional neural networks",
                "year": "2012",
                "full_block": "Imagenet classification with deep convolutional neural networks.\n"
            },
            {
                "ref_title_clean": "gradient based learning applied to document recognition",
                "ref_title_full": "Gradient based learning applied to document recognition",
                "year": "none",
                "full_block": "Gradient-based learning applied to document recognition.\n"
            },
            {
                "ref_title_clean": "statistical language models based on neural networks",
                "ref_title_full": "Statistical language models based on neural networks",
                "year": "2012",
                "full_block": "{\\em Statistical language models based on neural networks}.\n"
            },
            {
                "ref_title_clean": "learning longer memory in recurrent neural networks",
                "ref_title_full": "Learning longer memory in recurrent neural networks",
                "year": "2014",
                "full_block": "Learning longer memory in recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "perceptrons",
                "ref_title_full": "Perceptrons",
                "year": "1969",
                "full_block": "{\\em Perceptrons}.\n"
            },
            {
                "ref_title_clean": "a connectionist symbol manipulator that discovers the structure of context free languages",
                "ref_title_full": "A connectionist symbol manipulator that discovers the structure of context free languages",
                "year": "1993",
                "full_block": "A connectionist symbol manipulator that discovers the structure of\n  context-free languages.\n"
            },
            {
                "ref_title_clean": "the induction of dynamical recognizers",
                "ref_title_full": "The induction of dynamical recognizers",
                "year": "1991",
                "full_block": "The induction of dynamical recognizers.\n"
            },
            {
                "ref_title_clean": "hogwild a lock free approach to parallelizing stochastic gradient descent",
                "ref_title_full": "Hogwild: A lock free approach to parallelizing stochastic gradient descent",
                "year": "2011",
                "full_block": "Hogwild: A lock-free approach to parallelizing stochastic gradient\n  descent.\n"
            },
            {
                "ref_title_clean": "a recurrent neural network that learns to count",
                "ref_title_full": "A recurrent neural network that learns to count",
                "year": "1999",
                "full_block": "A recurrent neural network that learns to count.\n"
            },
            {
                "ref_title_clean": "learning internal representations by error propagation",
                "ref_title_full": "Learning internal representations by error propagation",
                "year": "1985",
                "full_block": "Learning internal representations by error propagation.\n"
            },
            {
                "ref_title_clean": "fractal encoding of context free grammars in connectionist networks",
                "ref_title_full": "Fractal encoding of context free grammars in connectionist networks",
                "year": "2000",
                "full_block": "Fractal encoding of context-free grammars in connectionist networks.\n"
            },
            {
                "ref_title_clean": "generalization of backpropagation with application to a recurrent gas market model",
                "ref_title_full": "Generalization of backpropagation with application to a recurrent gas market model",
                "year": "1988",
                "full_block": "Generalization of backpropagation with application to a recurrent gas\n  market model.\n"
            },
            {
                "ref_title_clean": "memory networks",
                "ref_title_full": "Memory networks",
                "year": "2015",
                "full_block": "Memory networks.\n"
            },
            {
                "ref_title_clean": "learning to count without a counter a case study of dynamics and activation landscapes in recurrent networks",
                "ref_title_full": "Learning to count without a counter: A case study of dynamics and activation landscapes in recurrent networks",
                "year": "1995",
                "full_block": "Learning to count without a counter: A case study of dynamics and\n  activation landscapes in recurrent networks.\n"
            },
            {
                "ref_title_clean": "gradient based learning algorithms for recurrent networks and their computational complexity",
                "ref_title_full": "Gradient based learning algorithms for recurrent networks and their computational complexity",
                "year": "1995",
                "full_block": "Gradient-based learning algorithms for recurrent networks and their\n  computational complexity.\n"
            },
            {
                "ref_title_clean": "learning to execute",
                "ref_title_full": "Learning to execute",
                "year": "2014",
                "full_block": "Learning to execute.\n"
            },
            {
                "ref_title_clean": "discrete recurrent neural networks for grammatical inference",
                "ref_title_full": "Discrete recurrent neural networks for grammatical inference",
                "year": "1994",
                "full_block": "Discrete recurrent neural networks for grammatical inference.\n"
            }
        ],
        "refs_source": "unpacked_sources/1503.01007/paper.bbl"
    },
    "neural gpus learn algorithms": {
        "id": "1511.08228",
        "depth": 1,
        "children_titles": [
            "learning regaular sets from queries and counterexamples",
            "url httparxiv",
            "automatic structures",
            "listen attend and spell",
            "url httparxiv",
            "empirical evaluation of gated recurrent neural networks on sequence modeling",
            "url httparxiv",
            "context dependent pre trained deep neural networks for large vocabulary speech recognition",
            "url httparxiv",
            "8 \fpublished as a conference paper at iclr 2016 grefenstette edward hermann karl moritz suleyman mustafa and blunsom learning to transduce with unbounded memory",
            "httparxiv",
            "url httparxiv",
            "dimensions in program synthesis",
            "long short term memory",
            "url httparxiv",
            "url httparxiv",
            "url httparxiv",
            "inductive programming a survey of program synthesis techniques",
            "imagenet classification with deep convolutional neural network",
            "url httparxiv",
            "url httparxiv",
            "url httparxiv",
            "sequence to sequence learning with neural networks",
            "url httparxiv",
            "variable rate image compression with recurrent neural networks",
            "url httparxiv",
            "url httparxiv",
            "url httparxiv",
            "an introduction to cellular automata",
            "bayesian learning via stochastic gradient langevin dynamics",
            "httparxiv",
            "url httparxiv"
        ],
        "status": "expanded",
        "title_full": "Neural gpus learn algorithms",
        "link": "https://arxiv.org/abs/1511.08228",
        "n_parents": 5,
        "year": "2015",
        "children_full_dicts": [
            {
                "ref_title_clean": "learning regaular sets from queries and counterexamples",
                "ref_title_full": "Learning regaular sets from queries and counterexamples",
                "year": "none",
                "full_block": "\nAngluin, Dana. Learning regaular sets from queries and counterexamples. Information and Computation, 75:\n87\u2013106, "
            },
            {
                "ref_title_clean": "url httparxiv",
                "ref_title_full": "URL http://arxiv",
                "year": "none",
                "full_block": "Bahdanau, Dzmitry, Cho, Kyunghyun, and Bengio, Yoshua. Neural machine translation by jointly learning to\nalign and translate. CoRR, abs/1409.0473, 2014. URL http://arxiv.org/abs/1409."
            },
            {
                "ref_title_clean": "automatic structures",
                "ref_title_full": "Automatic Structures",
                "year": "none",
                "full_block": "Blumensath, Achim and Gra\u0308del, Erich. Automatic Structures. In Proceedings of LICS 2000, pp. 51\u201362, "
            },
            {
                "ref_title_clean": "listen attend and spell",
                "ref_title_full": "Listen, attend and spell",
                "year": "none",
                "full_block": "URL http://www.logic.rwth-aachen.de/pub/graedel/BlGr-lics00.ps.\nChan, William, Jaitly, Navdeep, Le, Quoc V., and Vinyals, Oriol. Listen, attend and spell. In International\nConference on Acoustics, Speech and Signal Processing, ICASSP\u201916, "
            },
            {
                "ref_title_clean": "url httparxiv",
                "ref_title_full": "URL http://arxiv",
                "year": "none",
                "full_block": "Cho, Kyunghyun, van Merrienboer, Bart, Gulcehre, Caglar, Bougares, Fethi, Schwenk, Holger, and Bengio,\nYoshua. Learning phrase representations using rnn encoder-decoder for statistical machine translation.\nCoRR, abs/1406.1078, 2014. URL http://arxiv.org/abs/1406."
            },
            {
                "ref_title_clean": "empirical evaluation of gated recurrent neural networks on sequence modeling",
                "ref_title_full": "Empirical evaluation of gated recurrent neural networks on sequence modeling",
                "year": "none",
                "full_block": "Chung, Junyoung, Gu\u0308lc\u0327ehre, C\u0327aglar, Cho, Kyunghyun, and Bengio, Yoshua.\nEmpirical evaluation\nof gated recurrent neural networks on sequence modeling.\nCoRR, abs/1412.3555, "
            },
            {
                "ref_title_clean": "url httparxiv",
                "ref_title_full": "URL http://arxiv",
                "year": "none",
                "full_block": "URL\nhttp://arxiv.org/abs/1412."
            },
            {
                "ref_title_clean": "context dependent pre trained deep neural networks for large vocabulary speech recognition",
                "ref_title_full": "Context dependent pre trained deep neural networks for large vocabulary speech recognition",
                "year": "none",
                "full_block": "Dahl, George E., Yu, Dong, Deng, Li, and Acero, Alex. Context-dependent pre-trained deep neural networks\nfor large-vocabulary speech recognition. IEEE Transactions on Audio, Speech & Language Processing, 20\n(1):30\u201342, "
            },
            {
                "ref_title_clean": "url httparxiv",
                "ref_title_full": "URL http://arxiv",
                "year": "none",
                "full_block": "Graves, Alex, Wayne, Greg, and Danihelka, Ivo. Neural turing machines. CoRR, abs/1410.5401, 2014. URL\nhttp://arxiv.org/abs/1410."
            },
            {
                "ref_title_clean": "8 \fpublished as a conference paper at iclr 2016 grefenstette edward hermann karl moritz suleyman mustafa and blunsom learning to transduce with unbounded memory",
                "ref_title_full": "8 \fPublished as a conference paper at ICLR 2016 Grefenstette, Edward, Hermann, Karl Moritz, Suleyman, Mustafa, and Blunsom, Learning to transduce with unbounded memory",
                "year": "none",
                "full_block": "\n8\n\n\fPublished as a conference paper at ICLR 2016\n\nGrefenstette, Edward, Hermann, Karl Moritz, Suleyman, Mustafa, and Blunsom,\nLearning to transduce with unbounded memory.\nCoRR, abs/1506.02516, "
            },
            {
                "ref_title_clean": "httparxiv",
                "ref_title_full": "http://arxiv",
                "year": "none",
                "full_block": "http://arxiv.org/abs/1506.0"
            },
            {
                "ref_title_clean": "url httparxiv",
                "ref_title_full": "URL http://arxiv",
                "year": "none",
                "full_block": "\nPhil.\nURL\n\nGreff, Klaus, Srivastava, Rupesh Kumar, Koutn\u0131\u0301k, Jan, Steunebrink, Bas R., and Schmidhuber, Ju\u0308rgen. LSTM:\nA search space odyssey. CoRR, abs/1503.04069, 2015. URL http://arxiv.org/abs/1503.0"
            },
            {
                "ref_title_clean": "dimensions in program synthesis",
                "ref_title_full": "Dimensions in program synthesis",
                "year": "none",
                "full_block": "Gulwani, Sumit. Dimensions in program synthesis. In Proceedings of PPDP 2010, PPDP \u201910, pp. 13\u201324, "
            },
            {
                "ref_title_clean": "long short term memory",
                "ref_title_full": "Long short term memory",
                "year": "none",
                "full_block": "Hochreiter, Sepp and Schmidhuber, Ju\u0308rgen. Long short-term memory. Neural computation, 9(8):1735\u20131780,\n"
            },
            {
                "ref_title_clean": "url httparxiv",
                "ref_title_full": "URL http://arxiv",
                "year": "none",
                "full_block": "Joulin, Armand and Mikolov, Tomas. Inferring algorithmic patterns with stack-augmented recurrent nets.\nCoRR, abs/1503.01007, 2015. URL http://arxiv.org/abs/1503.0"
            },
            {
                "ref_title_clean": "url httparxiv",
                "ref_title_full": "URL http://arxiv",
                "year": "none",
                "full_block": "Kaiser, \u0141ukasz. Learning games from videos guided by descriptive complexity. In Proceedings of the AAAI-12,\npp. 963\u2013970. AAAI Press, 2012. URL http://goo.gl/mRbfV5.\nKalchbrenner, Nal and Blunsom, Phil. Recurrent continuous translation models. In Proceedings EMNLP 2013,\npp. 1700\u20131709, 2013. URL http://nal.co/papers/KalchbrennerBlunsom_EMNLP13.\nKalchbrenner, Nal, Danihelka, Ivo, and Graves, Alex. Grid long short-term memory. In International Conference on Learning Representations, 2016. URL http://arxiv.org/abs/1507.0"
            },
            {
                "ref_title_clean": "url httparxiv",
                "ref_title_full": "URL http://arxiv",
                "year": "none",
                "full_block": "Kingma, Diederik P. and Ba, Jimmy. Adam: A method for stochastic optimization. CoRR, abs/1412.6980,\n2014. URL http://arxiv.org/abs/1412."
            },
            {
                "ref_title_clean": "inductive programming a survey of program synthesis techniques",
                "ref_title_full": "Inductive programming: A survey of program synthesis techniques",
                "year": "none",
                "full_block": "Kitzelmann, Emanuel. Inductive programming: A survey of program synthesis techniques. In Approaches and\nApplications of Inductive Programming, AAIP 2009, volume 5812 of LNCS, pp. 50\u201373, "
            },
            {
                "ref_title_clean": "imagenet classification with deep convolutional neural network",
                "ref_title_full": "Imagenet classification with deep convolutional neural network",
                "year": "none",
                "full_block": "Krizhevsky, Alex, Sutskever, Ilya, and Hinton, Geoffrey. Imagenet classification with deep convolutional neural\nnetwork. In Advances in Neural Information Processing Systems, "
            },
            {
                "ref_title_clean": "url httparxiv",
                "ref_title_full": "URL http://arxiv",
                "year": "none",
                "full_block": "Lavin, Andrew and Gray, Scott. Fast algorithms for convolutional neural networks. CoRR, abs/1509.09308,\n2015. URL http://arxiv.org/abs/1509.0"
            },
            {
                "ref_title_clean": "url httparxiv",
                "ref_title_full": "URL http://arxiv",
                "year": "none",
                "full_block": "Pham, Vu, Bluche, The\u0301odore, Kermorvant, Christopher, and Louradour, Je\u0301ro\u0302me. Dropout improves recurrent neural networks for handwriting recognition. In International Conference on Frontiers in Handwriting\nRecognition (ICFHR), pp. 285\u2013290. IEEE, 2014. URL http://arxiv.org/pdf/1312.4569.pdf.\nShi, Xingjian, Chen, Zhourong, Wang, Hao, Yeung, Dit-Yan, kin Wong, Wai, and chun Woo, Wang. Convolutional LSTM network: A machine learning approach for precipitation nowcasting. In Advances in Neural\nInformation Processing Systems, 2015. URL http://arxiv.org/abs/1506.0"
            },
            {
                "ref_title_clean": "url httparxiv",
                "ref_title_full": "URL http://arxiv",
                "year": "none",
                "full_block": "Srivastava, Rupesh Kumar, Greff, Klaus, and Schmidhuber, Ju\u0308rgen.\nHighway networks.\nabs/1505.00387, 2015. URL http://arxiv.org/abs/1505.0"
            },
            {
                "ref_title_clean": "sequence to sequence learning with neural networks",
                "ref_title_full": "Sequence to sequence learning with neural networks",
                "year": "none",
                "full_block": "\nCoRR,\n\nSutskever, Ilya, Vinyals, Oriol, and Le, Quoc VV. Sequence to sequence learning with neural networks.\nIn Advances in Neural Information Processing Systems, pp. 3104\u20133112, "
            },
            {
                "ref_title_clean": "url httparxiv",
                "ref_title_full": "URL http://arxiv",
                "year": "none",
                "full_block": "URL\nhttp://arxiv.org/abs/1409."
            },
            {
                "ref_title_clean": "variable rate image compression with recurrent neural networks",
                "ref_title_full": "Variable rate image compression with recurrent neural networks",
                "year": "none",
                "full_block": "Toderici, George, O\u2019Malley, Sean M., Hwang, Sung Jin, Vincent, Damien, Minnen, David, Baluja,\nShumeet, Covell, Michele, and Sukthankar, Rahul. Variable rate image compression with recurrent neural networks.\nIn International Conference on Learning Representations, "
            },
            {
                "ref_title_clean": "url httparxiv",
                "ref_title_full": "URL http://arxiv",
                "year": "none",
                "full_block": "URL\nhttp://arxiv.org/abs/1511.0"
            },
            {
                "ref_title_clean": "url httparxiv",
                "ref_title_full": "URL http://arxiv",
                "year": "none",
                "full_block": "Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In Advances in Neural\nInformation Processing Systems, 2015. URL http://arxiv.org/abs/1412."
            },
            {
                "ref_title_clean": "url httparxiv",
                "ref_title_full": "URL http://arxiv",
                "year": "none",
                "full_block": "Vinyals, Oriol, Toshev, Alexander, Bengio, Samy, and Erhan, Dumitru. Show and tell: A neural image caption\ngenerator. CoRR, abs/1411.4555, 2014. URL http://arxiv.org/abs/1411."
            },
            {
                "ref_title_clean": "an introduction to cellular automata",
                "ref_title_full": "An Introduction to cellular automata",
                "year": "none",
                "full_block": "Vivien,\nHelene.\nAn Introduction to cellular automata.\n"
            },
            {
                "ref_title_clean": "bayesian learning via stochastic gradient langevin dynamics",
                "ref_title_full": "Bayesian learning via stochastic gradient Langevin dynamics",
                "year": "none",
                "full_block": "URL\nhttp://www.liafa.univ-paris-diderot.fr/\u02dcyunes/ca/archives/bookvivien.pdf.\nWelling, Max and Teh, Yee Whye. Bayesian learning via stochastic gradient Langevin dynamics. In Proceedings of ICML 2011, pp. 681\u2013688, "
            },
            {
                "ref_title_clean": "httparxiv",
                "ref_title_full": "http://arxiv",
                "year": "none",
                "full_block": "Zaremba, Wojciech and Sutskever, Ilya. Learning to execute.\nhttp://arxiv.org/abs/1410."
            },
            {
                "ref_title_clean": "url httparxiv",
                "ref_title_full": "URL http://arxiv",
                "year": "none",
                "full_block": "\nCoRR, abs/1410.4615, 2015a.\n\nZaremba, Wojciech and Sutskever, Ilya.\nReinforcement learning neural turing machines.\nabs/1505.00521, 2015b. URL http://arxiv.org/abs/1505.0"
            }
        ],
        "refs_source": "from_pdf"
    },
    "neural random access machines": {
        "id": "1511.06392",
        "depth": 1,
        "children_titles": [
            "neural machine translation by jointly learning to align and translate",
            "learning long term dependencies with gradient descent is difficult",
            "curriculum learning",
            "listen attend and spell",
            "neural turing machines",
            "learning to transduce with unbounded memory",
            "long short term memory",
            "inferring algorithmic patterns with stack augmented recurrent nets",
            "grid long short term memory",
            "adam a method for stochastic optimization",
            "effective approaches to attention based neural machine translation",
            "rectified linear units improve restricted boltzmann machines",
            "adding gradient noise improves learning for very deep networks",
            "a formal theory of inductive inference part i",
            "end to end memory networks",
            "grammar as a foreign language",
            "pointer networks",
            "memory networks",
            "learning to execute",
            "reinforcement learning neural turing machines"
        ],
        "status": "expanded",
        "title_full": "Neural random access machines",
        "link": "https://arxiv.org/abs/1511.06392",
        "n_parents": 6,
        "year": "2016",
        "children_full_dicts": [
            {
                "ref_title_clean": "neural machine translation by jointly learning to align and translate",
                "ref_title_full": "Neural machine translation by jointly learning to align and translate",
                "year": "2014",
                "full_block": "Neural machine translation by jointly learning to align and\n  translate.\n"
            },
            {
                "ref_title_clean": "learning long term dependencies with gradient descent is difficult",
                "ref_title_full": "Learning long term dependencies with gradient descent is difficult",
                "year": "1994",
                "full_block": "Learning long-term dependencies with gradient descent is difficult.\n"
            },
            {
                "ref_title_clean": "curriculum learning",
                "ref_title_full": "Curriculum learning",
                "year": "2009",
                "full_block": "Curriculum learning.\n"
            },
            {
                "ref_title_clean": "listen attend and spell",
                "ref_title_full": "Listen, attend and spell",
                "year": "2015",
                "full_block": "Listen, attend and spell.\n"
            },
            {
                "ref_title_clean": "neural turing machines",
                "ref_title_full": "Neural turing machines",
                "year": "2014",
                "full_block": "Neural turing machines.\n"
            },
            {
                "ref_title_clean": "learning to transduce with unbounded memory",
                "ref_title_full": "Learning to transduce with unbounded memory",
                "year": "2015",
                "full_block": "Learning to transduce with unbounded memory.\n"
            },
            {
                "ref_title_clean": "long short term memory",
                "ref_title_full": "Long short term memory",
                "year": "1997",
                "full_block": "Long short-term memory.\n"
            },
            {
                "ref_title_clean": "inferring algorithmic patterns with stack augmented recurrent nets",
                "ref_title_full": "Inferring algorithmic patterns with stack augmented recurrent nets",
                "year": "2015",
                "full_block": "Inferring algorithmic patterns with stack-augmented recurrent nets.\n"
            },
            {
                "ref_title_clean": "grid long short term memory",
                "ref_title_full": "Grid long short term memory",
                "year": "2015",
                "full_block": "Grid long short-term memory.\n"
            },
            {
                "ref_title_clean": "adam a method for stochastic optimization",
                "ref_title_full": "Adam: A method for stochastic optimization",
                "year": "2014",
                "full_block": "Adam: A method for stochastic optimization.\n"
            },
            {
                "ref_title_clean": "effective approaches to attention based neural machine translation",
                "ref_title_full": "Effective approaches to attention based neural machine translation",
                "year": "2015",
                "full_block": "Effective approaches to attention-based neural machine translation.\n"
            },
            {
                "ref_title_clean": "rectified linear units improve restricted boltzmann machines",
                "ref_title_full": "Rectified linear units improve restricted boltzmann machines",
                "year": "2010",
                "full_block": "Rectified linear units improve restricted boltzmann machines.\n"
            },
            {
                "ref_title_clean": "adding gradient noise improves learning for very deep networks",
                "ref_title_full": "Adding gradient noise improves learning for very deep networks",
                "year": "2015",
                "full_block": "Adding gradient noise improves learning for very deep networks.\n"
            },
            {
                "ref_title_clean": "a formal theory of inductive inference part i",
                "ref_title_full": "A formal theory of inductive inference. part i",
                "year": "1964",
                "full_block": "A formal theory of inductive inference. part i.\n"
            },
            {
                "ref_title_clean": "end to end memory networks",
                "ref_title_full": "End to end memory networks",
                "year": "2015",
                "full_block": "End-to-end memory networks.\n"
            },
            {
                "ref_title_clean": "grammar as a foreign language",
                "ref_title_full": "Grammar as a foreign language",
                "year": "2014",
                "full_block": "Grammar as a foreign language.\n"
            },
            {
                "ref_title_clean": "pointer networks",
                "ref_title_full": "Pointer networks",
                "year": "2015",
                "full_block": "Pointer networks.\n"
            },
            {
                "ref_title_clean": "memory networks",
                "ref_title_full": "Memory networks",
                "year": "2014",
                "full_block": "Memory networks.\n"
            },
            {
                "ref_title_clean": "learning to execute",
                "ref_title_full": "Learning to execute",
                "year": "2014",
                "full_block": "Learning to execute.\n"
            },
            {
                "ref_title_clean": "reinforcement learning neural turing machines",
                "ref_title_full": "Reinforcement learning neural turing machines",
                "year": "2015",
                "full_block": "Reinforcement learning neural turing machines.\n"
            }
        ],
        "refs_source": "unpacked_sources/1511.06392/paper.bbl"
    },
    "effective approaches to attention based neural machine translation": {
        "id": "1508.04025",
        "depth": 1,
        "children_titles": [
            "neural machine translation by jointly learning to align and translate",
            "n gram counts and language models from the common crawl",
            "learning phrase representations using rnn encoder decoder for statistical machine translation",
            "measuring word alignment quality for statistical machine translation",
            "draw a recurrent neural network for image generation",
            "on using very large target vocabulary for neural machine translation",
            "recurrent continuous translation models",
            "statistical phrase based translation",
            "alignment by agreement",
            "addressing the rare word problem in neural machine translation",
            "recurrent models of visual attention",
            "bleu a method for automatic evaluation of machine translation",
            "sequence to sequence learning with neural networks",
            "show attend and tell neural image caption generation with visual attention",
            "recurrent neural network regularization"
        ],
        "status": "expanded",
        "title_full": "Effective approaches to attention based neural machine translation",
        "link": "https://arxiv.org/abs/1508.04025",
        "n_parents": 2,
        "year": "2015",
        "children_full_dicts": [
            {
                "ref_title_clean": "neural machine translation by jointly learning to align and translate",
                "ref_title_full": "Neural machine translation by jointly learning to align and translate",
                "year": "none",
                "full_block": "Neural machine translation by jointly learning to align and\n  translate.\n"
            },
            {
                "ref_title_clean": "n gram counts and language models from the common crawl",
                "ref_title_full": "N gram counts and language models from the common crawl",
                "year": "none",
                "full_block": "N-gram counts and language models from the common crawl.\n"
            },
            {
                "ref_title_clean": "learning phrase representations using rnn encoder decoder for statistical machine translation",
                "ref_title_full": "Learning phrase representations using RNN encoder decoder for statistical machine translation",
                "year": "none",
                "full_block": "Learning phrase representations using {RNN} encoder-decoder for\n  statistical machine translation.\n"
            },
            {
                "ref_title_clean": "measuring word alignment quality for statistical machine translation",
                "ref_title_full": "Measuring word alignment quality for statistical machine translation",
                "year": "none",
                "full_block": "Measuring word alignment quality for statistical machine translation.\n"
            },
            {
                "ref_title_clean": "draw a recurrent neural network for image generation",
                "ref_title_full": "DRAW: A recurrent neural network for image generation",
                "year": "none",
                "full_block": "{DRAW:} {A} recurrent neural network for image generation.\n"
            },
            {
                "ref_title_clean": "on using very large target vocabulary for neural machine translation",
                "ref_title_full": "On using very large target vocabulary for neural machine translation",
                "year": "none",
                "full_block": "On using very large target vocabulary for neural machine translation.\n"
            },
            {
                "ref_title_clean": "recurrent continuous translation models",
                "ref_title_full": "Recurrent continuous translation models",
                "year": "none",
                "full_block": "Recurrent continuous translation models.\n"
            },
            {
                "ref_title_clean": "statistical phrase based translation",
                "ref_title_full": "Statistical phrase based translation",
                "year": "none",
                "full_block": "Statistical phrase-based translation.\n"
            },
            {
                "ref_title_clean": "alignment by agreement",
                "ref_title_full": "Alignment by agreement",
                "year": "none",
                "full_block": "Alignment by agreement.\n"
            },
            {
                "ref_title_clean": "addressing the rare word problem in neural machine translation",
                "ref_title_full": "Addressing the rare word problem in neural machine translation",
                "year": "none",
                "full_block": "Addressing the rare word problem in neural machine translation.\n"
            },
            {
                "ref_title_clean": "recurrent models of visual attention",
                "ref_title_full": "Recurrent models of visual attention",
                "year": "none",
                "full_block": "Recurrent models of visual attention.\n"
            },
            {
                "ref_title_clean": "bleu a method for automatic evaluation of machine translation",
                "ref_title_full": "Bleu: a method for automatic evaluation of machine translation",
                "year": "none",
                "full_block": "Bleu: a method for automatic evaluation of machine translation.\n"
            },
            {
                "ref_title_clean": "sequence to sequence learning with neural networks",
                "ref_title_full": "Sequence to sequence learning with neural networks",
                "year": "none",
                "full_block": "Sequence to sequence learning with neural networks.\n"
            },
            {
                "ref_title_clean": "show attend and tell neural image caption generation with visual attention",
                "ref_title_full": "Show, attend and tell: Neural image caption generation with visual attention",
                "year": "none",
                "full_block": "Show, attend and tell: Neural image caption generation with visual\n  attention.\n"
            },
            {
                "ref_title_clean": "recurrent neural network regularization",
                "ref_title_full": "Recurrent neural network regularization",
                "year": "none",
                "full_block": "Recurrent neural network regularization.\n"
            }
        ],
        "refs_source": "unpacked_sources/1508.04025/emnlp15.bbl"
    },
    "knowledge and reasoning in program synthesis": {
        "id": null,
        "depth": 1,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Knowledge and reasoning in program synthesis",
        "link": "none",
        "n_parents": 1,
        "year": "1975"
    },
    "a deductive approach to program synthesis": {
        "id": null,
        "depth": 1,
        "children_titles": [],
        "status": "no_id",
        "title_full": "A deductive approach to program synthesis",
        "link": "none",
        "n_parents": 1,
        "year": "1980"
    },
    "computation of normalized edit distance and applications": {
        "id": null,
        "depth": 1,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Computation of normalized edit distance and applications",
        "link": "none",
        "n_parents": 1,
        "year": "1993"
    },
    "a machine learning framework for programming by example": {
        "id": null,
        "depth": 1,
        "children_titles": [],
        "status": "no_id",
        "title_full": "A machine learning framework for programming by example",
        "link": "none",
        "n_parents": 3,
        "year": "2013"
    },
    "neural programmer inducing latent programs with gradient descent": {
        "id": "1511.04834",
        "depth": 1,
        "children_titles": [
            "learning to compose neural networks for question answering",
            "neural machine translation by jointly learning to align and translate",
            "end to end attention based large vocabulary speech recognition",
            "question answering with subgraph embeddings",
            "functional imaging of numerical processing in adults and 4 y old children",
            "listen attend and spell",
            "driving semantic parsing from the worlds response",
            "learning context free grammars capabilities and limitations of a recurrent neural network with an external stack memory",
            "using prior knowledge in an nnpda to learn context free languages",
            "numerical processing in the human parietal cortex during experimental and natural conditions",
            "reading to learn constructing features from semantic abstracts",
            "processing of abstract ordinal knowledge in the horizontal segment of the intraparietal sulcus",
            "lstm recurrent networks learn simple context free and context sensitive languages",
            "generating sequences with recurrent neural networks",
            "towards end to end speech recognition with recurrent neural networks",
            "neural turing machines",
            "deep speech scaling up end to end speech recognition",
            "teaching machines to read and comprehend",
            "deep neural networks for acoustic modeling in speech recognition",
            "long short term memory",
            "robust estimation of a location parameter",
            "a neural network for factoid question answering over paragraphs",
            "inferring algorithmic patterns with stack augmented recurrent nets",
            "adam a method for stochastic optimization",
            "imagenet classification with deep convolutional neural networks",
            "impaired neural networks for approximate calculation in dyscalculic children a functional mri study",
            "ask me anything dynamic memory networks for natural language processing",
            "learning programs a hierarchical bayesian approach",
            "learning dependency based compositional semantics",
            "modeling relation paths for representation learning of knowledge bases",
            "addressing the rare word problem in neural machine translation",
            "compositional vector space models for knowledge base completion",
            "adding gradient noise improves learning for very deep networks",
            "compositional semantic parsing on semi structured tables",
            "towards neural network based reasoning",
            "a bayesian model of the acquisition of compositional semantics",
            "tuning curves for approximate numerosity in the human intraparietal sulcus",
            "grounded unsupervised semantic parsing",
            "neural programmer interpreters",
            "a self referentialweight matrix",
            "neural responding machine for short text conversation",
            "a recurrent network that performs a context sensitive prediction task",
            "end to end memory networks",
            "sequence to sequence learning with neural networks",
            "a neural conversational model",
            "show and tell a neural image caption generator",
            "first draft of a report on the edvac",
            "building a semantic parser overnight",
            "bayesian learning via stochastic gradient langevin dynamics",
            "backpropagation through time what does it do and how to do it",
            "memory networks",
            "show attend and tell neural image caption generation with visual attention",
            "neural enquirer learning to query tables with natural language",
            "learning to parse database queries using inductive logic programming",
            "discrete recurrent neural networks for grammatical inference",
            "learning to map sentences to logical form structured classification with probabilistic categorial grammars"
        ],
        "status": "expanded",
        "title_full": "Neural programmer: Inducing latent programs with gradient descent",
        "link": "https://arxiv.org/abs/1511.04834",
        "n_parents": 6,
        "year": "2016",
        "children_full_dicts": [
            {
                "ref_title_clean": "learning to compose neural networks for question answering",
                "ref_title_full": "Learning to compose neural networks for question answering",
                "year": "2016",
                "full_block": "Learning to compose neural networks for question answering.\n"
            },
            {
                "ref_title_clean": "neural machine translation by jointly learning to align and translate",
                "ref_title_full": "Neural machine translation by jointly learning to align and translate",
                "year": "2014",
                "full_block": "Neural machine translation by jointly learning to align and\n  translate.\n"
            },
            {
                "ref_title_clean": "end to end attention based large vocabulary speech recognition",
                "ref_title_full": "End to end attention based large vocabulary speech recognition",
                "year": "2015",
                "full_block": "End-to-end attention-based large vocabulary speech recognition.\n"
            },
            {
                "ref_title_clean": "question answering with subgraph embeddings",
                "ref_title_full": "Question answering with subgraph embeddings",
                "year": "2014",
                "full_block": "Question answering with subgraph embeddings.\n"
            },
            {
                "ref_title_clean": "functional imaging of numerical processing in adults and 4 y old children",
                "ref_title_full": "Functional imaging of numerical processing in adults and 4 y old children",
                "year": "2006",
                "full_block": "Functional imaging of numerical processing in adults and 4-y-old\n  children.\n"
            },
            {
                "ref_title_clean": "listen attend and spell",
                "ref_title_full": "Listen, attend and spell",
                "year": "2015",
                "full_block": "Listen, attend and spell.\n"
            },
            {
                "ref_title_clean": "driving semantic parsing from the worlds response",
                "ref_title_full": "Driving semantic parsing from the world's response",
                "year": "2010",
                "full_block": "Driving semantic parsing from the world's response.\n"
            },
            {
                "ref_title_clean": "learning context free grammars capabilities and limitations of a recurrent neural network with an external stack memory",
                "ref_title_full": "Learning context free grammars: Capabilities and limitations of a recurrent neural network with an external stack memory",
                "year": "none",
                "full_block": "Learning context-free grammars: Capabilities and limitations of a\n  recurrent neural network with an external stack memory.\n"
            },
            {
                "ref_title_clean": "using prior knowledge in an nnpda to learn context free languages",
                "ref_title_full": "Using prior knowledge in an NNPDA to learn context free languages",
                "year": "none",
                "full_block": "Using prior knowledge in an {NNPDA} to learn context-free languages.\n"
            },
            {
                "ref_title_clean": "numerical processing in the human parietal cortex during experimental and natural conditions",
                "ref_title_full": "Numerical processing in the human parietal cortex during experimental and natural conditions",
                "year": "2013",
                "full_block": "Numerical processing in the human parietal cortex during experimental\n  and natural conditions.\n"
            },
            {
                "ref_title_clean": "reading to learn constructing features from semantic abstracts",
                "ref_title_full": "Reading to learn: Constructing features from semantic abstracts",
                "year": "2009",
                "full_block": "Reading to learn: Constructing features from semantic abstracts.\n"
            },
            {
                "ref_title_clean": "processing of abstract ordinal knowledge in the horizontal segment of the intraparietal sulcus",
                "ref_title_full": "Processing of abstract ordinal knowledge in the horizontal segment of the intraparietal sulcus",
                "year": "2007",
                "full_block": "Processing of abstract ordinal knowledge in the horizontal segment of\n  the intraparietal sulcus.\n"
            },
            {
                "ref_title_clean": "lstm recurrent networks learn simple context free and context sensitive languages",
                "ref_title_full": "LSTM recurrent networks learn simple context free and context sensitive languages",
                "year": "2001",
                "full_block": "{LSTM} recurrent networks learn simple context free and context\n  sensitive languages.\n"
            },
            {
                "ref_title_clean": "generating sequences with recurrent neural networks",
                "ref_title_full": "Generating sequences with recurrent neural networks",
                "year": "2013",
                "full_block": "Generating sequences with recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "towards end to end speech recognition with recurrent neural networks",
                "ref_title_full": "Towards end to end speech recognition with recurrent neural networks",
                "year": "2014",
                "full_block": "Towards end-to-end speech recognition with recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "neural turing machines",
                "ref_title_full": "Neural Turing Machines",
                "year": "2014",
                "full_block": "Neural {T}uring {M}achines.\n"
            },
            {
                "ref_title_clean": "deep speech scaling up end to end speech recognition",
                "ref_title_full": "Deep Speech: Scaling up end to end speech recognition",
                "year": "2014",
                "full_block": "Deep {S}peech: Scaling up end-to-end speech recognition.\n"
            },
            {
                "ref_title_clean": "teaching machines to read and comprehend",
                "ref_title_full": "Teaching machines to read and comprehend",
                "year": "2015",
                "full_block": "Teaching machines to read and comprehend.\n"
            },
            {
                "ref_title_clean": "deep neural networks for acoustic modeling in speech recognition",
                "ref_title_full": "Deep neural networks for acoustic modeling in speech recognition",
                "year": "2012",
                "full_block": "Deep neural networks for acoustic modeling in speech recognition.\n"
            },
            {
                "ref_title_clean": "long short term memory",
                "ref_title_full": "Long short term memory",
                "year": "1997",
                "full_block": "Long short-term memory.\n"
            },
            {
                "ref_title_clean": "robust estimation of a location parameter",
                "ref_title_full": "Robust estimation of a location parameter",
                "year": "1964",
                "full_block": "Robust estimation of a location parameter.\n"
            },
            {
                "ref_title_clean": "a neural network for factoid question answering over paragraphs",
                "ref_title_full": "A neural network for factoid question answering over paragraphs",
                "year": "2014",
                "full_block": "A neural network for factoid question answering over paragraphs.\n"
            },
            {
                "ref_title_clean": "inferring algorithmic patterns with stack augmented recurrent nets",
                "ref_title_full": "Inferring algorithmic patterns with stack augmented recurrent nets",
                "year": "2015",
                "full_block": "Inferring algorithmic patterns with stack-augmented recurrent nets.\n"
            },
            {
                "ref_title_clean": "adam a method for stochastic optimization",
                "ref_title_full": "Adam: A method for stochastic optimization",
                "year": "2014",
                "full_block": "Adam: A method for stochastic optimization.\n"
            },
            {
                "ref_title_clean": "imagenet classification with deep convolutional neural networks",
                "ref_title_full": "Imagenet classification with deep convolutional neural networks",
                "year": "2012",
                "full_block": "Imagenet classification with deep convolutional neural networks.\n"
            },
            {
                "ref_title_clean": "impaired neural networks for approximate calculation in dyscalculic children a functional mri study",
                "ref_title_full": "Impaired neural networks for approximate calculation in dyscalculic children: a functional mri study",
                "year": "2006",
                "full_block": "Impaired neural networks for approximate calculation in dyscalculic\n  children: a functional mri study.\n"
            },
            {
                "ref_title_clean": "ask me anything dynamic memory networks for natural language processing",
                "ref_title_full": "Ask me anything: Dynamic memory networks for natural language processing",
                "year": "2015",
                "full_block": "Ask me anything: Dynamic memory networks for natural language\n  processing.\n"
            },
            {
                "ref_title_clean": "learning programs a hierarchical bayesian approach",
                "ref_title_full": "Learning programs: A hierarchical Bayesian approach",
                "year": "2010",
                "full_block": "Learning programs: A hierarchical {B}ayesian approach.\n"
            },
            {
                "ref_title_clean": "learning dependency based compositional semantics",
                "ref_title_full": "Learning dependency based compositional semantics",
                "year": "2011",
                "full_block": "Learning dependency-based compositional semantics.\n"
            },
            {
                "ref_title_clean": "modeling relation paths for representation learning of knowledge bases",
                "ref_title_full": "Modeling relation paths for representation learning of knowledge bases",
                "year": "2015",
                "full_block": "Modeling relation paths for representation learning of knowledge\n  bases.\n"
            },
            {
                "ref_title_clean": "addressing the rare word problem in neural machine translation",
                "ref_title_full": "Addressing the rare word problem in neural machine translation",
                "year": "2014",
                "full_block": "Addressing the rare word problem in neural machine translation.\n"
            },
            {
                "ref_title_clean": "compositional vector space models for knowledge base completion",
                "ref_title_full": "Compositional vector space models for knowledge base completion",
                "year": "2015",
                "full_block": "Compositional vector space models for knowledge base completion.\n"
            },
            {
                "ref_title_clean": "adding gradient noise improves learning for very deep networks",
                "ref_title_full": "Adding gradient noise improves learning for very deep networks",
                "year": "2016",
                "full_block": "Adding gradient noise improves learning for very deep networks.\n"
            },
            {
                "ref_title_clean": "compositional semantic parsing on semi structured tables",
                "ref_title_full": "Compositional semantic parsing on semi structured tables",
                "year": "2015",
                "full_block": "Compositional semantic parsing on semi-structured tables.\n"
            },
            {
                "ref_title_clean": "towards neural network based reasoning",
                "ref_title_full": "Towards neural network based reasoning",
                "year": "2015",
                "full_block": "Towards neural network-based reasoning.\n"
            },
            {
                "ref_title_clean": "a bayesian model of the acquisition of compositional semantics",
                "ref_title_full": "A Bayesian model of the acquisition of compositional semantics",
                "year": "2008",
                "full_block": "A {B}ayesian model of the acquisition of compositional semantics.\n"
            },
            {
                "ref_title_clean": "tuning curves for approximate numerosity in the human intraparietal sulcus",
                "ref_title_full": "Tuning curves for approximate numerosity in the human intraparietal sulcus",
                "year": "2004",
                "full_block": "Tuning curves for approximate numerosity in the human intraparietal\n  sulcus.\n"
            },
            {
                "ref_title_clean": "grounded unsupervised semantic parsing",
                "ref_title_full": "Grounded unsupervised semantic parsing",
                "year": "2013",
                "full_block": "Grounded unsupervised semantic parsing.\n"
            },
            {
                "ref_title_clean": "neural programmer interpreters",
                "ref_title_full": "Neural programmer interpreters",
                "year": "2016",
                "full_block": "Neural programmer-interpreters.\n"
            },
            {
                "ref_title_clean": "a self referentialweight matrix",
                "ref_title_full": "A self referentialweight matrix",
                "year": "1993",
                "full_block": "A self-referentialweight matrix.\n"
            },
            {
                "ref_title_clean": "neural responding machine for short text conversation",
                "ref_title_full": "Neural responding machine for short text conversation",
                "year": "2015",
                "full_block": "Neural responding machine for short-text conversation.\n"
            },
            {
                "ref_title_clean": "a recurrent network that performs a context sensitive prediction task",
                "ref_title_full": "A recurrent network that performs a context sensitive prediction task",
                "year": "1996",
                "full_block": "A recurrent network that performs a context-sensitive prediction\n  task.\n"
            },
            {
                "ref_title_clean": "end to end memory networks",
                "ref_title_full": "End to end memory networks",
                "year": "2015",
                "full_block": "End-to-end memory networks.\n"
            },
            {
                "ref_title_clean": "sequence to sequence learning with neural networks",
                "ref_title_full": "Sequence to sequence learning with neural networks",
                "year": "2014",
                "full_block": "Sequence to sequence learning with neural networks.\n"
            },
            {
                "ref_title_clean": "a neural conversational model",
                "ref_title_full": "A neural conversational model",
                "year": "2015",
                "full_block": "A neural conversational model.\n"
            },
            {
                "ref_title_clean": "show and tell a neural image caption generator",
                "ref_title_full": "Show and tell: A neural image caption generator",
                "year": "2015",
                "full_block": "Show and tell: A neural image caption generator.\n"
            },
            {
                "ref_title_clean": "first draft of a report on the edvac",
                "ref_title_full": "First draft of a report on the EDVAC",
                "year": "1945",
                "full_block": "First draft of a report on the {EDVAC}.\n"
            },
            {
                "ref_title_clean": "building a semantic parser overnight",
                "ref_title_full": "Building a semantic parser overnight",
                "year": "2015",
                "full_block": "Building a semantic parser overnight.\n"
            },
            {
                "ref_title_clean": "bayesian learning via stochastic gradient langevin dynamics",
                "ref_title_full": "Bayesian learning via stochastic gradient Langevin dynamics",
                "year": "2011",
                "full_block": "Bayesian learning via stochastic gradient {L}angevin dynamics.\n"
            },
            {
                "ref_title_clean": "backpropagation through time what does it do and how to do it",
                "ref_title_full": "Backpropagation through time: what does it do and how to do it",
                "year": "1990",
                "full_block": "Backpropagation through time: what does it do and how to do it.\n"
            },
            {
                "ref_title_clean": "memory networks",
                "ref_title_full": "Memory Networks",
                "year": "none",
                "full_block": "Memory {N}etworks.\n"
            },
            {
                "ref_title_clean": "show attend and tell neural image caption generation with visual attention",
                "ref_title_full": "Show, attend and tell: Neural image caption generation with visual attention",
                "year": "2015",
                "full_block": "Show, attend and tell: Neural image caption generation with visual\n  attention.\n"
            },
            {
                "ref_title_clean": "neural enquirer learning to query tables with natural language",
                "ref_title_full": "Neural enquirer: Learning to query tables with natural language",
                "year": "2015",
                "full_block": "Neural enquirer: Learning to query tables with natural language.\n"
            },
            {
                "ref_title_clean": "learning to parse database queries using inductive logic programming",
                "ref_title_full": "Learning to parse database queries using inductive logic programming",
                "year": "1996",
                "full_block": "Learning to parse database queries using inductive logic programming.\n"
            },
            {
                "ref_title_clean": "discrete recurrent neural networks for grammatical inference",
                "ref_title_full": "Discrete recurrent neural networks for grammatical inference",
                "year": "1994",
                "full_block": "Discrete recurrent neural networks for grammatical inference.\n"
            },
            {
                "ref_title_clean": "learning to map sentences to logical form structured classification with probabilistic categorial grammars",
                "ref_title_full": "Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars",
                "year": "2005",
                "full_block": "Learning to map sentences to logical form: Structured classification\n  with probabilistic categorial grammars.\n"
            }
        ],
        "refs_source": "unpacked_sources/1511.04834/neural_programmer.bbl"
    },
    "neuro symbolic program synthesis": {
        "id": "1611.01855",
        "depth": 1,
        "children_titles": [
            "syntax guided synthesis",
            "phog probabilistic model for code",
            "the inference of regular lisp programs from examples",
            "adaptive neural compilation",
            "terpret a probabilistic programming language for program induction",
            "neural turing machines",
            "automating string processing in spreadsheets using input output examples",
            "synthesis of loop free programs",
            "spreadsheet data manipulation using examples",
            "on the naturalness of software",
            "bidirectional recursive neural networks for token level labeling with structure",
            "inferring algorithmic patterns with stack augmented recurrent nets",
            "neural random access machines",
            "the inside outside recursive neural network model for dependency parsing",
            "learning programs a hierarchical bayesian approach",
            "structured generative models of natural source code",
            "a machine learning framework for programming by example",
            "neural programmer inducing latent programs with gradient descent",
            "global belief recursive neural networks",
            "predicting program properties from big code",
            "neural programmer interpreters",
            "programming with a differentiable forth interpreter",
            "stochastic superoptimization",
            "synthesizing data structure manipulations from storyboards",
            "automated feedback generation for introductory programming assignments",
            "program synthesis by sketching",
            "programming by sketching for bit streaming programs",
            "a methodology for lisp program construction from examples",
            "transit specifying protocols with concolic snippets",
            "grammar as a foreign language"
        ],
        "status": "expanded",
        "title_full": "Neuro symbolic program synthesis",
        "link": "https://arxiv.org/abs/1611.01855",
        "n_parents": 1,
        "year": "2017",
        "children_full_dicts": [
            {
                "ref_title_clean": "syntax guided synthesis",
                "ref_title_full": "Syntax guided synthesis",
                "year": "2015",
                "full_block": "Syntax-guided synthesis.\n"
            },
            {
                "ref_title_clean": "phog probabilistic model for code",
                "ref_title_full": "PHOG: probabilistic model for code",
                "year": "2016",
                "full_block": "{PHOG:} probabilistic model for code.\n"
            },
            {
                "ref_title_clean": "the inference of regular lisp programs from examples",
                "ref_title_full": "The inference of regular lisp programs from examples",
                "year": "1978",
                "full_block": "The inference of regular lisp programs from examples.\n"
            },
            {
                "ref_title_clean": "adaptive neural compilation",
                "ref_title_full": "Adaptive neural compilation",
                "year": "2016",
                "full_block": "Adaptive neural compilation.\n"
            },
            {
                "ref_title_clean": "terpret a probabilistic programming language for program induction",
                "ref_title_full": "Terpret: A probabilistic programming language for program induction",
                "year": "2016",
                "full_block": "Terpret: A probabilistic programming language for program induction.\n"
            },
            {
                "ref_title_clean": "neural turing machines",
                "ref_title_full": "Neural turing machines",
                "year": "2014",
                "full_block": "Neural turing machines.\n"
            },
            {
                "ref_title_clean": "automating string processing in spreadsheets using input output examples",
                "ref_title_full": "Automating string processing in spreadsheets using input output examples",
                "year": "2011",
                "full_block": "Automating string processing in spreadsheets using input-output\n  examples.\n"
            },
            {
                "ref_title_clean": "synthesis of loop free programs",
                "ref_title_full": "Synthesis of loop free programs",
                "year": "2011",
                "full_block": "Synthesis of loop-free programs.\n"
            },
            {
                "ref_title_clean": "spreadsheet data manipulation using examples",
                "ref_title_full": "Spreadsheet data manipulation using examples",
                "year": "2012",
                "full_block": "Spreadsheet data manipulation using examples.\n"
            },
            {
                "ref_title_clean": "on the naturalness of software",
                "ref_title_full": "On the naturalness of software",
                "year": "2016",
                "full_block": "On the naturalness of software.\n"
            },
            {
                "ref_title_clean": "bidirectional recursive neural networks for token level labeling with structure",
                "ref_title_full": "Bidirectional recursive neural networks for token level labeling with structure",
                "year": "2013",
                "full_block": "Bidirectional recursive neural networks for token-level labeling with\n  structure.\n"
            },
            {
                "ref_title_clean": "inferring algorithmic patterns with stack augmented recurrent nets",
                "ref_title_full": "Inferring algorithmic patterns with stack augmented recurrent nets",
                "year": "2015",
                "full_block": "Inferring algorithmic patterns with stack-augmented recurrent nets.\n"
            },
            {
                "ref_title_clean": "neural random access machines",
                "ref_title_full": "Neural random access machines",
                "year": "2015",
                "full_block": "Neural random-access machines.\n"
            },
            {
                "ref_title_clean": "the inside outside recursive neural network model for dependency parsing",
                "ref_title_full": "The inside outside recursive neural network model for dependency parsing",
                "year": "2014",
                "full_block": "The inside-outside recursive neural network model for dependency\n  parsing.\n"
            },
            {
                "ref_title_clean": "learning programs a hierarchical bayesian approach",
                "ref_title_full": "Learning programs: A hierarchical Bayesian approach",
                "year": "2010",
                "full_block": "Learning programs: A hierarchical {Bayesian} approach.\n"
            },
            {
                "ref_title_clean": "structured generative models of natural source code",
                "ref_title_full": "Structured generative models of natural source code",
                "year": "2014",
                "full_block": "Structured generative models of natural source code.\n"
            },
            {
                "ref_title_clean": "a machine learning framework for programming by example",
                "ref_title_full": "A machine learning framework for programming by example",
                "year": "2013",
                "full_block": "A machine learning framework for programming by example.\n"
            },
            {
                "ref_title_clean": "neural programmer inducing latent programs with gradient descent",
                "ref_title_full": "Neural programmer: Inducing latent programs with gradient descent",
                "year": "2015",
                "full_block": "Neural programmer: Inducing latent programs with gradient descent.\n"
            },
            {
                "ref_title_clean": "global belief recursive neural networks",
                "ref_title_full": "Global belief recursive neural networks",
                "year": "2014",
                "full_block": "Global belief recursive neural networks.\n"
            },
            {
                "ref_title_clean": "predicting program properties from big code",
                "ref_title_full": "Predicting program properties from \"big code\"",
                "year": "2015",
                "full_block": "Predicting program properties from \"big code\".\n"
            },
            {
                "ref_title_clean": "neural programmer interpreters",
                "ref_title_full": "Neural programmer interpreters",
                "year": "2015",
                "full_block": "Neural programmer-interpreters.\n"
            },
            {
                "ref_title_clean": "programming with a differentiable forth interpreter",
                "ref_title_full": "Programming with a differentiable forth interpreter",
                "year": "2016",
                "full_block": "Programming with a differentiable forth interpreter.\n"
            },
            {
                "ref_title_clean": "stochastic superoptimization",
                "ref_title_full": "Stochastic superoptimization",
                "year": "2013",
                "full_block": "Stochastic superoptimization.\n"
            },
            {
                "ref_title_clean": "synthesizing data structure manipulations from storyboards",
                "ref_title_full": "Synthesizing data structure manipulations from storyboards",
                "year": "2011",
                "full_block": "Synthesizing data structure manipulations from storyboards.\n"
            },
            {
                "ref_title_clean": "automated feedback generation for introductory programming assignments",
                "ref_title_full": "Automated feedback generation for introductory programming assignments",
                "year": "2013",
                "full_block": "Automated feedback generation for introductory programming\n  assignments.\n"
            },
            {
                "ref_title_clean": "program synthesis by sketching",
                "ref_title_full": "\\Program Synthesis By Sketching",
                "year": "2008",
                "full_block": "\\emph{Program Synthesis By Sketching}.\n"
            },
            {
                "ref_title_clean": "programming by sketching for bit streaming programs",
                "ref_title_full": "Programming by sketching for bit streaming programs",
                "year": "2005",
                "full_block": "Programming by sketching for bit-streaming programs.\n"
            },
            {
                "ref_title_clean": "a methodology for lisp program construction from examples",
                "ref_title_full": "A methodology for lisp program construction from examples",
                "year": "1977",
                "full_block": "A methodology for lisp program construction from examples.\n"
            },
            {
                "ref_title_clean": "transit specifying protocols with concolic snippets",
                "ref_title_full": "TRANSIT: specifying protocols with concolic snippets",
                "year": "2013",
                "full_block": "{TRANSIT:} specifying protocols with concolic snippets.\n"
            },
            {
                "ref_title_clean": "grammar as a foreign language",
                "ref_title_full": "Grammar as a foreign language",
                "year": "2015",
                "full_block": "Grammar as a foreign language.\n"
            }
        ],
        "refs_source": "unpacked_sources/1611.01855/iclr2017_conference.bbl"
    },
    "flashmeta a framework for inductive program synthesis": {
        "id": null,
        "depth": 1,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Flashmeta: a framework for inductive program synthesis",
        "link": "none",
        "n_parents": 3,
        "year": "2015"
    },
    "neural programmer interpreters": {
        "id": "1511.06279",
        "depth": 1,
        "children_titles": [
            "neural reuse a fundamental organizational principle of the brain",
            "programmable reinforcement learning agents",
            "genetic programming an introduction volume1",
            "hierarchical reinforcement learning with the maxq value function decomposition",
            "programming in the brain a neural network theoretical framework",
            "a programmer\u2013interpreter neural network architecture for prefrontal cognitive control",
            "3d object detection and viewpoint estimation with a deformable 3d cuboid model",
            "neural turing machines",
            "long short term memory",
            "inferring algorithmic patterns with stack augmented recurrent nets",
            "neural gpus learn algorithms",
            "adam a method for stochastic optimization",
            "hierarchical apprenticeship learning with application to quadruped locomotion",
            "neural random access machines",
            "catastrophic interference in connectionist networks the sequential learning problem",
            "building program vector representations for deep learning",
            "neural programmer inducing latent programs with gradient descent",
            "complementary learning systems",
            "modular inverse reinforcement learning for visuomotor behavior",
            "parallel distributed processing explorations in the microstructure of cognition vol 1",
            "universal value function approximators",
            "learning to control fast weight memories an alternative to dynamic recurrent networks",
            "controlled and automatic processing behavior theory and biological mechanisms",
            "learning options through human interaction",
            "using matrices to model symbolic relationship",
            "sequence to sequence learning with neural networks",
            "between mdps and semi mdps a framework for temporal abstraction in reinforcement learning",
            "pointer networks",
            "learning to execute",
            "reinforcement learning neural turing machines",
            "learning simple algorithms from examples"
        ],
        "status": "expanded",
        "title_full": "Neural programmer interpreters",
        "link": "https://arxiv.org/abs/1511.06279",
        "n_parents": 6,
        "year": "2016",
        "children_full_dicts": [
            {
                "ref_title_clean": "neural reuse a fundamental organizational principle of the brain",
                "ref_title_full": "Neural reuse: A fundamental organizational principle of the brain",
                "year": "2010",
                "full_block": "Neural reuse: A fundamental organizational principle of the brain.\n"
            },
            {
                "ref_title_clean": "programmable reinforcement learning agents",
                "ref_title_full": "Programmable reinforcement learning agents",
                "year": "2001",
                "full_block": "Programmable reinforcement learning agents.\n"
            },
            {
                "ref_title_clean": "genetic programming an introduction volume1",
                "ref_title_full": "\\Genetic programming: An introduction, volume~1",
                "year": "1998",
                "full_block": "\\emph{Genetic programming: An introduction}, volume~1.\n"
            },
            {
                "ref_title_clean": "hierarchical reinforcement learning with the maxq value function decomposition",
                "ref_title_full": "Hierarchical reinforcement learning with the MAXQ value function decomposition",
                "year": "2000",
                "full_block": "Hierarchical reinforcement learning with the {MAXQ} value function\n  decomposition.\n"
            },
            {
                "ref_title_clean": "programming in the brain a neural network theoretical framework",
                "ref_title_full": "Programming in the brain: A neural network theoretical framework",
                "year": "2012",
                "full_block": "Programming in the brain: A neural network theoretical framework.\n"
            },
            {
                "ref_title_clean": "a programmer\u2013interpreter neural network architecture for prefrontal cognitive control",
                "ref_title_full": "A programmer\u2013interpreter neural network architecture for prefrontal cognitive control",
                "year": "2015",
                "full_block": "A programmer\u2013interpreter neural network architecture for prefrontal\n  cognitive control.\n"
            },
            {
                "ref_title_clean": "3d object detection and viewpoint estimation with a deformable 3d cuboid model",
                "ref_title_full": "3D object detection and viewpoint estimation with a deformable 3D cuboid model",
                "year": "2012",
                "full_block": "{3D} object detection and viewpoint estimation with a deformable {3D}\n  cuboid model.\n"
            },
            {
                "ref_title_clean": "neural turing machines",
                "ref_title_full": "Neural Turing machines",
                "year": "2014",
                "full_block": "Neural {Turing} machines.\n"
            },
            {
                "ref_title_clean": "long short term memory",
                "ref_title_full": "Long short term memory",
                "year": "1997",
                "full_block": "Long short-term memory.\n"
            },
            {
                "ref_title_clean": "inferring algorithmic patterns with stack augmented recurrent nets",
                "ref_title_full": "Inferring algorithmic patterns with stack augmented recurrent nets",
                "year": "2015",
                "full_block": "Inferring algorithmic patterns with stack-augmented recurrent nets.\n"
            },
            {
                "ref_title_clean": "neural gpus learn algorithms",
                "ref_title_full": "Neural gpus learn algorithms",
                "year": "2015",
                "full_block": "Neural gpus learn algorithms.\n"
            },
            {
                "ref_title_clean": "adam a method for stochastic optimization",
                "ref_title_full": "Adam: A method for stochastic optimization",
                "year": "none",
                "full_block": "Adam: A method for stochastic optimization.\n"
            },
            {
                "ref_title_clean": "hierarchical apprenticeship learning with application to quadruped locomotion",
                "ref_title_full": "Hierarchical apprenticeship learning with application to quadruped locomotion",
                "year": "2008",
                "full_block": "Hierarchical apprenticeship learning with application to quadruped\n  locomotion.\n"
            },
            {
                "ref_title_clean": "neural random access machines",
                "ref_title_full": "Neural random access machines",
                "year": "2015",
                "full_block": "Neural random-access machines.\n"
            },
            {
                "ref_title_clean": "catastrophic interference in connectionist networks the sequential learning problem",
                "ref_title_full": "Catastrophic interference in connectionist networks: The sequential learning problem",
                "year": "1989",
                "full_block": "Catastrophic interference in connectionist networks: {The} sequential\n  learning problem.\n"
            },
            {
                "ref_title_clean": "building program vector representations for deep learning",
                "ref_title_full": "Building program vector representations for deep learning",
                "year": "2014",
                "full_block": "Building program vector representations for deep learning.\n"
            },
            {
                "ref_title_clean": "neural programmer inducing latent programs with gradient descent",
                "ref_title_full": "Neural programmer: Inducing latent programs with gradient descent",
                "year": "2015",
                "full_block": "Neural programmer: Inducing latent programs with gradient descent.\n"
            },
            {
                "ref_title_clean": "complementary learning systems",
                "ref_title_full": "Complementary learning systems",
                "year": "2014",
                "full_block": "Complementary learning systems.\n"
            },
            {
                "ref_title_clean": "modular inverse reinforcement learning for visuomotor behavior",
                "ref_title_full": "Modular inverse reinforcement learning for visuomotor behavior",
                "year": "2013",
                "full_block": "Modular inverse reinforcement learning for visuomotor behavior.\n"
            },
            {
                "ref_title_clean": "parallel distributed processing explorations in the microstructure of cognition vol 1",
                "ref_title_full": "Parallel distributed processing: Explorations in the microstructure of cognition, vol. 1",
                "year": "1986",
                "full_block": "Parallel distributed processing: Explorations in the microstructure\n  of cognition, vol. 1.\n"
            },
            {
                "ref_title_clean": "universal value function approximators",
                "ref_title_full": "Universal value function approximators",
                "year": "2015",
                "full_block": "Universal value function approximators.\n"
            },
            {
                "ref_title_clean": "learning to control fast weight memories an alternative to dynamic recurrent networks",
                "ref_title_full": "Learning to control fast weight memories: An alternative to dynamic recurrent networks",
                "year": "1992",
                "full_block": "Learning to control fast-weight memories: An alternative to dynamic\n  recurrent networks.\n"
            },
            {
                "ref_title_clean": "controlled and automatic processing behavior theory and biological mechanisms",
                "ref_title_full": "Controlled and automatic processing: behavior, theory, and biological mechanisms",
                "year": "2003",
                "full_block": "Controlled and automatic processing: behavior, theory, and biological\n  mechanisms.\n"
            },
            {
                "ref_title_clean": "learning options through human interaction",
                "ref_title_full": "Learning options through human interaction",
                "year": "2011",
                "full_block": "Learning options through human interaction.\n"
            },
            {
                "ref_title_clean": "using matrices to model symbolic relationship",
                "ref_title_full": "Using matrices to model symbolic relationship",
                "year": "2009",
                "full_block": "Using matrices to model symbolic relationship.\n"
            },
            {
                "ref_title_clean": "sequence to sequence learning with neural networks",
                "ref_title_full": "Sequence to sequence learning with neural networks",
                "year": "2014",
                "full_block": "Sequence to sequence learning with neural networks.\n"
            },
            {
                "ref_title_clean": "between mdps and semi mdps a framework for temporal abstraction in reinforcement learning",
                "ref_title_full": "Between MDPs and semi MDPs: A framework for temporal abstraction in reinforcement learning",
                "year": "1999",
                "full_block": "Between {MDPs} and {semi-MDPs}: A framework for temporal abstraction\n  in reinforcement learning.\n"
            },
            {
                "ref_title_clean": "pointer networks",
                "ref_title_full": "Pointer networks",
                "year": "2015",
                "full_block": "Pointer networks.\n"
            },
            {
                "ref_title_clean": "learning to execute",
                "ref_title_full": "Learning to execute",
                "year": "2014",
                "full_block": "Learning to execute.\n"
            },
            {
                "ref_title_clean": "reinforcement learning neural turing machines",
                "ref_title_full": "Reinforcement learning neural turing machines",
                "year": "2015",
                "full_block": "Reinforcement learning neural turing machines.\n"
            },
            {
                "ref_title_clean": "learning simple algorithms from examples",
                "ref_title_full": "Learning simple algorithms from examples",
                "year": "2015",
                "full_block": "Learning simple algorithms from examples.\n"
            }
        ],
        "refs_source": "unpacked_sources/1511.06279/iclr2016_full.bbl"
    },
    "programming with a differentiable forth interpreter": {
        "id": "1605.06640",
        "depth": 1,
        "children_titles": [
            "url urlhttptensorfloworg",
            "recursive program synthesis",
            "neural module networks",
            "learning to generate textual data",
            "starting forth",
            "adaptive neural compilation",
            "terpret a probabilistic programming language for program induction",
            "church a language for generative models",
            "neural turing machines",
            "hybrid computing using a neural network with dynamic external memory",
            "learning to transduce with unbounded memory",
            "a neural compiler",
            "long short term memory",
            "inferring algorithmic patterns with stack augmented recurrent nets",
            "neural gpus learn algorithms",
            "symbolic execution and program testing",
            "adam a method for stochastic optimization",
            "inductive programming a survey of program synthesis techniques",
            "parsing algebraic word problems into equations",
            "genetic programming on the programming of computers by means of natural selection volume1",
            "neural random access machines",
            "learning to automatically solve algebra word problems",
            "learning repetitive text editing procedures with smartedit",
            "gradient based hyperparameter optimization through reversible learning",
            "toward automatic program synthesis",
            "neural programmer inducing latent programs with gradient descent",
            "adding gradient noise improves learning for very deep networks",
            "evolutionary program induction of binary machine code and its applications",
            "neural programmer interpreters",
            "solving general arithmetic word problems",
            "reasoning about quantities in natural language",
            "neural programming language",
            "programming by sketching for bit streaming programs",
            "combinatorial sketching for finite programs",
            "sequence to sequence learning with neural networks"
        ],
        "status": "expanded",
        "title_full": "Programming with a differentiable forth interpreter",
        "link": "https://arxiv.org/abs/1605.06640",
        "n_parents": 4,
        "year": "2016",
        "children_full_dicts": [
            {
                "ref_title_clean": "url urlhttptensorfloworg",
                "ref_title_full": "URL \\urlhttp://tensorflow.org/",
                "year": "2015",
                "full_block": "URL \\url{http://tensorflow.org/}.\n"
            },
            {
                "ref_title_clean": "recursive program synthesis",
                "ref_title_full": "Recursive program synthesis",
                "year": "2013",
                "full_block": "Recursive program synthesis.\n"
            },
            {
                "ref_title_clean": "neural module networks",
                "ref_title_full": "Neural module networks",
                "year": "2016",
                "full_block": "Neural module networks.\n"
            },
            {
                "ref_title_clean": "learning to generate textual data",
                "ref_title_full": "Learning to generate textual data",
                "year": "2016",
                "full_block": "Learning to generate textual data.\n"
            },
            {
                "ref_title_clean": "starting forth",
                "ref_title_full": "\\Starting Forth",
                "year": "1980",
                "full_block": "\\emph{{Starting Forth}}.\n"
            },
            {
                "ref_title_clean": "adaptive neural compilation",
                "ref_title_full": "Adaptive neural compilation",
                "year": "2016",
                "full_block": "Adaptive neural compilation.\n"
            },
            {
                "ref_title_clean": "terpret a probabilistic programming language for program induction",
                "ref_title_full": "TerpreT: A Probabilistic Programming Language for Program Induction",
                "year": "2016",
                "full_block": "{TerpreT: A Probabilistic Programming Language for Program\n  Induction}.\n"
            },
            {
                "ref_title_clean": "church a language for generative models",
                "ref_title_full": "Church: a language for generative models",
                "year": "2008",
                "full_block": "Church: a language for generative models.\n"
            },
            {
                "ref_title_clean": "neural turing machines",
                "ref_title_full": "Neural Turing Machines",
                "year": "2014",
                "full_block": "{Neural Turing Machines}.\n"
            },
            {
                "ref_title_clean": "hybrid computing using a neural network with dynamic external memory",
                "ref_title_full": "Hybrid computing using a neural network with dynamic external memory",
                "year": "2016",
                "full_block": "Hybrid computing using a neural network with dynamic external memory.\n"
            },
            {
                "ref_title_clean": "learning to transduce with unbounded memory",
                "ref_title_full": "Learning to Transduce with Unbounded Memory",
                "year": "2015",
                "full_block": "{Learning to Transduce with Unbounded Memory}.\n"
            },
            {
                "ref_title_clean": "a neural compiler",
                "ref_title_full": "A Neural compiler",
                "year": "1995",
                "full_block": "{A Neural compiler}.\n"
            },
            {
                "ref_title_clean": "long short term memory",
                "ref_title_full": "Long short term memory",
                "year": "1997",
                "full_block": "Long short-term memory.\n"
            },
            {
                "ref_title_clean": "inferring algorithmic patterns with stack augmented recurrent nets",
                "ref_title_full": "Inferring Algorithmic Patterns with Stack Augmented Recurrent Nets",
                "year": "2015",
                "full_block": "{Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets}.\n"
            },
            {
                "ref_title_clean": "neural gpus learn algorithms",
                "ref_title_full": "Neural GPUs learn algorithms",
                "year": "2015",
                "full_block": "{Neural GPUs learn algorithms}.\n"
            },
            {
                "ref_title_clean": "symbolic execution and program testing",
                "ref_title_full": "Symbolic Execution and Program Testing",
                "year": "1976",
                "full_block": "{Symbolic Execution and Program Testing}.\n"
            },
            {
                "ref_title_clean": "adam a method for stochastic optimization",
                "ref_title_full": "Adam: A Method for Stochastic Optimization",
                "year": "2015",
                "full_block": "{Adam: A Method for Stochastic Optimization}.\n"
            },
            {
                "ref_title_clean": "inductive programming a survey of program synthesis techniques",
                "ref_title_full": "Inductive Programming: A Survey of Program Synthesis Techniques",
                "year": "2009",
                "full_block": "{Inductive Programming: A Survey of Program Synthesis Techniques}.\n"
            },
            {
                "ref_title_clean": "parsing algebraic word problems into equations",
                "ref_title_full": "Parsing Algebraic Word Problems into Equations",
                "year": "2015",
                "full_block": "{Parsing Algebraic Word Problems into Equations}.\n"
            },
            {
                "ref_title_clean": "genetic programming on the programming of computers by means of natural selection volume1",
                "ref_title_full": "\\Genetic Programming: On the Programming of Computers by Means of Natural Selection, volume~1",
                "year": "1992",
                "full_block": "\\emph{{Genetic Programming: On the Programming of Computers by Means\n  of Natural Selection}}, volume~1.\n"
            },
            {
                "ref_title_clean": "neural random access machines",
                "ref_title_full": "Neural Random Access Machines",
                "year": "2016",
                "full_block": "{Neural Random-Access Machines}.\n"
            },
            {
                "ref_title_clean": "learning to automatically solve algebra word problems",
                "ref_title_full": "Learning to Automatically Solve Algebra Word Problems",
                "year": "2014",
                "full_block": "{Learning to Automatically Solve Algebra Word Problems}.\n"
            },
            {
                "ref_title_clean": "learning repetitive text editing procedures with smartedit",
                "ref_title_full": "Learning repetitive text editing procedures with smartedit",
                "year": "2001",
                "full_block": "Learning repetitive text-editing procedures with smartedit.\n"
            },
            {
                "ref_title_clean": "gradient based hyperparameter optimization through reversible learning",
                "ref_title_full": "Gradient based Hyperparameter Optimization through Reversible Learning",
                "year": "2015",
                "full_block": "{Gradient-based Hyperparameter Optimization through Reversible\n  Learning}.\n"
            },
            {
                "ref_title_clean": "toward automatic program synthesis",
                "ref_title_full": "Toward automatic program synthesis",
                "year": "1971",
                "full_block": "Toward automatic program synthesis.\n"
            },
            {
                "ref_title_clean": "neural programmer inducing latent programs with gradient descent",
                "ref_title_full": "Neural Programmer: Inducing latent programs with gradient descent",
                "year": "none",
                "full_block": "{Neural Programmer: Inducing latent programs with gradient descent}.\n"
            },
            {
                "ref_title_clean": "adding gradient noise improves learning for very deep networks",
                "ref_title_full": "Adding Gradient Noise Improves Learning for Very Deep Networks",
                "year": "none",
                "full_block": "{Adding Gradient Noise Improves Learning for Very Deep Networks}.\n"
            },
            {
                "ref_title_clean": "evolutionary program induction of binary machine code and its applications",
                "ref_title_full": "\\Evolutionary Program Induction of Binary Machine Code and its Applications",
                "year": "1997",
                "full_block": "\\emph{{Evolutionary Program Induction of Binary Machine Code and its\n  Applications}}.\n"
            },
            {
                "ref_title_clean": "neural programmer interpreters",
                "ref_title_full": "Neural programmer interpreters",
                "year": "2015",
                "full_block": "Neural programmer-interpreters.\n"
            },
            {
                "ref_title_clean": "solving general arithmetic word problems",
                "ref_title_full": "Solving General Arithmetic Word Problems",
                "year": "2015",
                "full_block": "{Solving General Arithmetic Word Problems}.\n"
            },
            {
                "ref_title_clean": "reasoning about quantities in natural language",
                "ref_title_full": "Reasoning about quantities in natural language",
                "year": "2015",
                "full_block": "Reasoning about quantities in natural language.\n"
            },
            {
                "ref_title_clean": "neural programming language",
                "ref_title_full": "Neural Programming Language",
                "year": "1994",
                "full_block": "{Neural Programming Language}.\n"
            },
            {
                "ref_title_clean": "programming by sketching for bit streaming programs",
                "ref_title_full": "Programming by Sketching for Bit streaming Programs",
                "year": "2005",
                "full_block": "{Programming by Sketching for Bit-streaming Programs}.\n"
            },
            {
                "ref_title_clean": "combinatorial sketching for finite programs",
                "ref_title_full": "Combinatorial Sketching for Finite Programs",
                "year": "2006",
                "full_block": "{Combinatorial Sketching for Finite Programs}.\n"
            },
            {
                "ref_title_clean": "sequence to sequence learning with neural networks",
                "ref_title_full": "Sequence to Sequence Learning with Neural Networks",
                "year": "2014",
                "full_block": "{Sequence to Sequence Learning with Neural Networks}.\n"
            }
        ],
        "refs_source": "unpacked_sources/1605.06640/main.bbl"
    },
    "sequence to sequence learning with neural networks": {
        "id": "1409.3215",
        "depth": 1,
        "children_titles": [
            "joint language and translation modeling with recurrent neural networks",
            "neural machine translation by jointly learning to align and translate",
            "a neural probabilistic language model",
            "learning long term dependencies with gradient descent is difficult",
            "learning phrase representations using rnn encoder decoder for statistical machine translation",
            "multi column deep neural networks for image classification",
            "context dependent pre trained deep neural networks for large vocabulary speech recognition",
            "fast and robust neural network joint models for statistical machine translation",
            "edinburghs phrase based machine translation systems for wmt 14",
            "generating sequences with recurrent neural networks",
            "connectionist temporal classification labelling unsegmented sequence data with recurrent neural networks",
            "multilingual distributed representations without word alignment",
            "deep neural networks for acoustic modeling in speech recognition",
            "untersuchungen zu dynamischen neuronalen netzen",
            "long short term memory",
            "lstm can solve hard long time lag problems",
            "recurrent continuous translation models",
            "imagenet classification with deep convolutional neural networks",
            "building high level features using large scale unsupervised learning",
            "gradient based learning applied to document recognition",
            "statistical language models based on neural networks",
            "recurrent neural network based language model",
            "bleu a method for automatic evaluation of machine translation",
            "on the difficulty of training recurrent neural networks",
            "overcoming the curse of sentence length for neural machine translation using automatic segmentation",
            "on small depth threshold circuits",
            "learning representations by back propagating errors",
            "university le mans",
            "lstm neural networks for language modeling",
            "backpropagation through time what it does and how to do it"
        ],
        "status": "expanded",
        "title_full": "Sequence to sequence learning with neural networks",
        "link": "https://arxiv.org/abs/1409.3215",
        "n_parents": 12,
        "year": "2014",
        "children_full_dicts": [
            {
                "ref_title_clean": "joint language and translation modeling with recurrent neural networks",
                "ref_title_full": "Joint language and translation modeling with recurrent neural networks",
                "year": "2013",
                "full_block": "Joint language and translation modeling with recurrent neural\n  networks.\n"
            },
            {
                "ref_title_clean": "neural machine translation by jointly learning to align and translate",
                "ref_title_full": "Neural machine translation by jointly learning to align and translate",
                "year": "2014",
                "full_block": "Neural machine translation by jointly learning to align and\n  translate.\n"
            },
            {
                "ref_title_clean": "a neural probabilistic language model",
                "ref_title_full": "A neural probabilistic language model",
                "year": "2003",
                "full_block": "A neural probabilistic language model.\n"
            },
            {
                "ref_title_clean": "learning long term dependencies with gradient descent is difficult",
                "ref_title_full": "Learning long term dependencies with gradient descent is difficult",
                "year": "1994",
                "full_block": "Learning long-term dependencies with gradient descent is difficult.\n"
            },
            {
                "ref_title_clean": "learning phrase representations using rnn encoder decoder for statistical machine translation",
                "ref_title_full": "Learning phrase representations using RNN encoder decoder for statistical machine translation",
                "year": "2014",
                "full_block": "Learning phrase representations using {RNN} encoder-decoder for\n  statistical machine translation.\n"
            },
            {
                "ref_title_clean": "multi column deep neural networks for image classification",
                "ref_title_full": "Multi column deep neural networks for image classification",
                "year": "2012",
                "full_block": "Multi-column deep neural networks for image classification.\n"
            },
            {
                "ref_title_clean": "context dependent pre trained deep neural networks for large vocabulary speech recognition",
                "ref_title_full": "Context dependent pre trained deep neural networks for large vocabulary speech recognition",
                "year": "2012",
                "full_block": "Context-dependent pre-trained deep neural networks for large\n  vocabulary speech recognition.\n"
            },
            {
                "ref_title_clean": "fast and robust neural network joint models for statistical machine translation",
                "ref_title_full": "Fast and robust neural network joint models for statistical machine translation",
                "year": "2014",
                "full_block": "Fast and robust neural network joint models for statistical machine\n  translation.\n"
            },
            {
                "ref_title_clean": "edinburghs phrase based machine translation systems for wmt 14",
                "ref_title_full": "Edinburgh's phrase based machine translation systems for wmt 14",
                "year": "2014",
                "full_block": "Edinburgh's phrase-based machine translation systems for wmt-14.\n"
            },
            {
                "ref_title_clean": "generating sequences with recurrent neural networks",
                "ref_title_full": "Generating sequences with recurrent neural networks",
                "year": "2013",
                "full_block": "Generating sequences with recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "connectionist temporal classification labelling unsegmented sequence data with recurrent neural networks",
                "ref_title_full": "Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks",
                "year": "2006",
                "full_block": "Connectionist temporal classification: labelling unsegmented sequence\n  data with recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "multilingual distributed representations without word alignment",
                "ref_title_full": "Multilingual distributed representations without word alignment",
                "year": "2014",
                "full_block": "Multilingual distributed representations without word alignment.\n"
            },
            {
                "ref_title_clean": "deep neural networks for acoustic modeling in speech recognition",
                "ref_title_full": "Deep neural networks for acoustic modeling in speech recognition",
                "year": "2012",
                "full_block": "Deep neural networks for acoustic modeling in speech recognition.\n"
            },
            {
                "ref_title_clean": "untersuchungen zu dynamischen neuronalen netzen",
                "ref_title_full": "Untersuchungen zu dynamischen neuronalen netzen",
                "year": "1991",
                "full_block": "Untersuchungen zu dynamischen neuronalen netzen.\n"
            },
            {
                "ref_title_clean": "long short term memory",
                "ref_title_full": "Long short term memory",
                "year": "1997",
                "full_block": "Long short-term memory.\n"
            },
            {
                "ref_title_clean": "lstm can solve hard long time lag problems",
                "ref_title_full": "LSTM can solve hard long time lag problems",
                "year": "none",
                "full_block": "{LSTM} can solve hard long time lag problems.\n"
            },
            {
                "ref_title_clean": "recurrent continuous translation models",
                "ref_title_full": "Recurrent continuous translation models",
                "year": "2013",
                "full_block": "Recurrent continuous translation models.\n"
            },
            {
                "ref_title_clean": "imagenet classification with deep convolutional neural networks",
                "ref_title_full": "ImageNet classification with deep convolutional neural networks",
                "year": "2012",
                "full_block": "{ImageNet} classification with deep convolutional neural networks.\n"
            },
            {
                "ref_title_clean": "building high level features using large scale unsupervised learning",
                "ref_title_full": "Building high level features using large scale unsupervised learning",
                "year": "2012",
                "full_block": "Building high-level features using large scale unsupervised learning.\n"
            },
            {
                "ref_title_clean": "gradient based learning applied to document recognition",
                "ref_title_full": "Gradient based learning applied to document recognition",
                "year": "1998",
                "full_block": "Gradient-based learning applied to document recognition.\n"
            },
            {
                "ref_title_clean": "statistical language models based on neural networks",
                "ref_title_full": "Statistical Language Models based on Neural Networks",
                "year": "2012",
                "full_block": "{\\em Statistical Language Models based on Neural Networks}.\n"
            },
            {
                "ref_title_clean": "recurrent neural network based language model",
                "ref_title_full": "Recurrent neural network based language model",
                "year": "2010",
                "full_block": "Recurrent neural network based language model.\n"
            },
            {
                "ref_title_clean": "bleu a method for automatic evaluation of machine translation",
                "ref_title_full": "BLEU: a method for automatic evaluation of machine translation",
                "year": "2002",
                "full_block": "{BLEU}: a method for automatic evaluation of machine translation.\n"
            },
            {
                "ref_title_clean": "on the difficulty of training recurrent neural networks",
                "ref_title_full": "On the difficulty of training recurrent neural networks",
                "year": "2012",
                "full_block": "On the difficulty of training recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "overcoming the curse of sentence length for neural machine translation using automatic segmentation",
                "ref_title_full": "Overcoming the curse of sentence length for neural machine translation using automatic segmentation",
                "year": "2014",
                "full_block": "Overcoming the curse of sentence length for neural machine\n  translation using automatic segmentation.\n"
            },
            {
                "ref_title_clean": "on small depth threshold circuits",
                "ref_title_full": "On small depth threshold circuits",
                "year": "1992",
                "full_block": "On small depth threshold circuits.\n"
            },
            {
                "ref_title_clean": "learning representations by back propagating errors",
                "ref_title_full": "Learning representations by back propagating errors",
                "year": "1986",
                "full_block": "Learning representations by back-propagating errors.\n"
            },
            {
                "ref_title_clean": "university le mans",
                "ref_title_full": "University le mans",
                "year": "2014",
                "full_block": "University le mans.\n"
            },
            {
                "ref_title_clean": "lstm neural networks for language modeling",
                "ref_title_full": "LSTM neural networks for language modeling",
                "year": "2010",
                "full_block": "{LSTM} neural networks for language modeling.\n"
            },
            {
                "ref_title_clean": "backpropagation through time what it does and how to do it",
                "ref_title_full": "Backpropagation through time: what it does and how to do it",
                "year": "1990",
                "full_block": "Backpropagation through time: what it does and how to do it.\n"
            }
        ],
        "refs_source": "unpacked_sources/1409.3215/translate.bbl"
    },
    "improved semantic representations from tree structured long short term memory networks": {
        "id": "1503.00075",
        "depth": 1,
        "children_titles": [
            "neural machine translation by jointly learning to align and translate",
            "learning long term dependencies with gradient descent is difficult",
            "the meaning factory formal semantics for recognizing textual entailment and determining semantic similarity",
            "a convolutional neural network for modelling sentences",
            "a fast and accurate dependency parser using neural networks",
            "natural language processing almost from scratch",
            "adaptive subgradient methods for online learning and stochastic optimization",
            "finding structure in time",
            "the measurement of textual coherence with latent semantic analysis",
            "ppdb the paraphrase database",
            "learning task dependent distributed representations by backpropagation through structure",
            "hybrid speech recognition with deep bidirectional lstm",
            "multi step regression learning for compositional distributional semantics",
            "improving neural networks by preventing co adaptation of feature detectors",
            "the vanishing gradient problem during learning recurrent neural nets and problem solutions",
            "long short term memory",
            "improving word representations via global context and multiple word prototypes",
            "deep recursive neural networks for compositionality in language",
            "unal nlp combining soft cardinality features for semantic textual similarity relatedness and entailment",
            "convolutional neural networks for sentence classification",
            "accurate unlexicalized parsing",
            "illinois lh a denotational and distributional approach to semantics",
            "a solution to platos problem the latent semantic analysis theory of acquisition induction and representation of knowledge",
            "distributed representations of sentences and documents",
            "statistical language models based on neural networks",
            "distributed representations of words and phrases and their compositionality",
            "composition in distributional models of semantics",
            "glove global vectors for word representation",
            "learning representations by back propagating errors",
            "semantic compositionality through recursive matrix vector spaces",
            "grounded compositional semantics for finding and describing images with sentences",
            "parsing natural scenes and natural language with recursive neural networks",
            "recursive deep models for semantic compositionality over a sentiment treebank",
            "modeling documents with deep boltzmann machines",
            "sequence to sequence learning with neural networks",
            "word representations a simple and general method for semi supervised learning",
            "show and tell a neural image caption generator",
            "compositional matrix space models for sentiment analysis",
            "learning to execute",
            "ecnu one stone two birds ensemble of heterogenous measures for semantic relatedness and textual entailment"
        ],
        "status": "expanded",
        "title_full": "Improved semantic representations from tree structured long short term memory networks",
        "link": "https://arxiv.org/abs/1503.00075",
        "n_parents": 1,
        "year": "2015",
        "children_full_dicts": [
            {
                "ref_title_clean": "neural machine translation by jointly learning to align and translate",
                "ref_title_full": "Neural machine translation by jointly learning to align and translate",
                "year": "none",
                "full_block": "Neural machine translation by jointly learning to align and\n  translate.\n"
            },
            {
                "ref_title_clean": "learning long term dependencies with gradient descent is difficult",
                "ref_title_full": "Learning long term dependencies with gradient descent is difficult",
                "year": "none",
                "full_block": "Learning long-term dependencies with gradient descent is difficult.\n"
            },
            {
                "ref_title_clean": "the meaning factory formal semantics for recognizing textual entailment and determining semantic similarity",
                "ref_title_full": "The Meaning Factory: Formal semantics for recognizing textual entailment and determining semantic similarity",
                "year": "none",
                "full_block": "{The Meaning Factory}: Formal semantics for recognizing textual\n  entailment and determining semantic similarity.\n"
            },
            {
                "ref_title_clean": "a convolutional neural network for modelling sentences",
                "ref_title_full": "A convolutional neural network for modelling sentences",
                "year": "none",
                "full_block": "A convolutional neural network for modelling sentences.\n"
            },
            {
                "ref_title_clean": "a fast and accurate dependency parser using neural networks",
                "ref_title_full": "A fast and accurate dependency parser using neural networks",
                "year": "none",
                "full_block": "A fast and accurate dependency parser using neural networks.\n"
            },
            {
                "ref_title_clean": "natural language processing almost from scratch",
                "ref_title_full": "Natural language processing (almost) from scratch",
                "year": "none",
                "full_block": "Natural language processing (almost) from scratch.\n"
            },
            {
                "ref_title_clean": "adaptive subgradient methods for online learning and stochastic optimization",
                "ref_title_full": "Adaptive subgradient methods for online learning and stochastic optimization",
                "year": "none",
                "full_block": "Adaptive subgradient methods for online learning and stochastic\n  optimization.\n"
            },
            {
                "ref_title_clean": "finding structure in time",
                "ref_title_full": "Finding structure in time",
                "year": "none",
                "full_block": "Finding structure in time.\n"
            },
            {
                "ref_title_clean": "the measurement of textual coherence with latent semantic analysis",
                "ref_title_full": "The measurement of textual coherence with latent semantic analysis",
                "year": "none",
                "full_block": "The measurement of textual coherence with latent semantic analysis.\n"
            },
            {
                "ref_title_clean": "ppdb the paraphrase database",
                "ref_title_full": "PPDB: The Paraphrase Database",
                "year": "none",
                "full_block": "{PPDB}: {The Paraphrase Database}.\n"
            },
            {
                "ref_title_clean": "learning task dependent distributed representations by backpropagation through structure",
                "ref_title_full": "Learning task dependent distributed representations by backpropagation through structure",
                "year": "none",
                "full_block": "Learning task-dependent distributed representations by\n  backpropagation through structure.\n"
            },
            {
                "ref_title_clean": "hybrid speech recognition with deep bidirectional lstm",
                "ref_title_full": "Hybrid speech recognition with deep bidirectional LSTM",
                "year": "none",
                "full_block": "Hybrid speech recognition with deep bidirectional {LSTM}.\n"
            },
            {
                "ref_title_clean": "multi step regression learning for compositional distributional semantics",
                "ref_title_full": "Multi step regression learning for compositional distributional semantics",
                "year": "none",
                "full_block": "Multi-step regression learning for compositional distributional\n  semantics.\n"
            },
            {
                "ref_title_clean": "improving neural networks by preventing co adaptation of feature detectors",
                "ref_title_full": "Improving neural networks by preventing co adaptation of feature detectors",
                "year": "none",
                "full_block": "Improving neural networks by preventing co-adaptation of feature\n  detectors.\n"
            },
            {
                "ref_title_clean": "the vanishing gradient problem during learning recurrent neural nets and problem solutions",
                "ref_title_full": "The vanishing gradient problem during learning recurrent neural nets and problem solutions",
                "year": "none",
                "full_block": "The vanishing gradient problem during learning recurrent neural nets\n  and problem solutions.\n"
            },
            {
                "ref_title_clean": "long short term memory",
                "ref_title_full": "Long Short Term Memory",
                "year": "none",
                "full_block": "{Long Short-Term Memory}.\n"
            },
            {
                "ref_title_clean": "improving word representations via global context and multiple word prototypes",
                "ref_title_full": "Improving word representations via global context and multiple word prototypes",
                "year": "none",
                "full_block": "Improving word representations via global context and multiple word\n  prototypes.\n"
            },
            {
                "ref_title_clean": "deep recursive neural networks for compositionality in language",
                "ref_title_full": "Deep recursive neural networks for compositionality in language",
                "year": "none",
                "full_block": "Deep recursive neural networks for compositionality in language.\n"
            },
            {
                "ref_title_clean": "unal nlp combining soft cardinality features for semantic textual similarity relatedness and entailment",
                "ref_title_full": "UNAL NLP: Combining soft cardinality features for semantic textual similarity, relatedness and entailment",
                "year": "none",
                "full_block": "{UNAL-NLP}: Combining soft cardinality features for semantic textual\n  similarity, relatedness and entailment.\n"
            },
            {
                "ref_title_clean": "convolutional neural networks for sentence classification",
                "ref_title_full": "Convolutional neural networks for sentence classification",
                "year": "none",
                "full_block": "Convolutional neural networks for sentence classification.\n"
            },
            {
                "ref_title_clean": "accurate unlexicalized parsing",
                "ref_title_full": "Accurate unlexicalized parsing",
                "year": "none",
                "full_block": "Accurate unlexicalized parsing.\n"
            },
            {
                "ref_title_clean": "illinois lh a denotational and distributional approach to semantics",
                "ref_title_full": "Illinois lh: A denotational and distributional approach to semantics",
                "year": "none",
                "full_block": "Illinois-lh: A denotational and distributional approach to semantics.\n"
            },
            {
                "ref_title_clean": "a solution to platos problem the latent semantic analysis theory of acquisition induction and representation of knowledge",
                "ref_title_full": "A solution to plato's problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge",
                "year": "none",
                "full_block": "A solution to plato's problem: The latent semantic analysis theory of\n  acquisition, induction, and representation of knowledge.\n"
            },
            {
                "ref_title_clean": "distributed representations of sentences and documents",
                "ref_title_full": "Distributed representations of sentences and documents",
                "year": "none",
                "full_block": "Distributed representations of sentences and documents.\n"
            },
            {
                "ref_title_clean": "statistical language models based on neural networks",
                "ref_title_full": "Statistical Language Models Based on Neural Networks\\/",
                "year": "none",
                "full_block": "{\\em Statistical Language Models Based on Neural Networks\\/}.\n"
            },
            {
                "ref_title_clean": "distributed representations of words and phrases and their compositionality",
                "ref_title_full": "Distributed representations of words and phrases and their compositionality",
                "year": "none",
                "full_block": "Distributed representations of words and phrases and their\n  compositionality.\n"
            },
            {
                "ref_title_clean": "composition in distributional models of semantics",
                "ref_title_full": "Composition in distributional models of semantics",
                "year": "none",
                "full_block": "Composition in distributional models of semantics.\n"
            },
            {
                "ref_title_clean": "glove global vectors for word representation",
                "ref_title_full": "Glove: Global vectors for word representation",
                "year": "none",
                "full_block": "Glove: Global vectors for word representation.\n"
            },
            {
                "ref_title_clean": "learning representations by back propagating errors",
                "ref_title_full": "Learning representations by back propagating errors",
                "year": "none",
                "full_block": "Learning representations by back-propagating errors.\n"
            },
            {
                "ref_title_clean": "semantic compositionality through recursive matrix vector spaces",
                "ref_title_full": "Semantic compositionality through recursive matrix vector spaces",
                "year": "none",
                "full_block": "Semantic compositionality through recursive matrix-vector spaces.\n"
            },
            {
                "ref_title_clean": "grounded compositional semantics for finding and describing images with sentences",
                "ref_title_full": "Grounded compositional semantics for finding and describing images with sentences",
                "year": "none",
                "full_block": "Grounded compositional semantics for finding and describing images\n  with sentences.\n"
            },
            {
                "ref_title_clean": "parsing natural scenes and natural language with recursive neural networks",
                "ref_title_full": "Parsing natural scenes and natural language with recursive neural networks",
                "year": "none",
                "full_block": "Parsing natural scenes and natural language with recursive neural\n  networks.\n"
            },
            {
                "ref_title_clean": "recursive deep models for semantic compositionality over a sentiment treebank",
                "ref_title_full": "Recursive deep models for semantic compositionality over a sentiment treebank",
                "year": "none",
                "full_block": "Recursive deep models for semantic compositionality over a sentiment\n  treebank.\n"
            },
            {
                "ref_title_clean": "modeling documents with deep boltzmann machines",
                "ref_title_full": "Modeling documents with deep boltzmann machines",
                "year": "none",
                "full_block": "Modeling documents with deep boltzmann machines.\n"
            },
            {
                "ref_title_clean": "sequence to sequence learning with neural networks",
                "ref_title_full": "Sequence to sequence learning with neural networks",
                "year": "none",
                "full_block": "Sequence to sequence learning with neural networks.\n"
            },
            {
                "ref_title_clean": "word representations a simple and general method for semi supervised learning",
                "ref_title_full": "Word representations: a simple and general method for semi supervised learning",
                "year": "none",
                "full_block": "Word representations: a simple and general method for semi-supervised\n  learning.\n"
            },
            {
                "ref_title_clean": "show and tell a neural image caption generator",
                "ref_title_full": "Show and tell: A neural image caption generator",
                "year": "none",
                "full_block": "Show and tell: A neural image caption generator.\n"
            },
            {
                "ref_title_clean": "compositional matrix space models for sentiment analysis",
                "ref_title_full": "Compositional matrix space models for sentiment analysis",
                "year": "none",
                "full_block": "Compositional matrix-space models for sentiment analysis.\n"
            },
            {
                "ref_title_clean": "learning to execute",
                "ref_title_full": "Learning to execute",
                "year": "none",
                "full_block": "Learning to execute.\n"
            },
            {
                "ref_title_clean": "ecnu one stone two birds ensemble of heterogenous measures for semantic relatedness and textual entailment",
                "ref_title_full": "ECNU: One stone two birds: Ensemble of heterogenous measures for semantic relatedness and textual entailment",
                "year": "none",
                "full_block": "{ECNU}: One stone two birds: Ensemble of heterogenous measures for\n  semantic relatedness and textual entailment.\n"
            }
        ],
        "refs_source": "unpacked_sources/1503.00075/treelstm.bbl"
    },
    "grammar as a foreign language": {
        "id": "1412.7449",
        "depth": 1,
        "children_titles": [
            "sequence to sequence learning with neural networks",
            "neural machine translation by jointly learning to align and translate",
            "addressing the rare word problem in neural machine translation",
            "on using very large target vocabulary for neural machine translation",
            "long short term memory",
            "efficient estimation of word representations in vector space",
            "ontonotes the 90 solution",
            "questionbank creating a corpus of parse annotated questions",
            "building a large annotated corpus of english the penn treebank",
            "ambiguity aware ensemble training for semi supervised dependency parsing",
            "learning accurate compact and interpretable tree annotation",
            "fast and accurate shift reduce constituent parsing",
            "products of random latent variable grammars",
            "self training pcfg grammars with latent annotations across languages",
            "effective self training for parsing",
            "self training with products of latent variable grammars",
            "sparser better faster gpu parsing",
            "three generative lexicalised models for statistical parsing",
            "accurate unlexicalized parsing",
            "inducing history representations for broad coverage statistical parsing",
            "discriminative training of a neural network statistical parser",
            "constituent parsing with incremental sigmoid belief networks",
            "deep learning for efficient discriminative parsing",
            "parsing natural scenes and natural language with recursive neural networks",
            "a linear observed time statistical parser based on maximum entropy models",
            "incremental parsing with the perceptron algorithm",
            "generating sequences with recurrent neural networks",
            "end to end continuous speech recognition using attention based recurrent nn first results",
            "recurrent continuous translation models",
            "show and tell a neural image caption generator",
            "a neural network for learning how to parse tree adjoining grammar"
        ],
        "status": "expanded",
        "title_full": "Grammar as a foreign language",
        "link": "https://arxiv.org/abs/1412.7449",
        "n_parents": 3,
        "year": "2015",
        "children_full_dicts": [
            {
                "ref_title_clean": "sequence to sequence learning with neural networks",
                "ref_title_full": "Sequence to sequence learning with neural networks",
                "year": "2014",
                "full_block": "Sequence to sequence learning with neural networks.\n"
            },
            {
                "ref_title_clean": "neural machine translation by jointly learning to align and translate",
                "ref_title_full": "Neural machine translation by jointly learning to align and translate",
                "year": "2014",
                "full_block": "Neural machine translation by jointly learning to align and\n  translate.\n"
            },
            {
                "ref_title_clean": "addressing the rare word problem in neural machine translation",
                "ref_title_full": "Addressing the rare word problem in neural machine translation",
                "year": "2014",
                "full_block": "Addressing the rare word problem in neural machine translation.\n"
            },
            {
                "ref_title_clean": "on using very large target vocabulary for neural machine translation",
                "ref_title_full": "On using very large target vocabulary for neural machine translation",
                "year": "2014",
                "full_block": "On using very large target vocabulary for neural machine translation.\n"
            },
            {
                "ref_title_clean": "long short term memory",
                "ref_title_full": "Long short term memory",
                "year": "1997",
                "full_block": "Long short-term memory.\n"
            },
            {
                "ref_title_clean": "efficient estimation of word representations in vector space",
                "ref_title_full": "Efficient estimation of word representations in vector space",
                "year": "2013",
                "full_block": "Efficient estimation of word representations in vector space.\n"
            },
            {
                "ref_title_clean": "ontonotes the 90 solution",
                "ref_title_full": "Ontonotes: The 90\\% solution",
                "year": "2006",
                "full_block": "Ontonotes: The 90\\% solution.\n"
            },
            {
                "ref_title_clean": "questionbank creating a corpus of parse annotated questions",
                "ref_title_full": "Questionbank: Creating a corpus of parse annotated questions",
                "year": "2006",
                "full_block": "Questionbank: Creating a corpus of parse-annotated questions.\n"
            },
            {
                "ref_title_clean": "building a large annotated corpus of english the penn treebank",
                "ref_title_full": "Building a large annotated corpus of english: The penn treebank",
                "year": "1993",
                "full_block": "Building a large annotated corpus of english: The penn treebank.\n"
            },
            {
                "ref_title_clean": "ambiguity aware ensemble training for semi supervised dependency parsing",
                "ref_title_full": "Ambiguity aware ensemble training for semi supervised dependency parsing",
                "year": "2014",
                "full_block": "Ambiguity-aware ensemble training for semi-supervised dependency\n  parsing.\n"
            },
            {
                "ref_title_clean": "learning accurate compact and interpretable tree annotation",
                "ref_title_full": "Learning accurate, compact, and interpretable tree annotation",
                "year": "2006",
                "full_block": "Learning accurate, compact, and interpretable tree annotation.\n"
            },
            {
                "ref_title_clean": "fast and accurate shift reduce constituent parsing",
                "ref_title_full": "Fast and accurate shift reduce constituent parsing",
                "year": "2013",
                "full_block": "Fast and accurate shift-reduce constituent parsing.\n"
            },
            {
                "ref_title_clean": "products of random latent variable grammars",
                "ref_title_full": "Products of random latent variable grammars",
                "year": "2010",
                "full_block": "Products of random latent variable grammars.\n"
            },
            {
                "ref_title_clean": "self training pcfg grammars with latent annotations across languages",
                "ref_title_full": "Self training PCFG grammars with latent annotations across languages",
                "year": "2009",
                "full_block": "Self-training {PCFG} grammars with latent annotations across\n  languages.\n"
            },
            {
                "ref_title_clean": "effective self training for parsing",
                "ref_title_full": "Effective self training for parsing",
                "year": "2006",
                "full_block": "Effective self-training for parsing.\n"
            },
            {
                "ref_title_clean": "self training with products of latent variable grammars",
                "ref_title_full": "Self training with products of latent variable grammars",
                "year": "2010",
                "full_block": "Self-training with products of latent variable grammars.\n"
            },
            {
                "ref_title_clean": "sparser better faster gpu parsing",
                "ref_title_full": "Sparser, better, faster gpu parsing",
                "year": "2014",
                "full_block": "Sparser, better, faster gpu parsing.\n"
            },
            {
                "ref_title_clean": "three generative lexicalised models for statistical parsing",
                "ref_title_full": "Three generative, lexicalised models for statistical parsing",
                "year": "1997",
                "full_block": "Three generative, lexicalised models for statistical parsing.\n"
            },
            {
                "ref_title_clean": "accurate unlexicalized parsing",
                "ref_title_full": "Accurate unlexicalized parsing",
                "year": "2003",
                "full_block": "Accurate unlexicalized parsing.\n"
            },
            {
                "ref_title_clean": "inducing history representations for broad coverage statistical parsing",
                "ref_title_full": "Inducing history representations for broad coverage statistical parsing",
                "year": "2003",
                "full_block": "Inducing history representations for broad coverage statistical\n  parsing.\n"
            },
            {
                "ref_title_clean": "discriminative training of a neural network statistical parser",
                "ref_title_full": "Discriminative training of a neural network statistical parser",
                "year": "2004",
                "full_block": "Discriminative training of a neural network statistical parser.\n"
            },
            {
                "ref_title_clean": "constituent parsing with incremental sigmoid belief networks",
                "ref_title_full": "Constituent parsing with incremental sigmoid belief networks",
                "year": "2007",
                "full_block": "Constituent parsing with incremental sigmoid belief networks.\n"
            },
            {
                "ref_title_clean": "deep learning for efficient discriminative parsing",
                "ref_title_full": "Deep learning for efficient discriminative parsing",
                "year": "2011",
                "full_block": "Deep learning for efficient discriminative parsing.\n"
            },
            {
                "ref_title_clean": "parsing natural scenes and natural language with recursive neural networks",
                "ref_title_full": "Parsing natural scenes and natural language with recursive neural networks",
                "year": "2011",
                "full_block": "Parsing natural scenes and natural language with recursive neural\n  networks.\n"
            },
            {
                "ref_title_clean": "a linear observed time statistical parser based on maximum entropy models",
                "ref_title_full": "A linear observed time statistical parser based on maximum entropy models",
                "year": "1997",
                "full_block": "A linear observed time statistical parser based on maximum entropy\n  models.\n"
            },
            {
                "ref_title_clean": "incremental parsing with the perceptron algorithm",
                "ref_title_full": "Incremental parsing with the perceptron algorithm",
                "year": "2004",
                "full_block": "Incremental parsing with the perceptron algorithm.\n"
            },
            {
                "ref_title_clean": "generating sequences with recurrent neural networks",
                "ref_title_full": "Generating sequences with recurrent neural networks",
                "year": "2013",
                "full_block": "Generating sequences with recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "end to end continuous speech recognition using attention based recurrent nn first results",
                "ref_title_full": "End to end continuous speech recognition using attention based recurrent nn: First results",
                "year": "2014",
                "full_block": "End-to-end continuous speech recognition using attention-based\n  recurrent nn: First results.\n"
            },
            {
                "ref_title_clean": "recurrent continuous translation models",
                "ref_title_full": "Recurrent continuous translation models",
                "year": "2013",
                "full_block": "Recurrent continuous translation models.\n"
            },
            {
                "ref_title_clean": "show and tell a neural image caption generator",
                "ref_title_full": "Show and tell: A neural image caption generator",
                "year": "2014",
                "full_block": "Show and tell: A neural image caption generator.\n"
            },
            {
                "ref_title_clean": "a neural network for learning how to parse tree adjoining grammar",
                "ref_title_full": "A neural network for learning how to parse tree adjoining grammar",
                "year": "1990",
                "full_block": "A neural network for learning how to parse tree adjoining grammar.\n"
            }
        ],
        "refs_source": "unpacked_sources/1412.7449/nips2015.bbl"
    },
    "prow a step toward automatic program writing": {
        "id": null,
        "depth": 1,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Prow: A step toward automatic program writing",
        "link": "none",
        "n_parents": 1,
        "year": "1969"
    },
    "show attend and tell neural image caption generation with visual attention": {
        "id": "1502.03044",
        "depth": 1,
        "children_titles": [
            "multiple object recognition with visual attention",
            "neural machine translation by jointly learning to align and translate",
            "the dropout learning algorithm",
            "theano new features and speed improvements",
            "theano a cpu and gpu math expression compiler",
            "learning a recurrent visual representation for image caption generation",
            "learning phrase representations using rnn encoder decoder for statistical machine translation",
            "control of goal directed and stimulus driven attention in the brain",
            "learning where to attend with deep architectures for image tracking",
            "meteor universal language specific translation evaluation for any target language",
            "long term recurrent convolutional networks for visual recognition and description",
            "image description using visual dependency representations",
            "from captions to visual concepts and back",
            "long short term memory",
            "framing image description as a ranking task data models and evaluation metrics",
            "deep visual semantic alignments for generating image descriptions",
            "adam a method for stochastic optimization",
            "multimodal neural language models",
            "unifying visual semantic embeddings with multimodal neural language models",
            "imagenet classification with deep convolutional neural networks",
            "babytalk understanding and generating simple image descriptions",
            "collective generation of natural image descriptions",
            "treetalk composition and compression of trees for image descriptions",
            "learning to combine foveal glimpses with a third order boltzmann machine",
            "composing simple image descriptions using web scale n grams",
            "microsoft coco common objects in context",
            "deep captioning with multimodal recurrent neural networks m rnn",
            "midge generating image descriptions from computer vision detections",
            "recurrent models of visual attention",
            "how to construct deep recurrent neural networks",
            "the dynamic representation of scenes",
            "very deep convolutional networks for large scale image recognition",
            "practical bayesian optimization of machine learning algorithms",
            "input warping for bayesian optimization of non stationary functions",
            "dropout a simple way to prevent neural networks from overfitting",
            "sequence to sequence learning with neural networks",
            "going deeper with convolutions",
            "learning generative models with visual attention",
            "lecture 65 rmsprop",
            "show and tell a neural image caption generator",
            "the optimal reward baseline for gradient based reinforcement learning",
            "simple statistical gradient following algorithms for connectionist reinforcement learning",
            "corpus guided sentence generation of natural images",
            "from image descriptions to visual denotations new similarity metrics for semantic inference over event descriptions",
            "recurrent neural network regularization"
        ],
        "status": "expanded",
        "title_full": "Show, attend and tell: Neural image caption generation with visual attention",
        "link": "https://arxiv.org/abs/1502.03044",
        "n_parents": 3,
        "year": "2015",
        "children_full_dicts": [
            {
                "ref_title_clean": "multiple object recognition with visual attention",
                "ref_title_full": "Multiple object recognition with visual attention",
                "year": "none",
                "full_block": "Multiple object recognition with visual attention.\n"
            },
            {
                "ref_title_clean": "neural machine translation by jointly learning to align and translate",
                "ref_title_full": "Neural machine translation by jointly learning to align and translate",
                "year": "none",
                "full_block": "Neural machine translation by jointly learning to align and\n  translate.\n"
            },
            {
                "ref_title_clean": "the dropout learning algorithm",
                "ref_title_full": "The dropout learning algorithm",
                "year": "2014",
                "full_block": "The dropout learning algorithm.\n"
            },
            {
                "ref_title_clean": "theano new features and speed improvements",
                "ref_title_full": "Theano: new features and speed improvements",
                "year": "2012",
                "full_block": "{T}heano: new features and speed improvements.\n"
            },
            {
                "ref_title_clean": "theano a cpu and gpu math expression compiler",
                "ref_title_full": "Theano: a CPU and GPU math expression compiler",
                "year": "2010",
                "full_block": "Theano: a {CPU} and {GPU} math expression compiler.\n"
            },
            {
                "ref_title_clean": "learning a recurrent visual representation for image caption generation",
                "ref_title_full": "Learning a recurrent visual representation for image caption generation",
                "year": "2014",
                "full_block": "Learning a recurrent visual representation for image caption\n  generation.\n"
            },
            {
                "ref_title_clean": "learning phrase representations using rnn encoder decoder for statistical machine translation",
                "ref_title_full": "Learning phrase representations using RNN encoder decoder for statistical machine translation",
                "year": "2014",
                "full_block": "Learning phrase representations using {RNN} encoder-decoder for\n  statistical machine translation.\n"
            },
            {
                "ref_title_clean": "control of goal directed and stimulus driven attention in the brain",
                "ref_title_full": "Control of goal directed and stimulus driven attention in the brain",
                "year": "2002",
                "full_block": "Control of goal-directed and stimulus-driven attention in the brain.\n"
            },
            {
                "ref_title_clean": "learning where to attend with deep architectures for image tracking",
                "ref_title_full": "Learning where to attend with deep architectures for image tracking",
                "year": "2012",
                "full_block": "Learning where to attend with deep architectures for image tracking.\n"
            },
            {
                "ref_title_clean": "meteor universal language specific translation evaluation for any target language",
                "ref_title_full": "Meteor universal: Language specific translation evaluation for any target language",
                "year": "2014",
                "full_block": "Meteor universal: Language specific translation evaluation for any\n  target language.\n"
            },
            {
                "ref_title_clean": "long term recurrent convolutional networks for visual recognition and description",
                "ref_title_full": "Long term recurrent convolutional networks for visual recognition and description",
                "year": "none",
                "full_block": "Long-term recurrent convolutional networks for visual recognition and\n  description.\n"
            },
            {
                "ref_title_clean": "image description using visual dependency representations",
                "ref_title_full": "Image description using visual dependency representations",
                "year": "2013",
                "full_block": "Image description using visual dependency representations.\n"
            },
            {
                "ref_title_clean": "from captions to visual concepts and back",
                "ref_title_full": "From captions to visual concepts and back",
                "year": "none",
                "full_block": "From captions to visual concepts and back.\n"
            },
            {
                "ref_title_clean": "long short term memory",
                "ref_title_full": "Long short term memory",
                "year": "1997",
                "full_block": "Long short-term memory.\n"
            },
            {
                "ref_title_clean": "framing image description as a ranking task data models and evaluation metrics",
                "ref_title_full": "Framing image description as a ranking task: Data, models and evaluation metrics",
                "year": "2013",
                "full_block": "Framing image description as a ranking task: Data, models and\n  evaluation metrics.\n"
            },
            {
                "ref_title_clean": "deep visual semantic alignments for generating image descriptions",
                "ref_title_full": "Deep visual semantic alignments for generating image descriptions",
                "year": "none",
                "full_block": "Deep visual-semantic alignments for generating image descriptions.\n"
            },
            {
                "ref_title_clean": "adam a method for stochastic optimization",
                "ref_title_full": "Adam: A Method for Stochastic Optimization",
                "year": "none",
                "full_block": "Adam: {A}{ Method for Stochastic Optimization}.\n"
            },
            {
                "ref_title_clean": "multimodal neural language models",
                "ref_title_full": "Multimodal neural language models",
                "year": "none",
                "full_block": "Multimodal neural language models.\n"
            },
            {
                "ref_title_clean": "unifying visual semantic embeddings with multimodal neural language models",
                "ref_title_full": "Unifying visual semantic embeddings with multimodal neural language models",
                "year": "1411",
                "full_block": "Unifying visual-semantic embeddings with multimodal neural language\n  models.\n"
            },
            {
                "ref_title_clean": "imagenet classification with deep convolutional neural networks",
                "ref_title_full": "ImageNet classification with deep convolutional neural networks",
                "year": "2012",
                "full_block": "{ImageNet} classification with deep convolutional neural networks.\n"
            },
            {
                "ref_title_clean": "babytalk understanding and generating simple image descriptions",
                "ref_title_full": "Babytalk: Understanding and generating simple image descriptions",
                "year": "2013",
                "full_block": "Babytalk: Understanding and generating simple image descriptions.\n"
            },
            {
                "ref_title_clean": "collective generation of natural image descriptions",
                "ref_title_full": "Collective generation of natural image descriptions",
                "year": "2012",
                "full_block": "Collective generation of natural image descriptions.\n"
            },
            {
                "ref_title_clean": "treetalk composition and compression of trees for image descriptions",
                "ref_title_full": "Treetalk: Composition and compression of trees for image descriptions",
                "year": "2014",
                "full_block": "Treetalk: Composition and compression of trees for image\n  descriptions.\n"
            },
            {
                "ref_title_clean": "learning to combine foveal glimpses with a third order boltzmann machine",
                "ref_title_full": "Learning to combine foveal glimpses with a third order boltzmann machine",
                "year": "2010",
                "full_block": "Learning to combine foveal glimpses with a third-order boltzmann\n  machine.\n"
            },
            {
                "ref_title_clean": "composing simple image descriptions using web scale n grams",
                "ref_title_full": "Composing simple image descriptions using web scale n grams",
                "year": "2011",
                "full_block": "Composing simple image descriptions using web-scale n-grams.\n"
            },
            {
                "ref_title_clean": "microsoft coco common objects in context",
                "ref_title_full": "Microsoft coco: Common objects in context",
                "year": "2014",
                "full_block": "Microsoft coco: Common objects in context.\n"
            },
            {
                "ref_title_clean": "deep captioning with multimodal recurrent neural networks m rnn",
                "ref_title_full": "Deep captioning with multimodal recurrent neural networks (m rnn)",
                "year": "none",
                "full_block": "Deep captioning with multimodal recurrent neural networks (m-rnn).\n"
            },
            {
                "ref_title_clean": "midge generating image descriptions from computer vision detections",
                "ref_title_full": "Midge: Generating image descriptions from computer vision detections",
                "year": "2012",
                "full_block": "Midge: Generating image descriptions from computer vision detections.\n"
            },
            {
                "ref_title_clean": "recurrent models of visual attention",
                "ref_title_full": "Recurrent models of visual attention",
                "year": "2014",
                "full_block": "Recurrent models of visual attention.\n"
            },
            {
                "ref_title_clean": "how to construct deep recurrent neural networks",
                "ref_title_full": "How to construct deep recurrent neural networks",
                "year": "2014",
                "full_block": "How to construct deep recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "the dynamic representation of scenes",
                "ref_title_full": "The dynamic representation of scenes",
                "year": "2000",
                "full_block": "The dynamic representation of scenes.\n"
            },
            {
                "ref_title_clean": "very deep convolutional networks for large scale image recognition",
                "ref_title_full": "Very deep convolutional networks for large scale image recognition",
                "year": "2014",
                "full_block": "Very deep convolutional networks for large-scale image recognition.\n"
            },
            {
                "ref_title_clean": "practical bayesian optimization of machine learning algorithms",
                "ref_title_full": "Practical bayesian optimization of machine learning algorithms",
                "year": "2012",
                "full_block": "Practical bayesian optimization of machine learning algorithms.\n"
            },
            {
                "ref_title_clean": "input warping for bayesian optimization of non stationary functions",
                "ref_title_full": "Input warping for bayesian optimization of non stationary functions",
                "year": "2014",
                "full_block": "Input warping for bayesian optimization of non-stationary functions.\n"
            },
            {
                "ref_title_clean": "dropout a simple way to prevent neural networks from overfitting",
                "ref_title_full": "Dropout: A simple way to prevent neural networks from overfitting",
                "year": "2014",
                "full_block": "Dropout: A simple way to prevent neural networks from overfitting.\n"
            },
            {
                "ref_title_clean": "sequence to sequence learning with neural networks",
                "ref_title_full": "Sequence to sequence learning with neural networks",
                "year": "2014",
                "full_block": "Sequence to sequence learning with neural networks.\n"
            },
            {
                "ref_title_clean": "going deeper with convolutions",
                "ref_title_full": "Going deeper with convolutions",
                "year": "2014",
                "full_block": "Going deeper with convolutions.\n"
            },
            {
                "ref_title_clean": "learning generative models with visual attention",
                "ref_title_full": "Learning generative models with visual attention",
                "year": "2014",
                "full_block": "Learning generative models with visual attention.\n"
            },
            {
                "ref_title_clean": "lecture 65 rmsprop",
                "ref_title_full": "Lecture 6.5 rmsprop",
                "year": "2012",
                "full_block": "Lecture 6.5 - rmsprop.\n"
            },
            {
                "ref_title_clean": "show and tell a neural image caption generator",
                "ref_title_full": "Show and tell: A neural image caption generator",
                "year": "none",
                "full_block": "Show and tell: A neural image caption generator.\n"
            },
            {
                "ref_title_clean": "the optimal reward baseline for gradient based reinforcement learning",
                "ref_title_full": "The optimal reward baseline for gradient based reinforcement learning",
                "year": "2001",
                "full_block": "The optimal reward baseline for gradient-based reinforcement\n  learning.\n"
            },
            {
                "ref_title_clean": "simple statistical gradient following algorithms for connectionist reinforcement learning",
                "ref_title_full": "Simple statistical gradient following algorithms for connectionist reinforcement learning",
                "year": "1992",
                "full_block": "Simple statistical gradient-following algorithms for connectionist\n  reinforcement learning.\n"
            },
            {
                "ref_title_clean": "corpus guided sentence generation of natural images",
                "ref_title_full": "Corpus guided sentence generation of natural images",
                "year": "2011",
                "full_block": "Corpus-guided sentence generation of natural images.\n"
            },
            {
                "ref_title_clean": "from image descriptions to visual denotations new similarity metrics for semantic inference over event descriptions",
                "ref_title_full": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions",
                "year": "2014",
                "full_block": "From image descriptions to visual denotations: New similarity metrics\n  for semantic inference over event descriptions.\n"
            },
            {
                "ref_title_clean": "recurrent neural network regularization",
                "ref_title_full": "Recurrent neural network regularization",
                "year": "2014",
                "full_block": "Recurrent neural network regularization.\n"
            }
        ],
        "refs_source": "unpacked_sources/1502.03044/capgen.bbl"
    },
    "learning to execute": {
        "id": "1410.4615",
        "depth": 1,
        "children_titles": [
            "curriculum learning",
            "advances in optimizing recurrent networks",
            "can recursive neural tensor networks learn logical reasoning",
            "recursive neural networks for learning logical semantics",
            "learning phrase representations using rnn encoder decoder for statistical machine translation",
            "speech recognition with deep recurrent neural networks",
            "a statistical derivation of the significant digit law",
            "long short term memory",
            "optimization and applications of echo state networks with leaky integrator neurons",
            "a clockwork rnn",
            "self paced learning for latent variable models",
            "learning the easy things first self paced visual category discovery",
            "structured generative models of natural source code",
            "deep learning via hessian free optimization",
            "statistical language models based on neural networks",
            "recurrent neural network based language model",
            "building program vector representations for deep learning",
            "how to construct deep recurrent neural networks",
            "dropout improves recurrent neural networks for handwriting recognition",
            "the use of recurrent neural networks in continuous speech recognition",
            "training recurrent neural networks",
            "sequence to sequence learning with neural networks",
            "learning to discover efficient mathematical identities",
            "recurrent neural network regularization"
        ],
        "status": "expanded",
        "title_full": "Learning to execute",
        "link": "https://arxiv.org/abs/1410.4615",
        "n_parents": 5,
        "year": "2014",
        "children_full_dicts": [
            {
                "ref_title_clean": "curriculum learning",
                "ref_title_full": "Curriculum learning",
                "year": "2009",
                "full_block": "Curriculum learning.\n"
            },
            {
                "ref_title_clean": "advances in optimizing recurrent networks",
                "ref_title_full": "Advances in optimizing recurrent networks",
                "year": "2013",
                "full_block": "Advances in optimizing recurrent networks.\n"
            },
            {
                "ref_title_clean": "can recursive neural tensor networks learn logical reasoning",
                "ref_title_full": "Can recursive neural tensor networks learn logical reasoning?",
                "year": "2013",
                "full_block": "Can recursive neural tensor networks learn logical reasoning?\n"
            },
            {
                "ref_title_clean": "recursive neural networks for learning logical semantics",
                "ref_title_full": "Recursive neural networks for learning logical semantics",
                "year": "2014",
                "full_block": "Recursive neural networks for learning logical semantics.\n"
            },
            {
                "ref_title_clean": "learning phrase representations using rnn encoder decoder for statistical machine translation",
                "ref_title_full": "Learning phrase representations using rnn encoder decoder for statistical machine translation",
                "year": "2014",
                "full_block": "Learning phrase representations using rnn encoder-decoder for\n  statistical machine translation.\n"
            },
            {
                "ref_title_clean": "speech recognition with deep recurrent neural networks",
                "ref_title_full": "Speech recognition with deep recurrent neural networks",
                "year": "2013",
                "full_block": "Speech recognition with deep recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "a statistical derivation of the significant digit law",
                "ref_title_full": "A statistical derivation of the significant digit law",
                "year": "1995",
                "full_block": "A statistical derivation of the significant-digit law.\n"
            },
            {
                "ref_title_clean": "long short term memory",
                "ref_title_full": "Long short term memory",
                "year": "1997",
                "full_block": "Long short-term memory.\n"
            },
            {
                "ref_title_clean": "optimization and applications of echo state networks with leaky integrator neurons",
                "ref_title_full": "Optimization and applications of echo state networks with leaky integrator neurons",
                "year": "2007",
                "full_block": "Optimization and applications of echo state networks with\n  leaky-integrator neurons.\n"
            },
            {
                "ref_title_clean": "a clockwork rnn",
                "ref_title_full": "A clockwork rnn",
                "year": "2014",
                "full_block": "A clockwork rnn.\n"
            },
            {
                "ref_title_clean": "self paced learning for latent variable models",
                "ref_title_full": "Self paced learning for latent variable models",
                "year": "2010",
                "full_block": "Self-paced learning for latent variable models.\n"
            },
            {
                "ref_title_clean": "learning the easy things first self paced visual category discovery",
                "ref_title_full": "Learning the easy things first: Self paced visual category discovery",
                "year": "2011",
                "full_block": "Learning the easy things first: Self-paced visual category discovery.\n"
            },
            {
                "ref_title_clean": "structured generative models of natural source code",
                "ref_title_full": "Structured generative models of natural source code",
                "year": "2014",
                "full_block": "Structured generative models of natural source code.\n"
            },
            {
                "ref_title_clean": "deep learning via hessian free optimization",
                "ref_title_full": "Deep learning via hessian free optimization",
                "year": "2010",
                "full_block": "Deep learning via hessian-free optimization.\n"
            },
            {
                "ref_title_clean": "statistical language models based on neural networks",
                "ref_title_full": "\\Statistical language models based on neural networks",
                "year": "2012",
                "full_block": "\\emph{Statistical language models based on neural networks}.\n"
            },
            {
                "ref_title_clean": "recurrent neural network based language model",
                "ref_title_full": "Recurrent neural network based language model",
                "year": "2010",
                "full_block": "Recurrent neural network based language model.\n"
            },
            {
                "ref_title_clean": "building program vector representations for deep learning",
                "ref_title_full": "Building program vector representations for deep learning",
                "year": "2014",
                "full_block": "Building program vector representations for deep learning.\n"
            },
            {
                "ref_title_clean": "how to construct deep recurrent neural networks",
                "ref_title_full": "How to construct deep recurrent neural networks",
                "year": "2013",
                "full_block": "How to construct deep recurrent neural networks.\n"
            },
            {
                "ref_title_clean": "dropout improves recurrent neural networks for handwriting recognition",
                "ref_title_full": "Dropout improves recurrent neural networks for handwriting recognition",
                "year": "2013",
                "full_block": "Dropout improves recurrent neural networks for handwriting\n  recognition.\n"
            },
            {
                "ref_title_clean": "the use of recurrent neural networks in continuous speech recognition",
                "ref_title_full": "The use of recurrent neural networks in continuous speech recognition",
                "year": "1996",
                "full_block": "The use of recurrent neural networks in continuous speech\n  recognition.\n"
            },
            {
                "ref_title_clean": "training recurrent neural networks",
                "ref_title_full": "\\Training Recurrent Neural Networks",
                "year": "2013",
                "full_block": "\\emph{Training Recurrent Neural Networks}.\n"
            },
            {
                "ref_title_clean": "sequence to sequence learning with neural networks",
                "ref_title_full": "Sequence to sequence learning with neural networks",
                "year": "2014",
                "full_block": "Sequence to sequence learning with neural networks.\n"
            },
            {
                "ref_title_clean": "learning to discover efficient mathematical identities",
                "ref_title_full": "Learning to discover efficient mathematical identities",
                "year": "none",
                "full_block": "Learning to discover efficient mathematical identities.\n"
            },
            {
                "ref_title_clean": "recurrent neural network regularization",
                "ref_title_full": "Recurrent neural network regularization",
                "year": "none",
                "full_block": "Recurrent neural network regularization.\n"
            }
        ],
        "refs_source": "unpacked_sources/1410.4615/algebra.bbl"
    },
    "domain adaptation via pseudo in domain data selection": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Domain adaptation via pseudo in domain data selection",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "theano new features and speed improvements": {
        "id": "1211.5590",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Theano: new features and speed improvements",
        "link": "https://arxiv.org/abs/1211.5590",
        "n_parents": 2,
        "year": "none"
    },
    "learning long term dependencies with gradient descent is difficult": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Learning long term dependencies with gradient descent is difficult",
        "link": "none",
        "n_parents": 5,
        "year": "none"
    },
    "a neural probabilistic language model": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "A neural probabilistic language model",
        "link": "none",
        "n_parents": 2,
        "year": "none"
    },
    "theano a cpu and gpu math expression compiler": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Theano: a CPU and GPU math expression compiler",
        "link": "none",
        "n_parents": 2,
        "year": "none"
    },
    "audio chord recognition with recurrent neural networks": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Audio chord recognition with recurrent neural networks",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "learning phrase representations using rnn encoder decoder for statistical machine translation": {
        "id": "1406.1078",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Learning phrase representations using RNN encoder decoder for statistical machine translation",
        "link": "https://arxiv.org/abs/1406.1078",
        "n_parents": 6,
        "year": "none"
    },
    "on the properties of neural machine translation encoder decoder approaches": {
        "id": "1409.1259",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "On the properties of neural machine translation: Encoder Decoder approaches",
        "link": "https://arxiv.org/abs/1409.1259",
        "n_parents": 2,
        "year": "none"
    },
    "fast and robust neural network joint models for statistical machine translation": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Fast and robust neural network joint models for statistical machine translation",
        "link": "none",
        "n_parents": 2,
        "year": "none"
    },
    "recursive hetero associative memories for translation": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Recursive hetero associative memories for translation",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "maxout networks": {
        "id": "1302.4389",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Maxout networks",
        "link": "https://arxiv.org/abs/1302.4389",
        "n_parents": 1,
        "year": "none"
    },
    "sequence transduction with recurrent neural networks": {
        "id": "1211.3711",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Sequence transduction with recurrent neural networks",
        "link": "https://arxiv.org/abs/1211.3711",
        "n_parents": 1,
        "year": "none"
    },
    "generating sequences with recurrent neural networks": {
        "id": "1308.0850",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Generating sequences with recurrent neural networks",
        "link": "https://arxiv.org/abs/1308.0850",
        "n_parents": 6,
        "year": "1308"
    },
    "hybrid speech recognition with deep bidirectional lstm": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Hybrid speech recognition with deep bidirectional LSTM",
        "link": "none",
        "n_parents": 2,
        "year": "none"
    },
    "multilingual distributed representations without word alignment": {
        "id": "1312.6173",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Multilingual distributed representations without word alignment",
        "link": "https://arxiv.org/abs/1312.6173",
        "n_parents": 2,
        "year": "none"
    },
    "long short term memory": {
        "id": "1507.01526",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Long short term memory",
        "link": "https://arxiv.org/abs/1507.01526",
        "n_parents": 14,
        "year": "none"
    },
    "recurrent continuous translation models": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Recurrent continuous translation models",
        "link": "none",
        "n_parents": 4,
        "year": "none"
    },
    "statistical machine translation": {
        "id": "1809.01272",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Statistical Machine Translation\\/",
        "link": "https://arxiv.org/abs/1809.01272",
        "n_parents": 1,
        "year": "none"
    },
    "statistical phrase based translation": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Statistical phrase based translation",
        "link": "none",
        "n_parents": 2,
        "year": "none"
    },
    "on the difficulty of training recurrent neural networks": {
        "id": "1211.5063",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "On the difficulty of training recurrent neural networks",
        "link": "https://arxiv.org/abs/1211.5063",
        "n_parents": 3,
        "year": "none"
    },
    "how to construct deep recurrent neural networks": {
        "id": "1312.6026",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "How to construct deep recurrent neural networks",
        "link": "https://arxiv.org/abs/1312.6026",
        "n_parents": 3,
        "year": "none"
    },
    "overcoming the curse of sentence length for neural machine translation using automatic segmentation": {
        "id": "1409.1257",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Overcoming the curse of sentence length for neural machine translation using automatic segmentation",
        "link": "https://arxiv.org/abs/1409.1257",
        "n_parents": 2,
        "year": "none"
    },
    "bidirectional recurrent neural networks": {
        "id": "1604.03390",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Bidirectional recurrent neural networks",
        "link": "https://arxiv.org/abs/1604.03390",
        "n_parents": 1,
        "year": "none"
    },
    "continuous space translation models for phrase based statistical machine translation": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Continuous space translation models for phrase based statistical machine translation",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "continuous space language models for statistical machine translation": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Continuous space language models for statistical machine translation",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "adadelta an adaptive learning rate method": {
        "id": "1212.5701",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "ADADELTA: An adaptive learning rate method",
        "link": "https://arxiv.org/abs/1212.5701",
        "n_parents": 1,
        "year": "1212"
    },
    "deepmath deep sequence models for premise selection": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "DeepMath deep sequence models for premise selection",
        "link": "none",
        "n_parents": 1,
        "year": "2016"
    },
    "adaptive neural compilation": {
        "id": "1605.07969",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Adaptive neural compilation",
        "link": "https://arxiv.org/abs/1605.07969",
        "n_parents": 4,
        "year": "2016"
    },
    "the helmholtz machine": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "The Helmholtz machine",
        "link": "none",
        "n_parents": 1,
        "year": "1995"
    },
    "on label dependence and loss minimization in multi label classification": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "On label dependence and loss minimization in multi label classification",
        "link": "none",
        "n_parents": 1,
        "year": "2012"
    },
    "bayes optimal multilabel classification via probabilistic classifier chains": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Bayes optimal multilabel classification via probabilistic classifier chains",
        "link": "none",
        "n_parents": 1,
        "year": "2010"
    },
    "synthesizing data structure transformations from input output examples": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Synthesizing data structure transformations from input output examples",
        "link": "none",
        "n_parents": 1,
        "year": "2015"
    },
    "learning to transduce with unbounded memory": {
        "id": "1506.02516",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Learning to transduce with unbounded memory",
        "link": "https://arxiv.org/abs/1506.02516",
        "n_parents": 4,
        "year": "2015"
    },
    "programming by examples applications algorithms and ambiguity resolution": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Programming by examples: Applications, algorithms, and ambiguity resolution",
        "link": "none",
        "n_parents": 1,
        "year": "2016"
    },
    "synthesis of loop free programs": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Synthesis of loop free programs",
        "link": "none",
        "n_parents": 2,
        "year": "2011"
    },
    "learning to pass expectation propagation messages": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Learning to pass expectation propagation messages",
        "link": "none",
        "n_parents": 1,
        "year": "2013"
    },
    "the informed sampler a discriminative approach to bayesian inference in generative computer vision models": {
        "id": "1402.0859",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "The informed sampler: A discriminative approach to Bayesian inference in generative computer vision models",
        "link": "https://arxiv.org/abs/1402.0859",
        "n_parents": 1,
        "year": "2015"
    },
    "stochastic gradient vb and the variational auto encoder": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Stochastic gradient VB and the variational auto encoder",
        "link": "none",
        "n_parents": 1,
        "year": "2014"
    },
    "gated graph sequence neural networks": {
        "id": "1511.05493",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Gated graph sequence neural networks",
        "link": "https://arxiv.org/abs/1511.05493",
        "n_parents": 1,
        "year": "2016"
    },
    "latent predictor networks for code generation": {
        "id": "1603.06744",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Latent predictor networks for code generation",
        "link": "https://arxiv.org/abs/1603.06744",
        "n_parents": 1,
        "year": "2016"
    },
    "deep network guided proof search": {
        "id": "1701.06972",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Deep network guided proof search",
        "link": "https://arxiv.org/abs/1701.06972",
        "n_parents": 1,
        "year": "2017"
    },
    "learning program embeddings to propagate feedback on student code": {
        "id": "1505.05969",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Learning program embeddings to propagate feedback on student code",
        "link": "https://arxiv.org/abs/1505.05969",
        "n_parents": 1,
        "year": "2015"
    },
    "stochastic program optimization": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Stochastic program optimization",
        "link": "none",
        "n_parents": 1,
        "year": "2016"
    },
    "real time human pose recognition in parts from single depth images": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Real time human pose recognition in parts from single depth images",
        "link": "none",
        "n_parents": 1,
        "year": "2013"
    },
    "predicting a correct program in programming by example": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Predicting a correct program in programming by example",
        "link": "none",
        "n_parents": 1,
        "year": "2015"
    },
    "program synthesis by sketching": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "\\Program Synthesis By Sketching",
        "link": "none",
        "n_parents": 3,
        "year": "2008"
    },
    "learning stochastic inverses": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Learning stochastic inverses",
        "link": "none",
        "n_parents": 1,
        "year": "2013"
    },
    "end to end memory networks": {
        "id": "1503.08895",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "End to end memory networks",
        "link": "https://arxiv.org/abs/1503.08895",
        "n_parents": 4,
        "year": "2015"
    },
    "memory networks": {
        "id": "1410.3916",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Memory networks",
        "link": "https://arxiv.org/abs/1410.3916",
        "n_parents": 5,
        "year": "2015"
    },
    "learning simple algorithms from examples": {
        "id": "1511.07275",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Learning simple algorithms from examples",
        "link": "https://arxiv.org/abs/1511.07275",
        "n_parents": 3,
        "year": "2016"
    },
    "control flow analysis": {
        "id": "1512.03861",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Control flow analysis",
        "link": "https://arxiv.org/abs/1512.03861",
        "n_parents": 1,
        "year": "1970"
    },
    "the toolsmt lib standard version 25": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "The \\toolSMT LIB standard: Version 2.5",
        "link": "none",
        "n_parents": 1,
        "year": "2015"
    },
    "the inference of regular lisp programs from examples": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "The inference of regular lisp programs from examples",
        "link": "none",
        "n_parents": 2,
        "year": "1978"
    },
    "stan a probabilistic programming language": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Stan: A probabilistic programming language",
        "link": "none",
        "n_parents": 1,
        "year": "2015"
    },
    "bounded model checking using satisfiability solving": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Bounded model checking using satisfiability solving",
        "link": "none",
        "n_parents": 1,
        "year": "2001"
    },
    "using prior knowledge in a nnpda to learn context free languages": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Using prior knowledge in a \\NNPDA\\ to learn context free languages",
        "link": "none",
        "n_parents": 2,
        "year": "1992"
    },
    "identifying and attacking the saddle point problem in high dimensional non convex optimization": {
        "id": "1406.2572",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Identifying and attacking the saddle point problem in high dimensional non convex optimization",
        "link": "https://arxiv.org/abs/1406.2572",
        "n_parents": 1,
        "year": "2014"
    },
    "z3 an efficient smt solver": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Z3: an efficient SMT solver",
        "link": "none",
        "n_parents": 1,
        "year": "2008"
    },
    "unsupervised learning by program synthesis": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Unsupervised learning by program synthesis",
        "link": "none",
        "n_parents": 1,
        "year": "2015"
    },
    "higher order recurrent networks and grammatical inference": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Higher order recurrent networks and grammatical inference",
        "link": "none",
        "n_parents": 1,
        "year": "1989"
    },
    "church a language for generative models": {
        "id": "1206.3255",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Church: a language for generative models",
        "link": "https://arxiv.org/abs/1206.3255",
        "n_parents": 2,
        "year": "2008"
    },
    "program verification as probabilistic inference": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Program verification as probabilistic inference",
        "link": "none",
        "n_parents": 1,
        "year": "2007"
    },
    "a clockwork rnn": {
        "id": "1402.3511",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "A clockwork RNN",
        "link": "https://arxiv.org/abs/1402.3511",
        "n_parents": 2,
        "year": "2014"
    },
    "complete functional synthesis": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Complete functional synthesis",
        "link": "none",
        "n_parents": 1,
        "year": "2010"
    },
    "human level concept learning through probabilistic program induction": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Human level concept learning through probabilistic program induction",
        "link": "none",
        "n_parents": 1,
        "year": "2015"
    },
    "llvm a compilation framework for lifelong program analysis  transformation": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Llvm: A compilation framework for lifelong program analysis \\& transformation",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "learning longer memory in recurrent neural networks": {
        "id": "1412.7753",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Learning longer memory in recurrent neural networks",
        "link": "https://arxiv.org/abs/1412.7753",
        "n_parents": 2,
        "year": "2015"
    },
    "microsoft research cambridge httpresearchmicrosoftcominfernet": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Microsoft Research Cambridge. http://research.microsoft.com/infernet",
        "link": "none",
        "n_parents": 1,
        "year": "2014"
    },
    "gates": {
        "id": "1506.08251",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Gates",
        "link": "https://arxiv.org/abs/1506.08251",
        "n_parents": 1,
        "year": "2009"
    },
    "a connectionist symbol manipulator that discovers the structure of context free languages": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "A connectionist symbol manipulator that discovers the structure of context free languages",
        "link": "none",
        "n_parents": 2,
        "year": "1992"
    },
    "adding gradient noise improves learning for very deep networks": {
        "id": "1511.06807",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Adding gradient noise improves learning for very deep networks",
        "link": "https://arxiv.org/abs/1511.06807",
        "n_parents": 4,
        "year": "none"
    },
    "automatic sampler discovery via probabilistic programming and approximate bayesian computation": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Automatic sampler discovery via probabilistic programming and approximate bayesian computation",
        "link": "none",
        "n_parents": 1,
        "year": "2016"
    },
    "chlorophyll synthesis aided compiler for low power spatial architectures": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Chlorophyll: synthesis aided compiler for low power spatial architectures",
        "link": "none",
        "n_parents": 1,
        "year": "2014"
    },
    "learning programs from noisy data": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Learning programs from noisy data",
        "link": "none",
        "n_parents": 1,
        "year": "2016"
    },
    "counterexample guided quantifier instantiation for synthesis in smt": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Counterexample guided quantifier instantiation for synthesis in SMT",
        "link": "none",
        "n_parents": 1,
        "year": "2015"
    },
    "stochastic superoptimization": {
        "id": "1211.0557",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Stochastic superoptimization",
        "link": "https://arxiv.org/abs/1211.0557",
        "n_parents": 2,
        "year": "2013"
    },
    "syntactic analysis of two dimensional visual signals in the presence of noise": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Syntactic analysis of two dimensional visual signals in the presence of noise",
        "link": "none",
        "n_parents": 1,
        "year": "1976"
    },
    "blinkfill semi supervised programming by example for syntactic string transformations": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Blinkfill: Semi supervised programming by example for syntactic string transformations",
        "link": "none",
        "n_parents": 1,
        "year": "2016"
    },
    "automated feedback generation for introductory programming assignments": {
        "id": "1204.1751",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Automated feedback generation for introductory programming assignments",
        "link": "https://arxiv.org/abs/1204.1751",
        "n_parents": 2,
        "year": "2013"
    },
    "programming by sketching for bit streaming programs": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Programming by sketching for bit streaming programs",
        "link": "none",
        "n_parents": 3,
        "year": "2005"
    },
    "combinatorial sketching for finite programs": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Combinatorial sketching for finite programs",
        "link": "none",
        "n_parents": 2,
        "year": "2006"
    },
    "tightening lp relaxations for map using message passing": {
        "id": "1206.3288",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Tightening lp relaxations for map using message passing",
        "link": "https://arxiv.org/abs/1206.3288",
        "n_parents": 1,
        "year": "2008"
    },
    "url urlhttpmc stanorg": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "URL \\urlhttp://mc stan.org/",
        "link": "none",
        "n_parents": 1,
        "year": "2015"
    },
    "a methodology for lisp program construction from examples": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "A methodology for lisp program construction from examples",
        "link": "none",
        "n_parents": 2,
        "year": "1977"
    },
    "lecture 65 rmsprop divide the gradient by a running average of its recent magnitude": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Lecture 6.5 RmsProp: Divide the gradient by a running average of its recent magnitude",
        "link": "none",
        "n_parents": 1,
        "year": "2012"
    },
    "transit specifying protocols with concolic snippets": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "TRANSIT: specifying protocols with concolic snippets",
        "link": "none",
        "n_parents": 2,
        "year": "2013"
    },
    "graphical models exponential families and variational inference": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Graphical models, exponential families, and variational inference",
        "link": "none",
        "n_parents": 1,
        "year": "2008"
    },
    "a linear programming approach to max sum problem a review": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "A linear programming approach to max sum problem: A review",
        "link": "none",
        "n_parents": 1,
        "year": "2007"
    },
    "memory": {
        "id": "1003.0140",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Memory",
        "link": "https://arxiv.org/abs/1003.0140",
        "n_parents": 1,
        "year": "none"
    },
    "time constraints and resource sharing in adults working memory spans": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Time constraints and resource sharing in adults' working memory spans",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "three models for the description of language": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Three models for the description of language",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "learning context free grammars capabilities and limitations of a recurrent neural network with an external stack memory": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Learning context free grammars: Capabilities and limitations of a recurrent neural network with an external stack memory",
        "link": "none",
        "n_parents": 3,
        "year": "none"
    },
    "simple substrates for complex cognition": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Simple substrates for complex cognition",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "how to build a brain a neural architecture for biological cognition": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "How to build a brain: A neural architecture for biological cognition",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "the evolution of the language faculty clarifications and implications": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "The evolution of the language faculty: clarifications and implications",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "connectionism and cognitive architecture a critical analysis": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Connectionism and cognitive architecture: A critical analysis",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "a general framework for adaptive processing of data structures": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "A general framework for adaptive processing of data structures",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "memory and the computational brain why cognitive science will transform neuroscience volume3": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Memory and the computational brain: Why cognitive science will transform neuroscience, volume~3",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "cellular basis of working memory": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Cellular basis of working memory",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "towards end to end speech recognition with recurrent neural networks": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Towards end to end speech recognition with recurrent neural networks",
        "link": "none",
        "n_parents": 2,
        "year": "none"
    },
    "speech recognition with deep recurrent neural networks": {
        "id": "1303.5778",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Speech recognition with deep recurrent neural networks",
        "link": "https://arxiv.org/abs/1303.5778",
        "n_parents": 2,
        "year": "none"
    },
    "the problem of rapid variable creation": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "The problem of rapid variable creation",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "banishing the homunculus making working memory work": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Banishing the homunculus: making working memory work",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "learning distributed representations of concepts": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Learning distributed representations of concepts",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "gradient flow in recurrent nets the difficulty of learning long term dependencies": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Gradient flow in recurrent nets: the difficulty of learning long term dependencies",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "learning to learn using gradient descent": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Learning to learn using gradient descent",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "neural networks and physical systems with emergent collective computational abilities": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Neural networks and physical systems with emergent collective computational abilities",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "the nature of the language faculty and its implications for evolution of language reply to fitch hauser and chomsky": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "The nature of the language faculty and its implications for evolution of language (reply to fitch, hauser, and chomsky)",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "hyperdimensional computing an introduction to computing in distributed representation with high dimensional random vectors": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Hyperdimensional computing: An introduction to computing in distributed representation with high dimensional random vectors",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "the algebraic mind integrating connectionism and cognitive science": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "The algebraic mind: Integrating connectionism and cognitive science",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "the magical number seven plus or minus two some limits on our capacity for processing information": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "The magical number seven, plus or minus two: some limits on our capacity for processing information",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "the cognitive revolution a historical perspective": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "The cognitive revolution: a historical perspective",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "computation finite and infinite machines": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Computation: finite and infinite machines",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "machine learning a probabilistic perspective": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Machine learning: a probabilistic perspective",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "holographic reduced representation distributed representation for cognitive structures": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Holographic Reduced Representation: Distributed representation for cognitive structures",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "recursive distributed representations": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Recursive distributed representations",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "the importance of mixed selectivity in complex cognitive tasks": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "The importance of mixed selectivity in complex cognitive tasks",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "parallel distributed processing volume1": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Parallel distributed processing, volume~1",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "continuous attractors and oculomotor control": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Continuous attractors and oculomotor control",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "on the computational power of neural nets": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "On the computational power of neural nets",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "tensor product variable binding and the representation of symbolic structures in connectionist systems": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Tensor product variable binding and the representation of symbolic structures in connectionist systems",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "semantic compositionality through recursive matrix vector spaces": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Semantic compositionality through recursive matrix vector spaces",
        "link": "none",
        "n_parents": 2,
        "year": "none"
    },
    "generating text with recurrent neural networks": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Generating text with recurrent neural networks",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "boltzcons dynamic symbol structures in a connectionist network": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Boltzcons: Dynamic symbol structures in a connectionist network",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "first draft of a report on the edvac": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "First draft of a report on the edvac",
        "link": "none",
        "n_parents": 2,
        "year": "none"
    },
    "synaptic basis of cortical persistent activity the importance of nmda receptors to working memory": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Synaptic basis of cortical persistent activity: the importance of nmda receptors to working memory",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "scaling learning algorithms towards ai": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Scaling learning algorithms towards ai",
        "link": "none",
        "n_parents": 1,
        "year": "2007"
    },
    "pattern recognition and machine learning": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Pattern recognition and machine learning",
        "link": "none",
        "n_parents": 1,
        "year": "2006"
    },
    "context free and context sensitive dynamics in recurrent neural networks": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Context free and context sensitive dynamics in recurrent neural networks",
        "link": "none",
        "n_parents": 1,
        "year": "2000"
    },
    "large scale machine learning with stochastic gradient descent": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Large scale machine learning with stochastic gradient descent",
        "link": "none",
        "n_parents": 1,
        "year": "2010"
    },
    "random forests": {
        "id": "1507.06105",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Random forests",
        "link": "https://arxiv.org/abs/1507.06105",
        "n_parents": 1,
        "year": "2001"
    },
    "probabilistic interpretation of feedforward classification network outputs with relationships to statistical pattern recognition": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Probabilistic interpretation of feedforward classification network outputs, with relationships to statistical pattern recognition",
        "link": "none",
        "n_parents": 1,
        "year": "1990"
    },
    "toward a connectionist model of recursion in human linguistic performance": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Toward a connectionist model of recursion in human linguistic performance",
        "link": "none",
        "n_parents": 1,
        "year": "1999"
    },
    "gated feedback recurrent neural networks": {
        "id": "1502.02367",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Gated feedback recurrent neural networks",
        "link": "https://arxiv.org/abs/1502.02367",
        "n_parents": 1,
        "year": "2015"
    },
    "high performance neural networks for visual object classification": {
        "id": "1102.0183",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "High performance neural networks for visual object classification",
        "link": "https://arxiv.org/abs/1102.0183",
        "n_parents": 1,
        "year": "2011"
    },
    "mechanisms for sentence processing": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Mechanisms for sentence processing",
        "link": "none",
        "n_parents": 1,
        "year": "1996"
    },
    "context dependent pre trained deep neural networks for large vocabulary speech recognition": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Context dependent pre trained deep neural networks for large vocabulary speech recognition",
        "link": "none",
        "n_parents": 3,
        "year": "2012"
    },
    "finding structure in time": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Finding structure in time",
        "link": "none",
        "n_parents": 2,
        "year": "1990"
    },
    "context free parsing in connectionist networks": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Context free parsing in connectionist networks",
        "link": "none",
        "n_parents": 1,
        "year": "1994"
    },
    "lstm recurrent networks learn simple context free and context sensitive languages": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Lstm recurrent networks learn simple context free and context sensitive languages",
        "link": "none",
        "n_parents": 2,
        "year": "2001"
    },
    "a recurrent network that performs a context sensitive prediction task": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "A recurrent network that performs a context sensitive prediction task",
        "link": "none",
        "n_parents": 2,
        "year": "1996"
    },
    "designing a counter another case study of dynamics and activation landscapes in recurrent networks": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Designing a counter: Another case study of dynamics and activation landscapes in recurrent networks",
        "link": "none",
        "n_parents": 1,
        "year": "1997"
    },
    "imagenet classification with deep convolutional neural networks": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Imagenet classification with deep convolutional neural networks",
        "link": "none",
        "n_parents": 4,
        "year": "2012"
    },
    "gradient based learning applied to document recognition": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Gradient based learning applied to document recognition",
        "link": "none",
        "n_parents": 2,
        "year": "none"
    },
    "statistical language models based on neural networks": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Statistical language models based on neural networks",
        "link": "none",
        "n_parents": 4,
        "year": "2012"
    },
    "perceptrons": {
        "id": "1306.4375",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Perceptrons",
        "link": "https://arxiv.org/abs/1306.4375",
        "n_parents": 1,
        "year": "1969"
    },
    "the induction of dynamical recognizers": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "The induction of dynamical recognizers",
        "link": "none",
        "n_parents": 1,
        "year": "1991"
    },
    "hogwild a lock free approach to parallelizing stochastic gradient descent": {
        "id": "1106.5730",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Hogwild: A lock free approach to parallelizing stochastic gradient descent",
        "link": "https://arxiv.org/abs/1106.5730",
        "n_parents": 1,
        "year": "2011"
    },
    "a recurrent neural network that learns to count": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "A recurrent neural network that learns to count",
        "link": "none",
        "n_parents": 1,
        "year": "1999"
    },
    "learning internal representations by error propagation": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Learning internal representations by error propagation",
        "link": "none",
        "n_parents": 1,
        "year": "1985"
    },
    "fractal encoding of context free grammars in connectionist networks": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Fractal encoding of context free grammars in connectionist networks",
        "link": "none",
        "n_parents": 1,
        "year": "2000"
    },
    "generalization of backpropagation with application to a recurrent gas market model": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Generalization of backpropagation with application to a recurrent gas market model",
        "link": "none",
        "n_parents": 1,
        "year": "1988"
    },
    "learning to count without a counter a case study of dynamics and activation landscapes in recurrent networks": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Learning to count without a counter: A case study of dynamics and activation landscapes in recurrent networks",
        "link": "none",
        "n_parents": 1,
        "year": "1995"
    },
    "gradient based learning algorithms for recurrent networks and their computational complexity": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Gradient based learning algorithms for recurrent networks and their computational complexity",
        "link": "none",
        "n_parents": 1,
        "year": "1995"
    },
    "discrete recurrent neural networks for grammatical inference": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Discrete recurrent neural networks for grammatical inference",
        "link": "none",
        "n_parents": 2,
        "year": "1994"
    },
    "learning regaular sets from queries and counterexamples": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Learning regaular sets from queries and counterexamples",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "url httparxiv": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "URL http://arxiv",
        "link": "none",
        "n_parents": 16,
        "year": "none"
    },
    "automatic structures": {
        "id": "1710.01802",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Automatic Structures",
        "link": "https://arxiv.org/abs/1710.01802",
        "n_parents": 1,
        "year": "none"
    },
    "listen attend and spell": {
        "id": "1508.01211",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Listen, attend and spell",
        "link": "https://arxiv.org/abs/1508.01211",
        "n_parents": 3,
        "year": "none"
    },
    "empirical evaluation of gated recurrent neural networks on sequence modeling": {
        "id": "1412.3555",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Empirical evaluation of gated recurrent neural networks on sequence modeling",
        "link": "https://arxiv.org/abs/1412.3555",
        "n_parents": 1,
        "year": "none"
    },
    "8 \fpublished as a conference paper at iclr 2016 grefenstette edward hermann karl moritz suleyman mustafa and blunsom learning to transduce with unbounded memory": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "8 \fPublished as a conference paper at ICLR 2016 Grefenstette, Edward, Hermann, Karl Moritz, Suleyman, Mustafa, and Blunsom, Learning to transduce with unbounded memory",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "httparxiv": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "http://arxiv",
        "link": "none",
        "n_parents": 2,
        "year": "none"
    },
    "dimensions in program synthesis": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Dimensions in program synthesis",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "inductive programming a survey of program synthesis techniques": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Inductive programming: A survey of program synthesis techniques",
        "link": "none",
        "n_parents": 2,
        "year": "none"
    },
    "imagenet classification with deep convolutional neural network": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Imagenet classification with deep convolutional neural network",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "variable rate image compression with recurrent neural networks": {
        "id": "1511.06085",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Variable rate image compression with recurrent neural networks",
        "link": "https://arxiv.org/abs/1511.06085",
        "n_parents": 1,
        "year": "none"
    },
    "an introduction to cellular automata": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "An Introduction to cellular automata",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "bayesian learning via stochastic gradient langevin dynamics": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Bayesian learning via stochastic gradient Langevin dynamics",
        "link": "none",
        "n_parents": 2,
        "year": "none"
    },
    "curriculum learning": {
        "id": "1707.00183",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Curriculum learning",
        "link": "https://arxiv.org/abs/1707.00183",
        "n_parents": 2,
        "year": "2009"
    },
    "grid long short term memory": {
        "id": "1507.01526",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Grid long short term memory",
        "link": "https://arxiv.org/abs/1507.01526",
        "n_parents": 1,
        "year": "2015"
    },
    "adam a method for stochastic optimization": {
        "id": "1412.6980",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Adam: A method for stochastic optimization",
        "link": "https://arxiv.org/abs/1412.6980",
        "n_parents": 5,
        "year": "2014"
    },
    "rectified linear units improve restricted boltzmann machines": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Rectified linear units improve restricted boltzmann machines",
        "link": "none",
        "n_parents": 1,
        "year": "2010"
    },
    "a formal theory of inductive inference part i": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "A formal theory of inductive inference. part i",
        "link": "none",
        "n_parents": 1,
        "year": "1964"
    },
    "pointer networks": {
        "id": "1506.03134",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Pointer networks",
        "link": "https://arxiv.org/abs/1506.03134",
        "n_parents": 2,
        "year": "2015"
    },
    "reinforcement learning neural turing machines": {
        "id": "1505.00521",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Reinforcement learning neural turing machines",
        "link": "https://arxiv.org/abs/1505.00521",
        "n_parents": 2,
        "year": "2015"
    },
    "n gram counts and language models from the common crawl": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "N gram counts and language models from the common crawl",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "measuring word alignment quality for statistical machine translation": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Measuring word alignment quality for statistical machine translation",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "draw a recurrent neural network for image generation": {
        "id": "1502.04623",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "DRAW: A recurrent neural network for image generation",
        "link": "https://arxiv.org/abs/1502.04623",
        "n_parents": 1,
        "year": "none"
    },
    "on using very large target vocabulary for neural machine translation": {
        "id": "1412.2007",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "On using very large target vocabulary for neural machine translation",
        "link": "https://arxiv.org/abs/1412.2007",
        "n_parents": 2,
        "year": "none"
    },
    "alignment by agreement": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Alignment by agreement",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "addressing the rare word problem in neural machine translation": {
        "id": "1410.8206",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Addressing the rare word problem in neural machine translation",
        "link": "https://arxiv.org/abs/1410.8206",
        "n_parents": 3,
        "year": "none"
    },
    "recurrent models of visual attention": {
        "id": "1406.6247",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Recurrent models of visual attention",
        "link": "https://arxiv.org/abs/1406.6247",
        "n_parents": 2,
        "year": "none"
    },
    "bleu a method for automatic evaluation of machine translation": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Bleu: a method for automatic evaluation of machine translation",
        "link": "none",
        "n_parents": 2,
        "year": "none"
    },
    "recurrent neural network regularization": {
        "id": "1409.2329",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Recurrent neural network regularization",
        "link": "https://arxiv.org/abs/1409.2329",
        "n_parents": 3,
        "year": "none"
    },
    "learning to compose neural networks for question answering": {
        "id": "1601.01705",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Learning to compose neural networks for question answering",
        "link": "https://arxiv.org/abs/1601.01705",
        "n_parents": 1,
        "year": "2016"
    },
    "end to end attention based large vocabulary speech recognition": {
        "id": "1508.04395",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "End to end attention based large vocabulary speech recognition",
        "link": "https://arxiv.org/abs/1508.04395",
        "n_parents": 1,
        "year": "2015"
    },
    "question answering with subgraph embeddings": {
        "id": "1406.3676",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Question answering with subgraph embeddings",
        "link": "https://arxiv.org/abs/1406.3676",
        "n_parents": 1,
        "year": "2014"
    },
    "functional imaging of numerical processing in adults and 4 y old children": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Functional imaging of numerical processing in adults and 4 y old children",
        "link": "none",
        "n_parents": 1,
        "year": "2006"
    },
    "driving semantic parsing from the worlds response": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Driving semantic parsing from the world's response",
        "link": "none",
        "n_parents": 1,
        "year": "2010"
    },
    "using prior knowledge in an nnpda to learn context free languages": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Using prior knowledge in an NNPDA to learn context free languages",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "numerical processing in the human parietal cortex during experimental and natural conditions": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Numerical processing in the human parietal cortex during experimental and natural conditions",
        "link": "none",
        "n_parents": 1,
        "year": "2013"
    },
    "reading to learn constructing features from semantic abstracts": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Reading to learn: Constructing features from semantic abstracts",
        "link": "none",
        "n_parents": 1,
        "year": "2009"
    },
    "processing of abstract ordinal knowledge in the horizontal segment of the intraparietal sulcus": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Processing of abstract ordinal knowledge in the horizontal segment of the intraparietal sulcus",
        "link": "none",
        "n_parents": 1,
        "year": "2007"
    },
    "deep speech scaling up end to end speech recognition": {
        "id": "1412.5567",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Deep Speech: Scaling up end to end speech recognition",
        "link": "https://arxiv.org/abs/1412.5567",
        "n_parents": 1,
        "year": "2014"
    },
    "teaching machines to read and comprehend": {
        "id": "1506.03340",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Teaching machines to read and comprehend",
        "link": "https://arxiv.org/abs/1506.03340",
        "n_parents": 1,
        "year": "2015"
    },
    "deep neural networks for acoustic modeling in speech recognition": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Deep neural networks for acoustic modeling in speech recognition",
        "link": "none",
        "n_parents": 2,
        "year": "2012"
    },
    "robust estimation of a location parameter": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Robust estimation of a location parameter",
        "link": "none",
        "n_parents": 1,
        "year": "1964"
    },
    "a neural network for factoid question answering over paragraphs": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "A neural network for factoid question answering over paragraphs",
        "link": "none",
        "n_parents": 1,
        "year": "2014"
    },
    "impaired neural networks for approximate calculation in dyscalculic children a functional mri study": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Impaired neural networks for approximate calculation in dyscalculic children: a functional mri study",
        "link": "none",
        "n_parents": 1,
        "year": "2006"
    },
    "ask me anything dynamic memory networks for natural language processing": {
        "id": "1506.07285",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Ask me anything: Dynamic memory networks for natural language processing",
        "link": "https://arxiv.org/abs/1506.07285",
        "n_parents": 1,
        "year": "2015"
    },
    "learning programs a hierarchical bayesian approach": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Learning programs: A hierarchical Bayesian approach",
        "link": "none",
        "n_parents": 2,
        "year": "2010"
    },
    "learning dependency based compositional semantics": {
        "id": "1109.6841",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Learning dependency based compositional semantics",
        "link": "https://arxiv.org/abs/1109.6841",
        "n_parents": 1,
        "year": "2011"
    },
    "modeling relation paths for representation learning of knowledge bases": {
        "id": "1506.00379",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Modeling relation paths for representation learning of knowledge bases",
        "link": "https://arxiv.org/abs/1506.00379",
        "n_parents": 1,
        "year": "2015"
    },
    "compositional vector space models for knowledge base completion": {
        "id": "1504.06662",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Compositional vector space models for knowledge base completion",
        "link": "https://arxiv.org/abs/1504.06662",
        "n_parents": 1,
        "year": "2015"
    },
    "compositional semantic parsing on semi structured tables": {
        "id": "1508.00305",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Compositional semantic parsing on semi structured tables",
        "link": "https://arxiv.org/abs/1508.00305",
        "n_parents": 1,
        "year": "2015"
    },
    "towards neural network based reasoning": {
        "id": "1508.05508",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Towards neural network based reasoning",
        "link": "https://arxiv.org/abs/1508.05508",
        "n_parents": 1,
        "year": "2015"
    },
    "a bayesian model of the acquisition of compositional semantics": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "A Bayesian model of the acquisition of compositional semantics",
        "link": "none",
        "n_parents": 1,
        "year": "2008"
    },
    "tuning curves for approximate numerosity in the human intraparietal sulcus": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Tuning curves for approximate numerosity in the human intraparietal sulcus",
        "link": "none",
        "n_parents": 1,
        "year": "2004"
    },
    "grounded unsupervised semantic parsing": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Grounded unsupervised semantic parsing",
        "link": "none",
        "n_parents": 1,
        "year": "2013"
    },
    "a self referentialweight matrix": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "A self referentialweight matrix",
        "link": "none",
        "n_parents": 1,
        "year": "1993"
    },
    "neural responding machine for short text conversation": {
        "id": "1503.02364",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Neural responding machine for short text conversation",
        "link": "https://arxiv.org/abs/1503.02364",
        "n_parents": 1,
        "year": "2015"
    },
    "a neural conversational model": {
        "id": "1506.05869",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "A neural conversational model",
        "link": "https://arxiv.org/abs/1506.05869",
        "n_parents": 1,
        "year": "2015"
    },
    "show and tell a neural image caption generator": {
        "id": "1411.4555",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Show and tell: A neural image caption generator",
        "link": "https://arxiv.org/abs/1411.4555",
        "n_parents": 4,
        "year": "2015"
    },
    "building a semantic parser overnight": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Building a semantic parser overnight",
        "link": "none",
        "n_parents": 1,
        "year": "2015"
    },
    "backpropagation through time what does it do and how to do it": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Backpropagation through time: what does it do and how to do it",
        "link": "none",
        "n_parents": 1,
        "year": "1990"
    },
    "neural enquirer learning to query tables with natural language": {
        "id": "1512.00965",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Neural enquirer: Learning to query tables with natural language",
        "link": "https://arxiv.org/abs/1512.00965",
        "n_parents": 1,
        "year": "2015"
    },
    "learning to parse database queries using inductive logic programming": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Learning to parse database queries using inductive logic programming",
        "link": "none",
        "n_parents": 1,
        "year": "1996"
    },
    "learning to map sentences to logical form structured classification with probabilistic categorial grammars": {
        "id": "1207.1420",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars",
        "link": "https://arxiv.org/abs/1207.1420",
        "n_parents": 1,
        "year": "2005"
    },
    "phog probabilistic model for code": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "PHOG: probabilistic model for code",
        "link": "none",
        "n_parents": 1,
        "year": "2016"
    },
    "on the naturalness of software": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "On the naturalness of software",
        "link": "none",
        "n_parents": 1,
        "year": "2016"
    },
    "bidirectional recursive neural networks for token level labeling with structure": {
        "id": "1312.0493",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Bidirectional recursive neural networks for token level labeling with structure",
        "link": "https://arxiv.org/abs/1312.0493",
        "n_parents": 1,
        "year": "2013"
    },
    "the inside outside recursive neural network model for dependency parsing": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "The inside outside recursive neural network model for dependency parsing",
        "link": "none",
        "n_parents": 1,
        "year": "2014"
    },
    "structured generative models of natural source code": {
        "id": "1401.0514",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Structured generative models of natural source code",
        "link": "https://arxiv.org/abs/1401.0514",
        "n_parents": 2,
        "year": "2014"
    },
    "global belief recursive neural networks": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Global belief recursive neural networks",
        "link": "none",
        "n_parents": 1,
        "year": "2014"
    },
    "predicting program properties from big code": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Predicting program properties from \"big code\"",
        "link": "none",
        "n_parents": 1,
        "year": "2015"
    },
    "synthesizing data structure manipulations from storyboards": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Synthesizing data structure manipulations from storyboards",
        "link": "none",
        "n_parents": 1,
        "year": "2011"
    },
    "neural reuse a fundamental organizational principle of the brain": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Neural reuse: A fundamental organizational principle of the brain",
        "link": "none",
        "n_parents": 1,
        "year": "2010"
    },
    "programmable reinforcement learning agents": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Programmable reinforcement learning agents",
        "link": "none",
        "n_parents": 1,
        "year": "2001"
    },
    "genetic programming an introduction volume1": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "\\Genetic programming: An introduction, volume~1",
        "link": "none",
        "n_parents": 1,
        "year": "1998"
    },
    "hierarchical reinforcement learning with the maxq value function decomposition": {
        "id": "9905014",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Hierarchical reinforcement learning with the MAXQ value function decomposition",
        "link": "https://arxiv.org/abs/9905014",
        "n_parents": 1,
        "year": "2000"
    },
    "programming in the brain a neural network theoretical framework": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Programming in the brain: A neural network theoretical framework",
        "link": "none",
        "n_parents": 1,
        "year": "2012"
    },
    "a programmer\u2013interpreter neural network architecture for prefrontal cognitive control": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "A programmer\u2013interpreter neural network architecture for prefrontal cognitive control",
        "link": "none",
        "n_parents": 1,
        "year": "2015"
    },
    "3d object detection and viewpoint estimation with a deformable 3d cuboid model": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "3D object detection and viewpoint estimation with a deformable 3D cuboid model",
        "link": "none",
        "n_parents": 1,
        "year": "2012"
    },
    "hierarchical apprenticeship learning with application to quadruped locomotion": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Hierarchical apprenticeship learning with application to quadruped locomotion",
        "link": "none",
        "n_parents": 1,
        "year": "2008"
    },
    "catastrophic interference in connectionist networks the sequential learning problem": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Catastrophic interference in connectionist networks: The sequential learning problem",
        "link": "none",
        "n_parents": 1,
        "year": "1989"
    },
    "building program vector representations for deep learning": {
        "id": "1409.3358",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Building program vector representations for deep learning",
        "link": "https://arxiv.org/abs/1409.3358",
        "n_parents": 2,
        "year": "2014"
    },
    "complementary learning systems": {
        "id": "1905.02636",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Complementary learning systems",
        "link": "https://arxiv.org/abs/1905.02636",
        "n_parents": 1,
        "year": "2014"
    },
    "modular inverse reinforcement learning for visuomotor behavior": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Modular inverse reinforcement learning for visuomotor behavior",
        "link": "none",
        "n_parents": 1,
        "year": "2013"
    },
    "parallel distributed processing explorations in the microstructure of cognition vol 1": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Parallel distributed processing: Explorations in the microstructure of cognition, vol. 1",
        "link": "none",
        "n_parents": 1,
        "year": "1986"
    },
    "universal value function approximators": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Universal value function approximators",
        "link": "none",
        "n_parents": 1,
        "year": "2015"
    },
    "learning to control fast weight memories an alternative to dynamic recurrent networks": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Learning to control fast weight memories: An alternative to dynamic recurrent networks",
        "link": "none",
        "n_parents": 1,
        "year": "1992"
    },
    "controlled and automatic processing behavior theory and biological mechanisms": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Controlled and automatic processing: behavior, theory, and biological mechanisms",
        "link": "none",
        "n_parents": 1,
        "year": "2003"
    },
    "learning options through human interaction": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Learning options through human interaction",
        "link": "none",
        "n_parents": 1,
        "year": "2011"
    },
    "using matrices to model symbolic relationship": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Using matrices to model symbolic relationship",
        "link": "none",
        "n_parents": 1,
        "year": "2009"
    },
    "between mdps and semi mdps a framework for temporal abstraction in reinforcement learning": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Between MDPs and semi MDPs: A framework for temporal abstraction in reinforcement learning",
        "link": "none",
        "n_parents": 1,
        "year": "1999"
    },
    "url urlhttptensorfloworg": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "URL \\urlhttp://tensorflow.org/",
        "link": "none",
        "n_parents": 1,
        "year": "2015"
    },
    "recursive program synthesis": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Recursive program synthesis",
        "link": "none",
        "n_parents": 1,
        "year": "2013"
    },
    "neural module networks": {
        "id": "1511.02799",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Neural module networks",
        "link": "https://arxiv.org/abs/1511.02799",
        "n_parents": 1,
        "year": "2016"
    },
    "learning to generate textual data": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Learning to generate textual data",
        "link": "none",
        "n_parents": 1,
        "year": "2016"
    },
    "starting forth": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "\\Starting Forth",
        "link": "none",
        "n_parents": 1,
        "year": "1980"
    },
    "a neural compiler": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "A Neural compiler",
        "link": "none",
        "n_parents": 1,
        "year": "1995"
    },
    "symbolic execution and program testing": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Symbolic Execution and Program Testing",
        "link": "none",
        "n_parents": 1,
        "year": "1976"
    },
    "parsing algebraic word problems into equations": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Parsing Algebraic Word Problems into Equations",
        "link": "none",
        "n_parents": 1,
        "year": "2015"
    },
    "genetic programming on the programming of computers by means of natural selection volume1": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "\\Genetic Programming: On the Programming of Computers by Means of Natural Selection, volume~1",
        "link": "none",
        "n_parents": 1,
        "year": "1992"
    },
    "learning to automatically solve algebra word problems": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Learning to Automatically Solve Algebra Word Problems",
        "link": "none",
        "n_parents": 1,
        "year": "2014"
    },
    "learning repetitive text editing procedures with smartedit": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Learning repetitive text editing procedures with smartedit",
        "link": "none",
        "n_parents": 1,
        "year": "2001"
    },
    "gradient based hyperparameter optimization through reversible learning": {
        "id": "1502.03492",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Gradient based Hyperparameter Optimization through Reversible Learning",
        "link": "https://arxiv.org/abs/1502.03492",
        "n_parents": 1,
        "year": "2015"
    },
    "toward automatic program synthesis": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Toward automatic program synthesis",
        "link": "none",
        "n_parents": 1,
        "year": "1971"
    },
    "evolutionary program induction of binary machine code and its applications": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "\\Evolutionary Program Induction of Binary Machine Code and its Applications",
        "link": "none",
        "n_parents": 1,
        "year": "1997"
    },
    "solving general arithmetic word problems": {
        "id": "1608.01413",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Solving General Arithmetic Word Problems",
        "link": "https://arxiv.org/abs/1608.01413",
        "n_parents": 1,
        "year": "2015"
    },
    "reasoning about quantities in natural language": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Reasoning about quantities in natural language",
        "link": "none",
        "n_parents": 1,
        "year": "2015"
    },
    "neural programming language": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Neural Programming Language",
        "link": "none",
        "n_parents": 1,
        "year": "1994"
    },
    "joint language and translation modeling with recurrent neural networks": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Joint language and translation modeling with recurrent neural networks",
        "link": "none",
        "n_parents": 1,
        "year": "2013"
    },
    "multi column deep neural networks for image classification": {
        "id": "1202.2745",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Multi column deep neural networks for image classification",
        "link": "https://arxiv.org/abs/1202.2745",
        "n_parents": 1,
        "year": "2012"
    },
    "edinburghs phrase based machine translation systems for wmt 14": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Edinburgh's phrase based machine translation systems for wmt 14",
        "link": "none",
        "n_parents": 1,
        "year": "2014"
    },
    "connectionist temporal classification labelling unsegmented sequence data with recurrent neural networks": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks",
        "link": "none",
        "n_parents": 1,
        "year": "2006"
    },
    "untersuchungen zu dynamischen neuronalen netzen": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Untersuchungen zu dynamischen neuronalen netzen",
        "link": "none",
        "n_parents": 1,
        "year": "1991"
    },
    "lstm can solve hard long time lag problems": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "LSTM can solve hard long time lag problems",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "building high level features using large scale unsupervised learning": {
        "id": "1112.6209",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Building high level features using large scale unsupervised learning",
        "link": "https://arxiv.org/abs/1112.6209",
        "n_parents": 1,
        "year": "2012"
    },
    "recurrent neural network based language model": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Recurrent neural network based language model",
        "link": "none",
        "n_parents": 2,
        "year": "2010"
    },
    "on small depth threshold circuits": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "On small depth threshold circuits",
        "link": "none",
        "n_parents": 1,
        "year": "1992"
    },
    "learning representations by back propagating errors": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Learning representations by back propagating errors",
        "link": "none",
        "n_parents": 2,
        "year": "1986"
    },
    "university le mans": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "University le mans",
        "link": "none",
        "n_parents": 1,
        "year": "2014"
    },
    "lstm neural networks for language modeling": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "LSTM neural networks for language modeling",
        "link": "none",
        "n_parents": 1,
        "year": "2010"
    },
    "backpropagation through time what it does and how to do it": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Backpropagation through time: what it does and how to do it",
        "link": "none",
        "n_parents": 1,
        "year": "1990"
    },
    "the meaning factory formal semantics for recognizing textual entailment and determining semantic similarity": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "The Meaning Factory: Formal semantics for recognizing textual entailment and determining semantic similarity",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "a convolutional neural network for modelling sentences": {
        "id": "1404.2188",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "A convolutional neural network for modelling sentences",
        "link": "https://arxiv.org/abs/1404.2188",
        "n_parents": 1,
        "year": "none"
    },
    "a fast and accurate dependency parser using neural networks": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "A fast and accurate dependency parser using neural networks",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "natural language processing almost from scratch": {
        "id": "1103.0398",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Natural language processing (almost) from scratch",
        "link": "https://arxiv.org/abs/1103.0398",
        "n_parents": 1,
        "year": "none"
    },
    "adaptive subgradient methods for online learning and stochastic optimization": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Adaptive subgradient methods for online learning and stochastic optimization",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "the measurement of textual coherence with latent semantic analysis": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "The measurement of textual coherence with latent semantic analysis",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "ppdb the paraphrase database": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "PPDB: The Paraphrase Database",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "learning task dependent distributed representations by backpropagation through structure": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Learning task dependent distributed representations by backpropagation through structure",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "multi step regression learning for compositional distributional semantics": {
        "id": "1301.6939",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Multi step regression learning for compositional distributional semantics",
        "link": "https://arxiv.org/abs/1301.6939",
        "n_parents": 1,
        "year": "none"
    },
    "improving neural networks by preventing co adaptation of feature detectors": {
        "id": "1207.0580",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Improving neural networks by preventing co adaptation of feature detectors",
        "link": "https://arxiv.org/abs/1207.0580",
        "n_parents": 1,
        "year": "none"
    },
    "the vanishing gradient problem during learning recurrent neural nets and problem solutions": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "The vanishing gradient problem during learning recurrent neural nets and problem solutions",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "improving word representations via global context and multiple word prototypes": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Improving word representations via global context and multiple word prototypes",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "deep recursive neural networks for compositionality in language": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Deep recursive neural networks for compositionality in language",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "unal nlp combining soft cardinality features for semantic textual similarity relatedness and entailment": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "UNAL NLP: Combining soft cardinality features for semantic textual similarity, relatedness and entailment",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "convolutional neural networks for sentence classification": {
        "id": "1408.5882",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Convolutional neural networks for sentence classification",
        "link": "https://arxiv.org/abs/1408.5882",
        "n_parents": 1,
        "year": "none"
    },
    "accurate unlexicalized parsing": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Accurate unlexicalized parsing",
        "link": "none",
        "n_parents": 2,
        "year": "none"
    },
    "illinois lh a denotational and distributional approach to semantics": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Illinois lh: A denotational and distributional approach to semantics",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "a solution to platos problem the latent semantic analysis theory of acquisition induction and representation of knowledge": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "A solution to plato's problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "distributed representations of sentences and documents": {
        "id": "1405.4053",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Distributed representations of sentences and documents",
        "link": "https://arxiv.org/abs/1405.4053",
        "n_parents": 1,
        "year": "none"
    },
    "distributed representations of words and phrases and their compositionality": {
        "id": "1310.4546",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Distributed representations of words and phrases and their compositionality",
        "link": "https://arxiv.org/abs/1310.4546",
        "n_parents": 1,
        "year": "none"
    },
    "composition in distributional models of semantics": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Composition in distributional models of semantics",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "glove global vectors for word representation": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Glove: Global vectors for word representation",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "grounded compositional semantics for finding and describing images with sentences": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Grounded compositional semantics for finding and describing images with sentences",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "parsing natural scenes and natural language with recursive neural networks": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Parsing natural scenes and natural language with recursive neural networks",
        "link": "none",
        "n_parents": 2,
        "year": "none"
    },
    "recursive deep models for semantic compositionality over a sentiment treebank": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Recursive deep models for semantic compositionality over a sentiment treebank",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "modeling documents with deep boltzmann machines": {
        "id": "1309.6865",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Modeling documents with deep boltzmann machines",
        "link": "https://arxiv.org/abs/1309.6865",
        "n_parents": 1,
        "year": "none"
    },
    "word representations a simple and general method for semi supervised learning": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Word representations: a simple and general method for semi supervised learning",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "compositional matrix space models for sentiment analysis": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Compositional matrix space models for sentiment analysis",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "ecnu one stone two birds ensemble of heterogenous measures for semantic relatedness and textual entailment": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "ECNU: One stone two birds: Ensemble of heterogenous measures for semantic relatedness and textual entailment",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "efficient estimation of word representations in vector space": {
        "id": "1301.3781",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Efficient estimation of word representations in vector space",
        "link": "https://arxiv.org/abs/1301.3781",
        "n_parents": 1,
        "year": "2013"
    },
    "ontonotes the 90 solution": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Ontonotes: The 90\\% solution",
        "link": "none",
        "n_parents": 1,
        "year": "2006"
    },
    "questionbank creating a corpus of parse annotated questions": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Questionbank: Creating a corpus of parse annotated questions",
        "link": "none",
        "n_parents": 1,
        "year": "2006"
    },
    "building a large annotated corpus of english the penn treebank": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Building a large annotated corpus of english: The penn treebank",
        "link": "none",
        "n_parents": 1,
        "year": "1993"
    },
    "ambiguity aware ensemble training for semi supervised dependency parsing": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Ambiguity aware ensemble training for semi supervised dependency parsing",
        "link": "none",
        "n_parents": 1,
        "year": "2014"
    },
    "learning accurate compact and interpretable tree annotation": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Learning accurate, compact, and interpretable tree annotation",
        "link": "none",
        "n_parents": 1,
        "year": "2006"
    },
    "fast and accurate shift reduce constituent parsing": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Fast and accurate shift reduce constituent parsing",
        "link": "none",
        "n_parents": 1,
        "year": "2013"
    },
    "products of random latent variable grammars": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Products of random latent variable grammars",
        "link": "none",
        "n_parents": 1,
        "year": "2010"
    },
    "self training pcfg grammars with latent annotations across languages": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Self training PCFG grammars with latent annotations across languages",
        "link": "none",
        "n_parents": 1,
        "year": "2009"
    },
    "effective self training for parsing": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Effective self training for parsing",
        "link": "none",
        "n_parents": 1,
        "year": "2006"
    },
    "self training with products of latent variable grammars": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Self training with products of latent variable grammars",
        "link": "none",
        "n_parents": 1,
        "year": "2010"
    },
    "sparser better faster gpu parsing": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Sparser, better, faster gpu parsing",
        "link": "none",
        "n_parents": 1,
        "year": "2014"
    },
    "three generative lexicalised models for statistical parsing": {
        "id": "9706022",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Three generative, lexicalised models for statistical parsing",
        "link": "https://arxiv.org/abs/9706022",
        "n_parents": 1,
        "year": "1997"
    },
    "inducing history representations for broad coverage statistical parsing": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Inducing history representations for broad coverage statistical parsing",
        "link": "none",
        "n_parents": 1,
        "year": "2003"
    },
    "discriminative training of a neural network statistical parser": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Discriminative training of a neural network statistical parser",
        "link": "none",
        "n_parents": 1,
        "year": "2004"
    },
    "constituent parsing with incremental sigmoid belief networks": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Constituent parsing with incremental sigmoid belief networks",
        "link": "none",
        "n_parents": 1,
        "year": "2007"
    },
    "deep learning for efficient discriminative parsing": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Deep learning for efficient discriminative parsing",
        "link": "none",
        "n_parents": 1,
        "year": "2011"
    },
    "a linear observed time statistical parser based on maximum entropy models": {
        "id": "9706014",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "A linear observed time statistical parser based on maximum entropy models",
        "link": "https://arxiv.org/abs/9706014",
        "n_parents": 1,
        "year": "1997"
    },
    "incremental parsing with the perceptron algorithm": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Incremental parsing with the perceptron algorithm",
        "link": "none",
        "n_parents": 1,
        "year": "2004"
    },
    "end to end continuous speech recognition using attention based recurrent nn first results": {
        "id": "1412.1602",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "End to end continuous speech recognition using attention based recurrent nn: First results",
        "link": "https://arxiv.org/abs/1412.1602",
        "n_parents": 1,
        "year": "2014"
    },
    "a neural network for learning how to parse tree adjoining grammar": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "A neural network for learning how to parse tree adjoining grammar",
        "link": "none",
        "n_parents": 1,
        "year": "1990"
    },
    "multiple object recognition with visual attention": {
        "id": "1412.7755",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Multiple object recognition with visual attention",
        "link": "https://arxiv.org/abs/1412.7755",
        "n_parents": 1,
        "year": "none"
    },
    "the dropout learning algorithm": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "The dropout learning algorithm",
        "link": "none",
        "n_parents": 1,
        "year": "2014"
    },
    "learning a recurrent visual representation for image caption generation": {
        "id": "1411.5654",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Learning a recurrent visual representation for image caption generation",
        "link": "https://arxiv.org/abs/1411.5654",
        "n_parents": 1,
        "year": "2014"
    },
    "control of goal directed and stimulus driven attention in the brain": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Control of goal directed and stimulus driven attention in the brain",
        "link": "none",
        "n_parents": 1,
        "year": "2002"
    },
    "learning where to attend with deep architectures for image tracking": {
        "id": "1109.3737",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Learning where to attend with deep architectures for image tracking",
        "link": "https://arxiv.org/abs/1109.3737",
        "n_parents": 1,
        "year": "2012"
    },
    "meteor universal language specific translation evaluation for any target language": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Meteor universal: Language specific translation evaluation for any target language",
        "link": "none",
        "n_parents": 1,
        "year": "2014"
    },
    "long term recurrent convolutional networks for visual recognition and description": {
        "id": "1411.4389",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Long term recurrent convolutional networks for visual recognition and description",
        "link": "https://arxiv.org/abs/1411.4389",
        "n_parents": 1,
        "year": "none"
    },
    "image description using visual dependency representations": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Image description using visual dependency representations",
        "link": "none",
        "n_parents": 1,
        "year": "2013"
    },
    "from captions to visual concepts and back": {
        "id": "1411.4952",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "From captions to visual concepts and back",
        "link": "https://arxiv.org/abs/1411.4952",
        "n_parents": 1,
        "year": "none"
    },
    "framing image description as a ranking task data models and evaluation metrics": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Framing image description as a ranking task: Data, models and evaluation metrics",
        "link": "none",
        "n_parents": 1,
        "year": "2013"
    },
    "deep visual semantic alignments for generating image descriptions": {
        "id": "1412.2306",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Deep visual semantic alignments for generating image descriptions",
        "link": "https://arxiv.org/abs/1412.2306",
        "n_parents": 1,
        "year": "none"
    },
    "multimodal neural language models": {
        "id": "1411.2539",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Multimodal neural language models",
        "link": "https://arxiv.org/abs/1411.2539",
        "n_parents": 1,
        "year": "none"
    },
    "unifying visual semantic embeddings with multimodal neural language models": {
        "id": "1411.2539",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Unifying visual semantic embeddings with multimodal neural language models",
        "link": "https://arxiv.org/abs/1411.2539",
        "n_parents": 1,
        "year": "1411"
    },
    "babytalk understanding and generating simple image descriptions": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Babytalk: Understanding and generating simple image descriptions",
        "link": "none",
        "n_parents": 1,
        "year": "2013"
    },
    "collective generation of natural image descriptions": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Collective generation of natural image descriptions",
        "link": "none",
        "n_parents": 1,
        "year": "2012"
    },
    "treetalk composition and compression of trees for image descriptions": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Treetalk: Composition and compression of trees for image descriptions",
        "link": "none",
        "n_parents": 1,
        "year": "2014"
    },
    "learning to combine foveal glimpses with a third order boltzmann machine": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Learning to combine foveal glimpses with a third order boltzmann machine",
        "link": "none",
        "n_parents": 1,
        "year": "2010"
    },
    "composing simple image descriptions using web scale n grams": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Composing simple image descriptions using web scale n grams",
        "link": "none",
        "n_parents": 1,
        "year": "2011"
    },
    "microsoft coco common objects in context": {
        "id": "1405.0312",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Microsoft coco: Common objects in context",
        "link": "https://arxiv.org/abs/1405.0312",
        "n_parents": 1,
        "year": "2014"
    },
    "deep captioning with multimodal recurrent neural networks m rnn": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Deep captioning with multimodal recurrent neural networks (m rnn)",
        "link": "none",
        "n_parents": 1,
        "year": "none"
    },
    "midge generating image descriptions from computer vision detections": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Midge: Generating image descriptions from computer vision detections",
        "link": "none",
        "n_parents": 1,
        "year": "2012"
    },
    "the dynamic representation of scenes": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "The dynamic representation of scenes",
        "link": "none",
        "n_parents": 1,
        "year": "2000"
    },
    "very deep convolutional networks for large scale image recognition": {
        "id": "1409.1556",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Very deep convolutional networks for large scale image recognition",
        "link": "https://arxiv.org/abs/1409.1556",
        "n_parents": 1,
        "year": "2014"
    },
    "practical bayesian optimization of machine learning algorithms": {
        "id": "1206.2944",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Practical bayesian optimization of machine learning algorithms",
        "link": "https://arxiv.org/abs/1206.2944",
        "n_parents": 1,
        "year": "2012"
    },
    "input warping for bayesian optimization of non stationary functions": {
        "id": "1402.0929",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Input warping for bayesian optimization of non stationary functions",
        "link": "https://arxiv.org/abs/1402.0929",
        "n_parents": 1,
        "year": "2014"
    },
    "dropout a simple way to prevent neural networks from overfitting": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Dropout: A simple way to prevent neural networks from overfitting",
        "link": "none",
        "n_parents": 1,
        "year": "2014"
    },
    "going deeper with convolutions": {
        "id": "1409.4842",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Going deeper with convolutions",
        "link": "https://arxiv.org/abs/1409.4842",
        "n_parents": 1,
        "year": "2014"
    },
    "learning generative models with visual attention": {
        "id": "1312.6110",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Learning generative models with visual attention",
        "link": "https://arxiv.org/abs/1312.6110",
        "n_parents": 1,
        "year": "2014"
    },
    "lecture 65 rmsprop": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Lecture 6.5 rmsprop",
        "link": "none",
        "n_parents": 1,
        "year": "2012"
    },
    "the optimal reward baseline for gradient based reinforcement learning": {
        "id": "1301.2315",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "The optimal reward baseline for gradient based reinforcement learning",
        "link": "https://arxiv.org/abs/1301.2315",
        "n_parents": 1,
        "year": "2001"
    },
    "simple statistical gradient following algorithms for connectionist reinforcement learning": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Simple statistical gradient following algorithms for connectionist reinforcement learning",
        "link": "none",
        "n_parents": 1,
        "year": "1992"
    },
    "corpus guided sentence generation of natural images": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Corpus guided sentence generation of natural images",
        "link": "none",
        "n_parents": 1,
        "year": "2011"
    },
    "from image descriptions to visual denotations new similarity metrics for semantic inference over event descriptions": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions",
        "link": "none",
        "n_parents": 1,
        "year": "2014"
    },
    "advances in optimizing recurrent networks": {
        "id": "1212.0901",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Advances in optimizing recurrent networks",
        "link": "https://arxiv.org/abs/1212.0901",
        "n_parents": 1,
        "year": "2013"
    },
    "can recursive neural tensor networks learn logical reasoning": {
        "id": "1312.6192",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Can recursive neural tensor networks learn logical reasoning?",
        "link": "https://arxiv.org/abs/1312.6192",
        "n_parents": 1,
        "year": "2013"
    },
    "recursive neural networks for learning logical semantics": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Recursive neural networks for learning logical semantics",
        "link": "none",
        "n_parents": 1,
        "year": "2014"
    },
    "a statistical derivation of the significant digit law": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "A statistical derivation of the significant digit law",
        "link": "none",
        "n_parents": 1,
        "year": "1995"
    },
    "optimization and applications of echo state networks with leaky integrator neurons": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Optimization and applications of echo state networks with leaky integrator neurons",
        "link": "none",
        "n_parents": 1,
        "year": "2007"
    },
    "self paced learning for latent variable models": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Self paced learning for latent variable models",
        "link": "none",
        "n_parents": 1,
        "year": "2010"
    },
    "learning the easy things first self paced visual category discovery": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Learning the easy things first: Self paced visual category discovery",
        "link": "none",
        "n_parents": 1,
        "year": "2011"
    },
    "deep learning via hessian free optimization": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "Deep learning via hessian free optimization",
        "link": "none",
        "n_parents": 1,
        "year": "2010"
    },
    "dropout improves recurrent neural networks for handwriting recognition": {
        "id": "1312.4569",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Dropout improves recurrent neural networks for handwriting recognition",
        "link": "https://arxiv.org/abs/1312.4569",
        "n_parents": 1,
        "year": "2013"
    },
    "the use of recurrent neural networks in continuous speech recognition": {
        "id": null,
        "depth": 2,
        "children_titles": [],
        "status": "no_id",
        "title_full": "The use of recurrent neural networks in continuous speech recognition",
        "link": "none",
        "n_parents": 1,
        "year": "1996"
    },
    "training recurrent neural networks": {
        "id": "1511.05222",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "\\Training Recurrent Neural Networks",
        "link": "https://arxiv.org/abs/1511.05222",
        "n_parents": 1,
        "year": "2013"
    },
    "learning to discover efficient mathematical identities": {
        "id": "1406.1584",
        "depth": 2,
        "children_titles": [],
        "status": "max_depth",
        "title_full": "Learning to discover efficient mathematical identities",
        "link": "https://arxiv.org/abs/1406.1584",
        "n_parents": 1,
        "year": "none"
    }
}